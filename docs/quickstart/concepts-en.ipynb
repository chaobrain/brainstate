{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Key Concepts\n",
    "\n",
    "Welcome to ``brainstate``!\n",
    "\n",
    "This section will provide a brief introduction to key concepts of the ``brainstate`` framework."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2880d52052c4a9d4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "``BrainState`` is a high-performance computing framework specifically designed for modeling brain dynamics, built on top of [JAX](https://github.com/jax-ml/jax). It provides a comprehensive toolchain for neuroscientists, computational modeler, and brain-inspired computing researchers to build, optimize, and deploy various neural network models. It integrates advanced features such as modern hardware acceleration, automatic differentiation, and event-driven computing, specifically tailored for neural networks, particularly Spiking Neural Networks (SNNs). The following tutorial will detail its core functionalities and use cases, helping you quickly get started and understand how to utilize ``BrainState`` for constructing and optimizing your brain dynamics models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d60555bec9e4eab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "import brainstate as bst"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:05.279125Z",
     "start_time": "2024-11-03T08:20:04.482926Z"
    }
   },
   "id": "719f5d71daa81299",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview of Core Functions\n",
    "\n",
    "The core functionalities of ``BrainState`` include the following components:\n",
    "\n",
    "- **Program Compilation**: Supports [program compilation](../apis/compile.rst) using the [`State`-based syntax](../apis/brainstate.rst), enabling the deployment of computational models on various hardware platforms such as CPU, GPU, and TPU.\n",
    "- **Program Functionality Augmentation**: Provides [program functionality enhancement](../apis/augment.rst) features using the [``PyGraph``-based syntax](../apis/graph.rst), simplifying the process of constructing complex computational models through mechanisms such as automatic differentiation, batching, and parallelization.\n",
    "- **Event-Driven Computation**: Supports operator optimization based on [event-driven computation](../apis/event.rst), significantly improving the efficiency and scalability of Spiking Neural Networks.\n",
    "- **Additional Features**: Includes convenient auxiliary tools such as random number generation, surrogate gradient functions, and model parameter management, facilitating diverse model construction for users.\n",
    "\n",
    "In the following sections, we will examine in detail the implementation methodologies and optimization strategies for each of these functionalities."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d0a4af0370514cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. ``State`` Syntax\n",
    "\n",
    "While JAX typically favors functional programming paradigms, this approach may not be sufficiently intuitive for complex computational tasks such as brain dynamics modeling. ``BrainState`` introduces the ``State`` syntax, a highly abstracted interface that enables users to define and manage computational states much more easily and intuitively. The core characteristics of ``State`` syntax include:\n",
    "\n",
    "- All variables that need to be modified should be encapsulated within the ``State`` object, allowing users to track and debug the model's state.\n",
    "- Any variables not encapsulated by the ``State`` are immutable and cannot be modified after program compilation. The compilation functions provided in ``BrainState`` can be referenced in the [``brainstate.compile`` module](../apis/compile.rst).\n",
    "\n",
    "This means that in `BrainState`, all variables requiring mutation must be encapsulated within ``State`` objects to ensure program correctness and maintainability."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96e8f0b4d7601cf2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ``State`` class can have various subclasses. For example, in ``BrainState``, ``ParamState`` is a subclass of ``State`` used to encapsulate model parameters, while ``RandomState`` is another subclass designed to encapsulate the state of random number generators. Users can easily extend their own ``State`` subclasses to meet diverse needs. For instance:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee890dc8a6dcad34"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Counter(bst.State):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:05.283405Z",
     "start_time": "2024-11-03T08:20:05.280135Z"
    }
   },
   "id": "c370d94b2a04ef58",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the example above, by inheriting from the ``State`` class, we define a ``Counter`` class that can be used to encapsulate the state of a counter. This approach allows users to more flexibly define and manage the model's state, enhancing the readability and maintainability of the code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c743bf6449e39f4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "``State`` can wrap any Python data types, such as integers, floats, arrays, ``jax.Array``, and any of these Python data types encapsulated within dictionaries, lists or tuples. Users can access and modify this data through the ``State.value`` attribute. For example:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d782eacb92a667e3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "State(\n  value=Array([1., 1., 1.], dtype=float32)\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = bst.State(jnp.ones(3))\n",
    "\n",
    "example"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:05.315574Z",
     "start_time": "2024-11-03T08:20:05.283405Z"
    }
   },
   "id": "f395706e0a3413b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "State(\n  value=Array([0.7541833, 0.5430715, 0.0052768], dtype=float32)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.value = bst.random.random(3)\n",
    "\n",
    "example"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:05.537863Z",
     "start_time": "2024-11-03T08:20:05.316913Z"
    }
   },
   "id": "246c8503b04cdbc3",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "``State`` supports any [PyTree](https://jax.readthedocs.io/en/latest/working-with-pytrees.html), meaning that users can encapsulate any pytreee data structure within a ``State`` object, facilitating convenient state management and computation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5fd66a4cb2d137c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "State(\n  value={'a': Array([1., 1., 1.], dtype=float32), 'b': Array([0., 0., 0., 0.], dtype=float32)}\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example2 = bst.State({'a': jnp.ones(3), 'b': jnp.zeros(4)})\n",
    "\n",
    "example2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:05.558330Z",
     "start_time": "2024-11-03T08:20:05.538868Z"
    }
   },
   "id": "6ae2f6430cb30e52",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. ``PyGraph`` Syntax\n",
    "\n",
    "In JAX, a pytree (Python tree) is a versatile data structure used to flexibly represent nested, tree-like Python containers. It can encompass various containers such as lists, tuples, and dictionaries, while also allowing for the nesting of different types of data structures, such as NumPy arrays, JAX arrays, or custom objects. This flexibility makes pytree highly useful for data processing and model construction; however, its expressive capability may be limited in complex scientific computing scenarios.\n",
    "\n",
    "In many scientific computations, we often need to define intricate computation graphs that may include cyclic references, nested structures, and dynamically generated computational processes -- situations that are difficult to represent with the pytree structure. To address this challenge, ``brainstate`` provides the ``PyGraph`` data structure, offering users a more intuitive and flexible means to define and manipulate complex computational models that intertwine various modular objects in Python.\n",
    "\n",
    "The design of ``PyGraph`` is derived from Flax's [nnx module](https://flax.readthedocs.io/) and extends and optimises it for ``State`` retrieval, management and manipulation in ``brainstate``. ``PyGraph`` is constructed from basic sub-nodes represented by ``brainstate.graph.Node``, which can form directed acyclic graphs (DAGs) and support cyclic references between nodes, thereby facilitating the construction of complex computational workflows more naturally.\n",
    "\n",
    "Below is a simple code example."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89268cc809272164"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Linear(bst.graph.Node):\n",
    "    def __init__(self, din: int, dout: int):\n",
    "        self.din, self.dout = din, dout\n",
    "        self.w = bst.ParamState(bst.random.rand(din, dout))\n",
    "        self.b = bst.ParamState(jnp.zeros((dout,)))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x @ self.w.value + self.b.value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:05.563083Z",
     "start_time": "2024-11-03T08:20:05.559337Z"
    }
   },
   "id": "3335e37228792926",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(\n  din=2,\n  dout=5,\n  w=ParamState(\n    value=Array([[0.94007385, 0.0341239 , 0.57106984, 0.8860879 , 0.1215055 ],\n           [0.6579735 , 0.9333912 , 0.2877561 , 0.09438729, 0.44648933]],      dtype=float32)\n  ),\n  b=ParamState(\n    value=Array([0., 0., 0., 0., 0.], dtype=float32)\n  )\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Linear(2, 5)\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:05.658075Z",
     "start_time": "2024-11-03T08:20:05.564013Z"
    }
   },
   "id": "fecb0ec73611d541",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can incorporate a self-reference within the model to create a cyclic graph. Even in such cases, PyGraph maintains its capability to correctly process this self-referential structure."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7aa52a0b18570e7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(\n  din=2,\n  dout=5,\n  w=ParamState(\n    value=Array([[0.94007385, 0.0341239 , 0.57106984, 0.8860879 , 0.1215055 ],\n           [0.6579735 , 0.9333912 , 0.2877561 , 0.09438729, 0.44648933]],      dtype=float32)\n  ),\n  b=ParamState(\n    value=Array([0., 0., 0., 0., 0.], dtype=float32)\n  ),\n  self=Linear(...)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.self = model\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:05.663187Z",
     "start_time": "2024-11-03T08:20:05.659082Z"
    }
   },
   "id": "4737911609c7bcd6",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "``brainstate.graph.Node`` can be freely composed within nested structures, accommodating any (nested) pytree types, including lists, dictionaries, tuples, and others. Below is an example illustrating a Multi-Layer Perceptron (MLP)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "220993bc897789eb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "MLP(\n  input=Linear(\n    in_size=(2,),\n    out_size=(1,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[-1.2849224 ],\n             [ 0.79070586]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  ),\n  layers=[Linear(\n    in_size=(1,),\n    out_size=(1,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[0.0800172]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  ), Linear(\n    in_size=(1,),\n    out_size=(1,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[-0.6626468]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  ), Linear(\n    in_size=(1,),\n    out_size=(1,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[0.20347145]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  )],\n  output=Linear(\n    in_size=(1,),\n    out_size=(3,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[-1.8724355 ,  1.0703413 , -0.04334985]], dtype=float32), 'bias': Array([0., 0., 0.], dtype=float32)}\n    )\n  )\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(bst.graph.Node):\n",
    "    def __init__(self, din: int, dmid: int, dout: int, n_layer: int = 3):\n",
    "        self.input = bst.nn.Linear(din, dmid)\n",
    "        self.layers = [bst.nn.Linear(dmid, dmid) for _ in range(n_layer)]\n",
    "        self.output = bst.nn.Linear(dmid, dout)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = bst.functional.relu(self.input(x))\n",
    "        for layer in self.layers:\n",
    "            x = bst.functional.relu(layer(x))\n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "model = MLP(2, 1, 3)\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:06.252543Z",
     "start_time": "2024-11-03T08:20:05.663187Z"
    }
   },
   "id": "3e5826887566eb35",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `brainstate.graph` module offers a robust set of tools for creating and managing `PyGraph`, including features for node creation, connections, computations, and updates. These tools allow users to build computational graphs modularly, streamlining the management of workflows while improving model readability and maintainability. Users can leverage [simple APIs](../apis/graph.rst) to add nodes, define dependencies, and dynamically update node states. Additionally, `PyGraph` provides structured representations of computation graphs, helping users intuitively grasp the structure and operation of their workflows.\n",
    "\n",
    "For instance, `brainstate.graph.states` can efficiently retrieve all `State` instances within the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd06f6961d7aa70a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "FlattedDict({\n  ('input', 'weight'): ParamState(\n    value={'weight': Array([[-1.2849224 ],\n           [ 0.79070586]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n  ),\n  ('layers', 0, 'weight'): ParamState(\n    value={'weight': Array([[0.0800172]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n  ),\n  ('layers', 1, 'weight'): ParamState(\n    value={'weight': Array([[-0.6626468]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n  ),\n  ('layers', 2, 'weight'): ParamState(\n    value={'weight': Array([[0.20347145]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n  ),\n  ('output', 'weight'): ParamState(\n    value={'weight': Array([[-1.8724355 ,  1.0703413 , -0.04334985]], dtype=float32), 'bias': Array([0., 0., 0.], dtype=float32)}\n  )\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = bst.graph.states(model)\n",
    "\n",
    "states"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:06.260323Z",
     "start_time": "2024-11-03T08:20:06.254407Z"
    }
   },
   "id": "dd9b71905f548720",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "NestedDict({\n  'input': {\n    'weight': ParamState(\n      value={'weight': Array([[-1.2849224 ],\n             [ 0.79070586]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  },\n  'layers': {\n    0: {\n      'weight': ParamState(\n        value={'weight': Array([[0.0800172]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n      )\n    },\n    1: {\n      'weight': ParamState(\n        value={'weight': Array([[-0.6626468]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n      )\n    },\n    2: {\n      'weight': ParamState(\n        value={'weight': Array([[0.20347145]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n      )\n    }\n  },\n  'output': {\n    'weight': ParamState(\n      value={'weight': Array([[-1.8724355 ,  1.0703413 , -0.04334985]], dtype=float32), 'bias': Array([0., 0., 0.], dtype=float32)}\n    )\n  }\n})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.to_nest()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:06.266361Z",
     "start_time": "2024-11-03T08:20:06.261330Z"
    }
   },
   "id": "32ade61b63508b74",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "For example, ``brainstate.graph.nodes`` can efficiently retrieve all ``Node`` instances encompassed within the model:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49f744e5852c3d60"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "FlattedDict({\n  ('input',): Linear(\n    in_size=(2,),\n    out_size=(1,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[-1.2849224 ],\n             [ 0.79070586]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  ),\n  ('layers', 0): Linear(\n    in_size=(1,),\n    out_size=(1,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[0.0800172]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  ),\n  ('layers', 1): Linear(\n    in_size=(1,),\n    out_size=(1,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[-0.6626468]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  ),\n  ('layers', 2): Linear(\n    in_size=(1,),\n    out_size=(1,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[0.20347145]], dtype=float32), 'bias': Array([0.], dtype=float32)}\n    )\n  ),\n  ('output',): Linear(\n    in_size=(1,),\n    out_size=(3,),\n    w_mask=None,\n    weight=ParamState(\n      value={'weight': Array([[-1.8724355 ,  1.0703413 , -0.04334985]], dtype=float32), 'bias': Array([0., 0., 0.], dtype=float32)}\n    )\n  ),\n  (): MLP(\n    input=Linear(...),\n    layers=[Linear(...), Linear(...), Linear(...)],\n    output=Linear(...)\n  )\n})"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = bst.graph.nodes(model)\n",
    "\n",
    "nodes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:06.274992Z",
     "start_time": "2024-11-03T08:20:06.269032Z"
    }
   },
   "id": "2f72f5c60d289b37",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "In summary, the `PyGraph` syntax offers strong support for complex models in scientific computing, allowing users to efficiently construct, manage, and optimize computation graphs. This capability enhances research and applications in brain dynamics modeling."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d533d59c6d7852ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Program Compilation\n",
    "\n",
    "In high-performance computing, hardware acceleration is essential for improving computational efficiency. The `BrainState` framework achieves hardware compilation and deployment through a `State`-based syntax. This provides a highly abstracted interface that allows users to write code once and generate an intermediate representation (IR) that can be compiled and optimized across various hardware platforms.\n",
    "\n",
    "The compilation capabilities of `brainstate` are primarily housed within the [``brainstate.compile`` module](../apis/compile.rst). These compilation APIs offer a comprehensive range of functionalities, including:\n",
    "\n",
    "- **Conditional Statements**: Supports `if-else` logic, enabling users to execute different computational workflows based on varying conditions.\n",
    "- **Loop Statements**: Supports `for` loops for repeated execution of identical computational operations.\n",
    "- **While Statements**: Supports `while` loops for condition-based repetitive execution of computational tasks.\n",
    "- **Just-In-Time (JIT) Compilation**: Enhances computational efficiency and performance through JIT compilation.\n",
    "\n",
    "A notable feature of `brainstate` compilation is its focus solely on `State`. During program execution, whenever a `State` instance is encountered, it is compiled into the computation graph and executed on various hardware. This approach allows users to define complex programs freely, while the compiler optimizes based on the actual execution paths of the program, significantly enhancing computational efficiency. Furthermore, this `State`-sensitive compilation mode enables users to express program logic with greater flexibility, free from constraints imposed by concepts like `PyGraph` or `PyTree`, thereby maximizing programming versatility.\n",
    "\n",
    "Below is a simple example of the compilation process:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6539e9ece3b61662"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0\n"
     ]
    }
   ],
   "source": [
    "a = bst.State(1.)\n",
    "\n",
    "\n",
    "def add(i):\n",
    "    a.value += 1.\n",
    "\n",
    "\n",
    "bst.compile.for_loop(add, jnp.arange(10))\n",
    "\n",
    "print(a.value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:06.312454Z",
     "start_time": "2024-11-03T08:20:06.276005Z"
    }
   },
   "id": "db5aad9a8f19a46",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, we define a simple for loop that increments the value of `a` by 1 in each iteration. By calling the `bst.compile.for_loop` function, we compile this loop into a computation graph and execute it on JAX."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99ffc7923ea43e09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another distinctive feature of `brainstate` compilation is its capability to recursively invoke both JAX's functional compilation functions and `brainstate`'s built-in `State`-aware compilation functions. `State` variables created or used during intermediate steps remain local and are optimized out throughout the entire program. This characteristic leads to reduced memory consumption and improved execution speed.\n",
    "\n",
    "Here is a simple example of the compilation process:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4355082c10dab42"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.0\n"
     ]
    }
   ],
   "source": [
    "b = bst.State(0.)\n",
    "\n",
    "\n",
    "def add(i):\n",
    "    c = bst.State(0.)\n",
    "\n",
    "    def cond(j):\n",
    "        return j <= i\n",
    "\n",
    "    def body(j):\n",
    "        c.value += 1.\n",
    "        return j + 1\n",
    "\n",
    "    bst.compile.while_loop(cond, body, 0.)\n",
    "\n",
    "    b.value += c.value\n",
    "\n",
    "\n",
    "bst.compile.for_loop(add, jnp.arange(10))\n",
    "\n",
    "print(b.value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:06.346637Z",
     "start_time": "2024-11-03T08:20:06.313459Z"
    }
   },
   "id": "6086108bc8acef60",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is worth noting that ``brainstate`` compilation also supports debugging using JAX's debugging tools. For instance, users can print the values of intermediate states in the program by calling the ``jax.debug.print`` function, which aids in debugging and optimizing the program. The following example provides a debugging output for the program mentioned above. For more information on JAX debugging capabilities, please refer to the [JAX Debugging Documentation](https://jax.readthedocs.io/en/latest/debugging/index.html)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baf641a7cb0adb90"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b = 1.0, c = 1.0\n",
      "b = 3.0, c = 2.0\n",
      "b = 6.0, c = 3.0\n",
      "b = 10.0, c = 4.0\n",
      "b = 15.0, c = 5.0\n",
      "b = 21.0, c = 6.0\n",
      "b = 28.0, c = 7.0\n",
      "b = 36.0, c = 8.0\n",
      "b = 45.0, c = 9.0\n",
      "b = 55.0, c = 10.0\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "b = bst.State(0.)\n",
    "\n",
    "\n",
    "def add(i):\n",
    "    c = bst.State(0.)\n",
    "\n",
    "    def cond(j):\n",
    "        return j <= i\n",
    "\n",
    "    def body(j):\n",
    "        c.value += 1.\n",
    "        return j + 1\n",
    "\n",
    "    bst.compile.while_loop(cond, body, 0.)\n",
    "\n",
    "    b.value += c.value\n",
    "    jax.debug.print('b = {b}, c = {c}', b=b.value, c=c.value)\n",
    "\n",
    "\n",
    "bst.compile.for_loop(add, jnp.arange(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:06.385633Z",
     "start_time": "2024-11-03T08:20:06.346637Z"
    }
   },
   "id": "145d6f5751a31ff2",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "``brainstate`` also supports compilation for different hardware platforms. Users can deploy their models on various hardware, including CPU, GPU, and TPU, simply by changing a parameter. Users can call the following at the beginning of their program:\n",
    "\n",
    "```python\n",
    "brainstate.environ.set(platform='cpu')  # CPU backend\n",
    "\n",
    "brainstate.environ.set(platform='gpu')  # GPU backend\n",
    "\n",
    "brainstate.environ.set(platform='tpu')  # TPU backend\n",
    "```\n",
    "\n",
    "Alternatively, users can use JAX's syntax:\n",
    "\n",
    "```python\n",
    "jax.config.update('jax_platform_name', 'cpu')  # CPU backend\n",
    "\n",
    "jax.config.update('jax_platform_name', 'gpu')  # GPU backend\n",
    "\n",
    "jax.config.update('jax_platform_name', 'tpu')  # TPU backend\n",
    "```\n",
    "\n",
    "This flexible compilation approach enables users to better leverage the advantages of different hardware, enhancing computational efficiency and performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "555f98db1272bc5d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Program Augmentation\n",
    "\n",
    "`Brainstate` also provides a suite of functionality enhancement transformations. For example, while a program may be defined solely for forward inference, users can easily obtain additional gradient information through automatic differentiation transformations such as `grad`. These functional enhancement transformations enable users to construct and optimize complex computational models more conveniently.\n",
    "\n",
    "However, enhancing program functionality requires a solid understanding of the program's structure and clarity regarding enhancement objectives. Users must be familiar with the program's architecture before compilation. To assist with this, the `PyGraph` syntax can be utilized, making it easier for users to define and manage computational models.\n",
    "\n",
    "The various operations and management functions provided by `PyGraph` related to `State` and graph representations significantly simplify the construction of complex functional enhancement transformations. Key enhancement transformations available in `brainstate` include:\n",
    "\n",
    "- **Automatic Differentiation**: Essential for model optimization, particularly in backpropagation and gradient descent algorithms.\n",
    "- **Batch Processing**: Support for processing large-scale data in batches, which significantly enhances training speed and inference efficiency.\n",
    "- **Multi-Device Parallelism**: Facilitates parallel computation across multiple devices, improving computational efficiency and overall model performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e2d1f90666fee88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is a simple example of automatic differentiation:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "925845c6d8624e4e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# <input, output> pair\n",
    "x = jnp.ones((1, 2))\n",
    "y = jnp.ones((1, 3))\n",
    "\n",
    "# model\n",
    "model = bst.nn.Linear(2, 3)\n",
    "\n",
    "\n",
    "# loss function\n",
    "def loss_fn(x, y):\n",
    "    return jnp.mean((y - model(x)) ** 2)\n",
    "\n",
    "\n",
    "prev_loss = loss_fn(x, y)\n",
    "\n",
    "# gradients\n",
    "weights = model.states()\n",
    "grads = bst.augment.grad(loss_fn, weights)(x, y)\n",
    "\n",
    "# SGD update\n",
    "for key, grad in grads.items():\n",
    "    updates = jax.tree.map(lambda p, g: p - 0.1 * g, weights[key].value, grad)\n",
    "    weights[key].value = updates\n",
    "\n",
    "# loss evaluation\n",
    "assert loss_fn(x, y) < prev_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:06.825927Z",
     "start_time": "2024-11-03T08:20:06.386640Z"
    }
   },
   "id": "df82379b9d30c6b5",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the example above, we define a simple linear model and then compute the model's loss function. By calling the ``bst.augment.grad`` function, we can easily obtain the gradient information of the model and update the model parameters using gradient descent algorithms. However, this automatic differentiation enhancement transformation requires us to know in advance which parameters need gradients. Therefore, we use the ``brainstate.graph.states`` function to retrieve all ``State`` instances within the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0e0639713990b37"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall, functional enhancement transformations offer users a more convenient and efficient method for constructing and optimizing computational models. By fully leveraging these features, users can achieve faster model training and inference, ultimately enhancing model performance and efficiency. For more information on functional enhancement transformations, please refer to the tutorial of [Program Augmentation](../tutorials/program_augmentation-en.ipynb)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bec1f951c9dcf41"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Event-Driven Computation\n",
    "\n",
    "Event-driven computation represents a novel paradigm distinct from traditional computing models. Modern computers and compilers are primarily optimized for dense matrices, particularly for operations like matrix multiplication, which underpin contemporary artificial neural networks, as illustrated in Figure A below. However, this computation model does not align with the spiking dynamics of the real brain, where neurons are event-driven and activate only upon receiving spike events. Furthermore, the connections between neurons are sparse, as depicted in Figure B below.\n",
    "\n",
    "![](../_static/dense-mv-vs-event-spmv.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4de99242ecd7d7d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`BrainState` offers operator optimizations that cater specifically to the characteristics of event-driven computing. This paradigm effectively minimizes unnecessary computations, significantly reducing resource consumption and enhancing speed, especially when dealing with sparse data. In Spiking Neural Network (SNN) models, neurons activate only upon receiving spike events, thereby avoiding the computational waste inherent in traditional neural networks, which continue calculations even in the absence of input. This characteristic renders SNNs particularly well-suited for applications that require low power consumption and high efficiency, such as edge computing and embedded systems.\n",
    "\n",
    "**Example**: Defining an event-driven interaction between neurons:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a880c6b0db42cdbe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pre-synaptic spikes, 10000 neurons, 1% sparsity\n",
    "pre_spikes = bst.random.rand(10000) < 0.01\n",
    "\n",
    "# dense weight matrix, 10000x1000, 1% sparsity\n",
    "dense_w = (bst.random.rand(10000, 1000) < 0.01).astype(float)\n",
    "\n",
    "# event-driven weight matrix, 10000x1000, 1% sparsity\n",
    "fp = jax.jit(bst.event.FixedProb(10000, 1000, 0.01, 1.))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:07.057921Z",
     "start_time": "2024-11-03T08:20:06.826933Z"
    }
   },
   "id": "65e376d5ceea0c64",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 ms ± 104 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "jnp.dot(pre_spikes, dense_w)\n",
    "%timeit -n 100 -r 10 jnp.dot(pre_spikes, dense_w)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:08.278949Z",
     "start_time": "2024-11-03T08:20:07.058926Z"
    }
   },
   "id": "264e4e813213cf8a",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597 µs ± 14.7 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "fp(pre_spikes)\n",
    "%timeit -n 100 -r 10 fp(pre_spikes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T08:20:08.972747Z",
     "start_time": "2024-11-03T08:20:08.280313Z"
    }
   },
   "id": "6fc96047144389ea",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Other Auxiliary Functions\n",
    "\n",
    "In addition to the core functionalities mentioned above, `BrainState` offers a range of auxiliary features that simplify model construction and optimization for users. These features include, but are not limited to:\n",
    "\n",
    "- **Random Number Generation**: Quickly generate random numbers with various distributions, useful for simulating randomness or managing random variables.\n",
    "- **Parameter Management**: Provide a straightforward interface for initializing, storing, and updating model parameters, accommodating complex model architectures and multi-layer networks.\n",
    "- **Debugging Tools**: Assist users in monitoring the status and computational results of various layers during the model development process, making it easier to identify potential issues."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc0fe89333cd6d00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "`BrainState` is a powerful framework for brain dynamics modeling, providing capabilities for cross-hardware compilation, computation model enhancement, event-driven computing, and a comprehensive suite of auxiliary tools. For users involved in neuroscience, cognitive modeling, and SNN development, `BrainState` offers extensive modular functionalities that facilitate the rapid construction, optimization, and deployment of efficient brain dynamics models.\n",
    "\n",
    "By thoroughly understanding and leveraging the features outlined above, you can easily create and optimize computational models that are well-suited for a variety of research tasks and hardware platforms."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac1515021cd41d5f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f1a8630b34c771ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
