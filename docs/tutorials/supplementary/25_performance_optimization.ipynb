{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 25: Performance Optimization Guide\n",
    "\n",
    "In this tutorial, we'll explore techniques to optimize BrainState models for maximum performance.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Profile and analyze model performance\n",
    "- Optimize memory usage\n",
    "- Speed up computation with JAX transformations\n",
    "- Implement parallel processing strategies\n",
    "- Understand JIT compilation best practices\n",
    "- Reduce memory footprint\n",
    "- Apply advanced optimization techniques\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Performance optimization is crucial for:\n",
    "- **Training speed**: Faster iterations and experimentation\n",
    "- **Memory efficiency**: Handling larger models and datasets\n",
    "- **Inference latency**: Real-time applications\n",
    "- **Scalability**: Deploying to production systems\n",
    "\n",
    "BrainState/JAX provides powerful tools for optimization through functional transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainstate as bst\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from typing import Dict, Callable, Any, Tuple\n",
    "from functools import partial\n",
    "\n",
    "bst.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Performance Profiling\n",
    "\n",
    "### 1.1 Basic Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    \"\"\"Simple context manager for timing code blocks.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"Block\"):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        self.elapsed = None\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start_time = time.time()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        self.elapsed = time.time() - self.start_time\n",
    "        print(f\"{self.name}: {self.elapsed:.4f} seconds\")\n",
    "\n",
    "# Example usage\n",
    "def expensive_operation():\n",
    "    x = bst.random.randn(1000, 1000)\n",
    "    return jnp.linalg.svd(x)\n",
    "\n",
    "with Timer(\"SVD computation\"):\n",
    "    result = expensive_operation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Benchmarking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(func: Callable, *args, num_runs: int = 100, warmup: int = 10, **kwargs) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Benchmark a function.\n",
    "    \n",
    "    Args:\n",
    "        func: Function to benchmark\n",
    "        *args: Positional arguments\n",
    "        num_runs: Number of runs for benchmarking\n",
    "        warmup: Number of warmup runs\n",
    "        **kwargs: Keyword arguments\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with timing statistics\n",
    "    \"\"\"\n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = func(*args, **kwargs)\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    for _ in range(num_runs):\n",
    "        start = time.time()\n",
    "        _ = func(*args, **kwargs)\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    times = np.array(times)\n",
    "    return {\n",
    "        'mean': np.mean(times),\n",
    "        'std': np.std(times),\n",
    "        'min': np.min(times),\n",
    "        'max': np.max(times),\n",
    "        'median': np.median(times),\n",
    "        'p95': np.percentile(times, 95),\n",
    "        'p99': np.percentile(times, 99),\n",
    "    }\n",
    "\n",
    "# Example: Compare matrix multiplication implementations\n",
    "def matmul_numpy(a, b):\n",
    "    return np.matmul(a, b)\n",
    "\n",
    "def matmul_jax(a, b):\n",
    "    return jnp.matmul(a, b)\n",
    "\n",
    "a_np = np.random.randn(500, 500)\n",
    "b_np = np.random.randn(500, 500)\n",
    "a_jax = jnp.array(a_np)\n",
    "b_jax = jnp.array(b_np)\n",
    "\n",
    "print(\"Matrix Multiplication Benchmark (500x500)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "numpy_stats = benchmark(matmul_numpy, a_np, b_np, num_runs=50)\n",
    "print(f\"NumPy:  {numpy_stats['mean']*1000:.2f} ± {numpy_stats['std']*1000:.2f} ms\")\n",
    "\n",
    "jax_stats = benchmark(matmul_jax, a_jax, b_jax, num_runs=50)\n",
    "print(f\"JAX:    {jax_stats['mean']*1000:.2f} ± {jax_stats['std']*1000:.2f} ms\")\n",
    "\n",
    "speedup = numpy_stats['mean'] / jax_stats['mean']\n",
    "print(f\"\\nSpeedup: {speedup:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Profiling Model Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(bst.graph.Node):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = bst.nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = bst.nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = bst.nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = jax.nn.relu(self.fc1(x))\n",
    "        x = jax.nn.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Create model\n",
    "model = SimpleModel(784, 512, 10)\n",
    "x = bst.random.randn(128, 784)\n",
    "_ = model(x)  # Initialize\n",
    "\n",
    "# Profile different configurations\n",
    "print(\"Model Forward Pass Profiling\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "batch_sizes = [1, 16, 32, 64, 128, 256]\n",
    "results = []\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    x_test = bst.random.randn(bs, 784)\n",
    "    stats = benchmark(model, x_test, num_runs=50)\n",
    "    results.append(stats['mean'])\n",
    "    throughput = bs / stats['mean']\n",
    "    print(f\"Batch size {bs:3d}: {stats['mean']*1000:6.2f} ms, \"\n",
    "          f\"Throughput: {throughput:8.1f} samples/sec\")\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(batch_sizes, [r*1000 for r in results], 'o-', linewidth=2)\n",
    "ax1.set_xlabel('Batch Size')\n",
    "ax1.set_ylabel('Latency (ms)')\n",
    "ax1.set_title('Forward Pass Latency')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "throughputs = [bs/t for bs, t in zip(batch_sizes, results)]\n",
    "ax2.plot(batch_sizes, throughputs, 's-', linewidth=2, color='green')\n",
    "ax2.set_xlabel('Batch Size')\n",
    "ax2.set_ylabel('Throughput (samples/sec)')\n",
    "ax2.set_title('Throughput vs Batch Size')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. JIT Compilation Optimization\n",
    "\n",
    "### 2.1 JIT vs Non-JIT Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"JIT Compilation Impact\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a moderately complex function\n",
    "def complex_computation(x):\n",
    "    for _ in range(10):\n",
    "        x = jnp.tanh(x)\n",
    "        x = jnp.matmul(x, x.T)\n",
    "        x = jnp.maximum(x, 0)\n",
    "    return jnp.sum(x)\n",
    "\n",
    "# JIT version\n",
    "complex_computation_jit = jax.jit(complex_computation)\n",
    "\n",
    "# Test data\n",
    "x_test = bst.random.randn(100, 100)\n",
    "\n",
    "# Benchmark\n",
    "print(\"\\nBenchmarking (100x100 matrix):\")\n",
    "no_jit_stats = benchmark(complex_computation, x_test, num_runs=20)\n",
    "print(f\"Without JIT: {no_jit_stats['mean']*1000:.2f} ± {no_jit_stats['std']*1000:.2f} ms\")\n",
    "\n",
    "jit_stats = benchmark(complex_computation_jit, x_test, num_runs=20)\n",
    "print(f\"With JIT:    {jit_stats['mean']*1000:.2f} ± {jit_stats['std']*1000:.2f} ms\")\n",
    "\n",
    "speedup = no_jit_stats['mean'] / jit_stats['mean']\n",
    "print(f\"\\nSpeedup: {speedup:.1f}x\")\n",
    "print(f\"\\n⚡ JIT compilation can provide {speedup:.1f}x speedup!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Static vs Dynamic Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Static vs Dynamic Arguments in JIT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Function with both static and dynamic args\n",
    "def power_sum(x, n):\n",
    "    \"\"\"Compute sum of x raised to power n.\"\"\"\n",
    "    return jnp.sum(x ** n)\n",
    "\n",
    "# WRONG: Treating n as dynamic causes recompilation\n",
    "power_sum_jit_wrong = jax.jit(power_sum)\n",
    "\n",
    "# CORRECT: Mark n as static\n",
    "power_sum_jit_correct = jax.jit(power_sum, static_argnums=(1,))\n",
    "\n",
    "x = bst.random.randn(1000, 1000)\n",
    "\n",
    "print(\"\\nWrong approach (n as dynamic):\")\n",
    "for n in [2, 3, 4]:\n",
    "    with Timer(f\"  n={n}\"):\n",
    "        _ = power_sum_jit_wrong(x, n)\n",
    "        # Each call with different n causes recompilation!\n",
    "\n",
    "print(\"\\nCorrect approach (n as static):\")\n",
    "for n in [2, 3, 4]:\n",
    "    with Timer(f\"  n={n}\"):\n",
    "        _ = power_sum_jit_correct(x, n)\n",
    "        # Recompiles once per unique n value, then caches\n",
    "\n",
    "print(\"\\n✓ Use static_argnums for arguments that determine control flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 JIT Compilation Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"JIT Best Practices\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. JIT the outermost function\n",
    "print(\"\\n1. JIT the outermost function:\")\n",
    "\n",
    "# ❌ BAD: JIT inner functions\n",
    "def bad_approach(x):\n",
    "    @jax.jit\n",
    "    def inner1(y):\n",
    "        return jnp.sin(y)\n",
    "    \n",
    "    @jax.jit\n",
    "    def inner2(y):\n",
    "        return jnp.cos(y)\n",
    "    \n",
    "    return inner1(x) + inner2(x)\n",
    "\n",
    "# ✓ GOOD: JIT the outer function\n",
    "@jax.jit\n",
    "def good_approach(x):\n",
    "    def inner1(y):\n",
    "        return jnp.sin(y)\n",
    "    \n",
    "    def inner2(y):\n",
    "        return jnp.cos(y)\n",
    "    \n",
    "    return inner1(x) + inner2(x)\n",
    "\n",
    "x = bst.random.randn(1000)\n",
    "bad_stats = benchmark(bad_approach, x, num_runs=50)\n",
    "good_stats = benchmark(good_approach, x, num_runs=50)\n",
    "\n",
    "print(f\"Bad approach:  {bad_stats['mean']*1000:.3f} ms\")\n",
    "print(f\"Good approach: {good_stats['mean']*1000:.3f} ms\")\n",
    "print(f\"Speedup: {bad_stats['mean']/good_stats['mean']:.1f}x\")\n",
    "\n",
    "# 2. Avoid Python control flow inside JIT\n",
    "print(\"\\n2. Avoid Python control flow (use JAX control flow):\")\n",
    "print(\"❌ BAD: if/for with dynamic values\")\n",
    "print(\"✓ GOOD: jax.lax.cond, jax.lax.fori_loop\")\n",
    "\n",
    "# 3. Minimize data transfer\n",
    "print(\"\\n3. Minimize host-device data transfer:\")\n",
    "print(\"✓ Keep data on device as long as possible\")\n",
    "print(\"✓ Use jnp arrays, not numpy arrays inside JIT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory Optimization\n",
    "\n",
    "### 3.1 Memory Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_model_memory(model: bst.graph.Node) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Estimate memory usage of a model.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with memory estimates in MB\n",
    "    \"\"\"\n",
    "    params = model.states(bst.ParamState)\n",
    "    \n",
    "    # Calculate parameter memory\n",
    "    param_memory = sum(p.value.nbytes for p in params.values())\n",
    "    \n",
    "    # Calculate state memory (non-param states)\n",
    "    all_states = model.states()\n",
    "    state_memory = sum(\n",
    "        s.value.nbytes for s in all_states.values() \n",
    "        if s not in params.values()\n",
    "    )\n",
    "    \n",
    "    total_memory = param_memory + state_memory\n",
    "    \n",
    "    return {\n",
    "        'parameters_mb': param_memory / 1024 / 1024,\n",
    "        'states_mb': state_memory / 1024 / 1024,\n",
    "        'total_mb': total_memory / 1024 / 1024,\n",
    "        'num_parameters': sum(p.value.size for p in params.values())\n",
    "    }\n",
    "\n",
    "# Analyze model memory\n",
    "model = SimpleModel(784, 512, 10)\n",
    "x = bst.random.randn(1, 784)\n",
    "_ = model(x)\n",
    "\n",
    "mem_info = estimate_model_memory(model)\n",
    "print(\"Model Memory Usage\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Parameters:        {mem_info['parameters_mb']:.2f} MB\")\n",
    "print(f\"States:            {mem_info['states_mb']:.2f} MB\")\n",
    "print(f\"Total:             {mem_info['total_mb']:.2f} MB\")\n",
    "print(f\"Number of params:  {mem_info['num_parameters']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Checkpointing for Memory Efficiency\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Without checkpointing: stores all intermediate activations\n",
    "def deep_network_no_checkpoint(x, weights):\n",
    "    \"\"\"Deep network without checkpointing.\"\"\"\n",
    "    for w in weights:\n",
    "        x = jnp.tanh(jnp.matmul(x, w))\n",
    "    return jnp.sum(x)\n",
    "\n",
    "# With checkpointing: recomputes activations during backward pass\n",
    "def deep_network_with_checkpoint(x, weights):\n",
    "    \"\"\"Deep network with checkpointing.\"\"\"\n",
    "    for w in weights:\n",
    "        # Use checkpoint to save memory\n",
    "        x = jax.checkpoint(lambda y, w: jnp.tanh(jnp.matmul(y, w)))(x, w)\n",
    "    return jnp.sum(x)\n",
    "\n",
    "# Create deep network (many layers)\n",
    "num_layers = 50\n",
    "layer_size = 100\n",
    "weights = [bst.random.randn(layer_size, layer_size) * 0.01 for _ in range(num_layers)]\n",
    "x_input = bst.random.randn(10, layer_size)\n",
    "\n",
    "print(f\"\\nDeep network: {num_layers} layers, {layer_size}x{layer_size} each\")\n",
    "print(\"\\nWithout checkpointing:\")\n",
    "print(\"  Memory: High (stores all activations)\")\n",
    "print(\"  Speed: Fast (forward and backward)\")\n",
    "\n",
    "print(\"\\nWith checkpointing:\")\n",
    "print(\"  Memory: Low (recomputes activations)\")\n",
    "print(\"  Speed: Slower (recomputation overhead)\")\n",
    "\n",
    "# Benchmark gradient computation\n",
    "grad_no_cp = jax.grad(lambda x: deep_network_no_checkpoint(x, weights))\n",
    "grad_with_cp = jax.grad(lambda x: deep_network_with_checkpoint(x, weights))\n",
    "\n",
    "print(\"\\nGradient computation time:\")\n",
    "stats_no_cp = benchmark(grad_no_cp, x_input, num_runs=10)\n",
    "print(f\"  No checkpoint:   {stats_no_cp['mean']*1000:.2f} ms\")\n",
    "\n",
    "stats_cp = benchmark(grad_with_cp, x_input, num_runs=10)\n",
    "print(f\"  With checkpoint: {stats_cp['mean']*1000:.2f} ms\")\n",
    "\n",
    "print(f\"\\nTradeoff: {stats_cp['mean']/stats_no_cp['mean']:.1f}x slower, but uses less memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Mixed Precision Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mixed Precision Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Full precision (float32)\n",
    "def model_fp32(x, w):\n",
    "    return jnp.matmul(x.astype(jnp.float32), w.astype(jnp.float32))\n",
    "\n",
    "# Half precision (float16) - faster but less precise\n",
    "def model_fp16(x, w):\n",
    "    result = jnp.matmul(x.astype(jnp.float16), w.astype(jnp.float16))\n",
    "    return result.astype(jnp.float32)  # Cast back to fp32\n",
    "\n",
    "# Test data\n",
    "x = bst.random.randn(1000, 1000)\n",
    "w = bst.random.randn(1000, 1000)\n",
    "\n",
    "# Memory comparison\n",
    "fp32_memory = x.astype(jnp.float32).nbytes + w.astype(jnp.float32).nbytes\n",
    "fp16_memory = x.astype(jnp.float16).nbytes + w.astype(jnp.float16).nbytes\n",
    "\n",
    "print(\"\\nMemory Usage:\")\n",
    "print(f\"FP32: {fp32_memory / 1024 / 1024:.2f} MB\")\n",
    "print(f\"FP16: {fp16_memory / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Memory savings: {(1 - fp16_memory/fp32_memory)*100:.1f}%\")\n",
    "\n",
    "# Speed comparison\n",
    "print(\"\\nSpeed Comparison:\")\n",
    "fp32_stats = benchmark(model_fp32, x, w, num_runs=20)\n",
    "print(f\"FP32: {fp32_stats['mean']*1000:.2f} ms\")\n",
    "\n",
    "fp16_stats = benchmark(model_fp16, x, w, num_runs=20)\n",
    "print(f\"FP16: {fp16_stats['mean']*1000:.2f} ms\")\n",
    "print(f\"Speedup: {fp32_stats['mean']/fp16_stats['mean']:.2f}x\")\n",
    "\n",
    "# Accuracy comparison\n",
    "result_fp32 = model_fp32(x, w)\n",
    "result_fp16 = model_fp16(x, w)\n",
    "error = jnp.abs(result_fp32 - result_fp16).max()\n",
    "print(f\"\\nMax error: {error:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorization with vmap\n",
    "\n",
    "### 4.1 vmap vs Loop Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vectorization with vmap\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Function that operates on single example\n",
    "def process_single(x, w):\n",
    "    return jnp.tanh(jnp.dot(x, w))\n",
    "\n",
    "# Process batch with Python loop\n",
    "def process_batch_loop(batch, w):\n",
    "    results = []\n",
    "    for x in batch:\n",
    "        results.append(process_single(x, w))\n",
    "    return jnp.stack(results)\n",
    "\n",
    "# Process batch with vmap\n",
    "process_batch_vmap = jax.vmap(process_single, in_axes=(0, None))\n",
    "\n",
    "# Test data\n",
    "batch = bst.random.randn(100, 128)\n",
    "w = bst.random.randn(128, 64)\n",
    "\n",
    "print(\"\\nProcessing 100 samples:\")\n",
    "\n",
    "loop_stats = benchmark(process_batch_loop, batch, w, num_runs=50)\n",
    "print(f\"Loop:  {loop_stats['mean']*1000:.2f} ms\")\n",
    "\n",
    "vmap_stats = benchmark(process_batch_vmap, batch, w, num_runs=50)\n",
    "print(f\"vmap:  {vmap_stats['mean']*1000:.2f} ms\")\n",
    "\n",
    "speedup = loop_stats['mean'] / vmap_stats['mean']\n",
    "print(f\"\\nSpeedup: {speedup:.1f}x\")\n",
    "print(f\"\\n⚡ vmap provides automatic vectorization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Nested vmap for Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nested vmap Example\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Function for single pair of vectors\n",
    "def pairwise_distance(x, y):\n",
    "    return jnp.sqrt(jnp.sum((x - y) ** 2))\n",
    "\n",
    "# Compute all pairwise distances\n",
    "# First vmap over x, second vmap over y\n",
    "pairwise_distances = jax.vmap(\n",
    "    jax.vmap(pairwise_distance, in_axes=(None, 0)),\n",
    "    in_axes=(0, None)\n",
    ")\n",
    "\n",
    "# Test\n",
    "X = bst.random.randn(50, 10)  # 50 points in 10D\n",
    "Y = bst.random.randn(30, 10)  # 30 points in 10D\n",
    "\n",
    "distances = pairwise_distances(X, Y)\n",
    "print(f\"Input shapes: X={X.shape}, Y={Y.shape}\")\n",
    "print(f\"Distance matrix shape: {distances.shape}\")\n",
    "print(f\"Expected: (50, 30) ✓\")\n",
    "\n",
    "# Benchmark\n",
    "stats = benchmark(pairwise_distances, X, Y, num_runs=50)\n",
    "print(f\"\\nComputed {distances.size} distances in {stats['mean']*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parallel Processing Strategies\n",
    "\n",
    "### 5.1 pmap for Multi-Device Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parallel Processing with pmap\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check available devices\n",
    "devices = jax.devices()\n",
    "print(f\"\\nAvailable devices: {len(devices)}\")\n",
    "for i, device in enumerate(devices):\n",
    "    print(f\"  Device {i}: {device}\")\n",
    "\n",
    "if len(devices) > 1:\n",
    "    print(\"\\nUsing pmap for multi-device parallelism:\")\n",
    "    \n",
    "    # Function to process on single device\n",
    "    def train_step(batch):\n",
    "        return jnp.sum(batch ** 2)\n",
    "    \n",
    "    # Parallelize across devices\n",
    "    train_step_pmap = jax.pmap(train_step)\n",
    "    \n",
    "    # Create data sharded across devices\n",
    "    num_devices = len(devices)\n",
    "    batch_per_device = 32\n",
    "    data = bst.random.randn(num_devices, batch_per_device, 100)\n",
    "    \n",
    "    # Process in parallel\n",
    "    results = train_step_pmap(data)\n",
    "    print(f\"Results shape: {results.shape}\")\n",
    "    print(f\"One result per device: {len(results)} results\")\nelse:\n",
    "    print(\"\\nSingle device detected. pmap would replicate computation.\")\n",
    "    print(\"In production with multiple GPUs/TPUs, pmap enables:\")\n",
    "    print(\"  - Data parallelism\")\n",
    "    print(\"  - Model parallelism\")\n",
    "    print(\"  - Pipeline parallelism\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Batch Size Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finding Optimal Batch Size\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model = SimpleModel(784, 256, 10)\n",
    "x_init = bst.random.randn(1, 784)\n",
    "_ = model(x_init)\n",
    "\n",
    "# Test different batch sizes\n",
    "batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "throughputs = []\n",
    "latencies = []\n",
    "\n",
    "print(\"\\nBatch Size Analysis:\")\n",
    "print(f\"{'Batch Size':<12} {'Latency (ms)':<15} {'Throughput':<20} {'Efficiency'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    x = bst.random.randn(bs, 784)\n",
    "    stats = benchmark(model, x, num_runs=30, warmup=5)\n",
    "    \n",
    "    latency = stats['mean'] * 1000  # ms\n",
    "    throughput = bs / stats['mean']  # samples/sec\n",
    "    efficiency = throughput / bs  # normalized throughput\n",
    "    \n",
    "    latencies.append(latency)\n",
    "    throughputs.append(throughput)\n",
    "    \n",
    "    print(f\"{bs:<12} {latency:<15.2f} {throughput:<20.1f} {efficiency:.3f}\")\n",
    "\n",
    "# Find optimal batch size (highest throughput)\n",
    "optimal_idx = np.argmax(throughputs)\n",
    "optimal_bs = batch_sizes[optimal_idx]\n",
    "print(f\"\\n✓ Optimal batch size: {optimal_bs}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(batch_sizes, throughputs, 'o-', linewidth=2, markersize=8)\n",
    "ax.axvline(optimal_bs, color='red', linestyle='--', alpha=0.7, \n",
    "           label=f'Optimal: {optimal_bs}')\n",
    "ax.set_xlabel('Batch Size')\n",
    "ax.set_ylabel('Throughput (samples/sec)')\n",
    "ax.set_title('Throughput vs Batch Size')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Optimization Techniques\n",
    "\n",
    "### 6.1 Fused Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fused Operations for Better Performance\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "x = bst.random.randn(1000, 1000)\n",
    "w = bst.random.randn(1000, 1000)\n",
    "b = bst.random.randn(1000)\n",
    "\n",
    "# Unfused: multiple operations\n",
    "def unfused_linear(x, w, b):\n",
    "    temp = jnp.matmul(x, w)\n",
    "    temp = temp + b\n",
    "    temp = jax.nn.relu(temp)\n",
    "    return temp\n",
    "\n",
    "# Fused: combined into single operation\n",
    "def fused_linear(x, w, b):\n",
    "    return jax.nn.relu(jnp.matmul(x, w) + b)\n",
    "\n",
    "# JIT will automatically fuse operations\n",
    "unfused_jit = jax.jit(unfused_linear)\n",
    "fused_jit = jax.jit(fused_linear)\n",
    "\n",
    "print(\"\\nOperation fusion (with JIT):\")\n",
    "unfused_stats = benchmark(unfused_jit, x, w, b, num_runs=50)\n",
    "print(f\"Unfused: {unfused_stats['mean']*1000:.2f} ms\")\n",
    "\n",
    "fused_stats = benchmark(fused_jit, x, w, b, num_runs=50)\n",
    "print(f\"Fused:   {fused_stats['mean']*1000:.2f} ms\")\n",
    "\n",
    "print(\"\\n✓ JIT compiler automatically fuses operations\")\n",
    "print(\"  Write clean code; let JIT optimize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Efficient Scanning with lax.scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Efficient Loops with lax.scan\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Inefficient: Python loop (can't JIT well)\n",
    "def rnn_loop_python(inputs, h0, w_h, w_x):\n",
    "    h = h0\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        h = jnp.tanh(jnp.dot(h, w_h) + jnp.dot(x, w_x))\n",
    "        outputs.append(h)\n",
    "    return jnp.stack(outputs), h\n",
    "\n",
    "# Efficient: lax.scan\n",
    "def rnn_scan(inputs, h0, w_h, w_x):\n",
    "    def step(h, x):\n",
    "        h_new = jnp.tanh(jnp.dot(h, w_h) + jnp.dot(x, w_x))\n",
    "        return h_new, h_new\n",
    "    \n",
    "    final_h, outputs = jax.lax.scan(step, h0, inputs)\n",
    "    return outputs, final_h\n",
    "\n",
    "# Test data\n",
    "seq_length = 100\n",
    "hidden_size = 128\n",
    "input_size = 64\n",
    "\n",
    "inputs = bst.random.randn(seq_length, input_size)\n",
    "h0 = bst.random.randn(hidden_size)\n",
    "w_h = bst.random.randn(hidden_size, hidden_size) * 0.01\n",
    "w_x = bst.random.randn(input_size, hidden_size) * 0.01\n",
    "\n",
    "print(f\"\\nProcessing sequence of length {seq_length}:\")\n",
    "\n",
    "# Note: Python loop version is slow to compile with JIT\n",
    "scan_jit = jax.jit(rnn_scan, static_argnums=())\n",
    "\n",
    "# Warmup\n",
    "_ = scan_jit(inputs, h0, w_h, w_x)\n",
    "\n",
    "scan_stats = benchmark(scan_jit, inputs, h0, w_h, w_x, num_runs=30)\n",
    "print(f\"lax.scan: {scan_stats['mean']*1000:.2f} ms\")\n",
    "\n",
    "print(\"\\n✓ lax.scan is the idiomatic way to write loops in JAX\")\n",
    "print(\"  Benefits:\")\n",
    "print(\"  - JIT-friendly\")\n",
    "print(\"  - Constant memory (doesn't accumulate)\")\n",
    "print(\"  - Fast compilation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Checklist\n",
    "\n",
    "### Summary of Optimization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance Optimization Checklist\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "checklist = [\n",
    "    (\"✓\", \"Use @jax.jit or @bst.transform.jit for performance-critical code\"),\n",
    "    (\"✓\", \"Mark control-flow arguments as static (static_argnums)\"),\n",
    "    (\"✓\", \"Use vmap instead of Python loops for batch processing\"),\n",
    "    (\"✓\", \"Use lax.scan for sequential operations\"),\n",
    "    (\"✓\", \"Profile code to identify bottlenecks\"),\n",
    "    (\"✓\", \"Choose appropriate batch sizes (benchmark different sizes)\"),\n",
    "    (\"✓\", \"Consider mixed precision (FP16) for memory/speed\"),\n",
    "    (\"✓\", \"Use gradient checkpointing for very deep networks\"),\n",
    "    (\"✓\", \"Minimize host-device data transfers\"),\n",
    "    (\"✓\", \"Use pmap for multi-device parallelism when available\"),\n",
    "    (\"✓\", \"Avoid unnecessary data copies (use views when possible)\"),\n",
    "    (\"✓\", \"Fuse operations (let JIT compiler optimize)\"),\n",
    "    (\"✓\", \"Reuse compiled functions (avoid recompilation)\"),\n",
    "    (\"✓\", \"Monitor memory usage and optimize state management\"),\n",
    "]\n",
    "\n",
    "for check, item in checklist:\n",
    "    print(f\"{check} {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Performance Tips by Priority:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "priorities = [\n",
    "    (\"High\", \"JIT compilation\", \"5-100x speedup\"),\n",
    "    (\"High\", \"Vectorization (vmap)\", \"10-100x speedup\"),\n",
    "    (\"High\", \"Batch size optimization\", \"2-5x speedup\"),\n",
    "    (\"Medium\", \"Mixed precision\", \"1.5-2x speedup, 50% memory\"),\n",
    "    (\"Medium\", \"Gradient checkpointing\", \"50% memory, -20% speed\"),\n",
    "    (\"Medium\", \"lax.scan for loops\", \"2-10x speedup\"),\n",
    "    (\"Low\", \"Multi-device (pmap)\", \"Nx speedup (N devices)\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Priority':<10} {'Technique':<30} {'Impact':<20}\")\n",
    "print(\"-\" * 60)\n",
    "for priority, technique, impact in priorities:\n",
    "    print(f\"{priority:<10} {technique:<30} {impact:<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we covered:\n",
    "\n",
    "1. **Performance Profiling**:\n",
    "   - Timing and benchmarking functions\n",
    "   - Model memory estimation\n",
    "   - Identifying bottlenecks\n",
    "\n",
    "2. **JIT Compilation**:\n",
    "   - JIT vs non-JIT comparison\n",
    "   - Static vs dynamic arguments\n",
    "   - Best practices for JIT\n",
    "\n",
    "3. **Memory Optimization**:\n",
    "   - Memory profiling\n",
    "   - Gradient checkpointing\n",
    "   - Mixed precision training\n",
    "\n",
    "4. **Vectorization**:\n",
    "   - vmap for batch processing\n",
    "   - Nested vmap\n",
    "   - Performance gains\n",
    "\n",
    "5. **Parallel Processing**:\n",
    "   - pmap for multi-device\n",
    "   - Batch size optimization\n",
    "   - Throughput analysis\n",
    "\n",
    "6. **Advanced Techniques**:\n",
    "   - Fused operations\n",
    "   - Efficient scanning with lax.scan\n",
    "   - Performance checklist\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- **Always use JIT** for production code (5-100x speedup)\n",
    "- **Vectorize with vmap** instead of Python loops\n",
    "- **Profile before optimizing** to find real bottlenecks\n",
    "- **Batch size matters** - benchmark to find optimal\n",
    "- **Trade memory for speed** with checkpointing when needed\n",
    "- **Use lax.scan** for sequential operations\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Profile your own models\n",
    "- Experiment with different optimization techniques\n",
    "- Monitor performance in production\n",
    "- Learn advanced JAX transformations\n",
    "\n",
    "For more information:\n",
    "- [JAX Performance Tips](https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html)\n",
    "- [BrainState Documentation](https://brainstate.readthedocs.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
