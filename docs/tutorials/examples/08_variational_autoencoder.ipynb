{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_header",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE) on MNIST\n",
    "\n",
    "This tutorial demonstrates how to build and train a **Variational Autoencoder (VAE)** using BrainState. VAEs are powerful generative models that learn to encode data into a latent space and decode it back, enabling both reconstruction and generation of new samples.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand the theory behind Variational Autoencoders\n",
    "- Build encoder and decoder networks in BrainState\n",
    "- Implement the VAE loss function (reconstruction + KL divergence)\n",
    "- Train a VAE on MNIST dataset\n",
    "- Generate new handwritten digits\n",
    "- Visualize the latent space\n",
    "\n",
    "## What is a Variational Autoencoder?\n",
    "\n",
    "A VAE consists of two main components:\n",
    "\n",
    "1. **Encoder**: Maps input data `x` to latent representation `z`\n",
    "   - Outputs mean `μ` and standard deviation `σ` of latent distribution\n",
    "   - Uses **reparameterization trick**: `z = μ + σ * ε`, where `ε ~ N(0,1)`\n",
    "\n",
    "2. **Decoder**: Reconstructs input from latent code `z`\n",
    "   - Maps `z` back to data space\n",
    "   - Outputs reconstruction `x̂`\n",
    "\n",
    "**Loss Function**:\n",
    "```\n",
    "Loss = Reconstruction Loss + β * KL Divergence\n",
    "```\n",
    "- **Reconstruction Loss**: How well we reconstruct the input\n",
    "- **KL Divergence**: Regularizes latent space to be close to N(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax  # For loss functions\n",
    "from datasets import load_dataset\n",
    "\n",
    "import brainstate\n",
    "import braintools\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "brainstate.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Configuration and Dataset\n",
    "\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hyperparams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "latent_size = 32          # Dimension of latent space\n",
    "hidden_size = 256         # Hidden layer size\n",
    "image_shape = (28, 28)    # MNIST image shape\n",
    "\n",
    "# Training configuration\n",
    "batch_size = 64\n",
    "steps_per_epoch = 200\n",
    "epochs = 20\n",
    "learning_rate = 1e-3\n",
    "kl_weight = 0.1           # β parameter for KL divergence\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Latent dimension: {latent_size}\")\n",
    "print(f\"  Hidden size: {hidden_size}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Epochs: {epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading",
   "metadata": {},
   "source": [
    "### Load and Preprocess MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "print(\"Loading MNIST dataset...\")\n",
    "dataset = load_dataset('mnist')\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(np.stack(dataset['train']['image']), dtype=np.uint8)\n",
    "X_test = np.array(np.stack(dataset['test']['image']), dtype=np.uint8)\n",
    "\n",
    "# Binarize data (threshold at 0)\n",
    "X_train = (X_train > 0).astype(jnp.float32)\n",
    "X_test = (X_test > 0).astype(jnp.float32)\n",
    "\n",
    "print(f\"\\nDataset loaded:\")\n",
    "print(f\"  Training samples: {X_train.shape[0]}\")\n",
    "print(f\"  Test samples: {X_test.shape[0]}\")\n",
    "print(f\"  Image shape: {X_train.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Training Images (Binarized)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_definition",
   "metadata": {},
   "source": [
    "## Building the VAE\n",
    "\n",
    "### Custom State for Loss Tracking\n",
    "\n",
    "We'll create a custom state type to track the KL divergence loss within the encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loss_state",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(brainstate.State):\n",
    "    \"\"\"Custom state for tracking loss components.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encoder_section",
   "metadata": {},
   "source": [
    "### Encoder Network\n",
    "\n",
    "The encoder maps images to latent distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encoder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(brainstate.nn.Module):\n",
    "    \"\"\"Encoder network for VAE.\n",
    "    \n",
    "    Maps input images to latent distribution parameters (mean and std).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, din: int, dmid: int, dout: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Shared hidden layer\n",
    "        self.linear1 = brainstate.nn.Linear(din, dmid)\n",
    "        \n",
    "        # Separate heads for mean and log-variance\n",
    "        self.linear_mean = brainstate.nn.Linear(dmid, dout)\n",
    "        self.linear_std = brainstate.nn.Linear(dmid, dout)\n",
    "    \n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        \"\"\"Encode input to latent representation.\n",
    "        \n",
    "        Args:\n",
    "            x: Input images [batch, height, width]\n",
    "            \n",
    "        Returns:\n",
    "            z: Latent codes [batch, latent_dim]\n",
    "        \"\"\"\n",
    "        # Flatten input\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        \n",
    "        # Shared hidden layer with ReLU\n",
    "        x = self.linear1(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        \n",
    "        # Compute mean and std of latent distribution\n",
    "        mean = self.linear_mean(x)\n",
    "        log_std = self.linear_std(x)\n",
    "        std = jnp.exp(log_std)  # Ensure std > 0\n",
    "        \n",
    "        # Compute KL divergence: KL(N(μ,σ²) || N(0,1))\n",
    "        # KL = 0.5 * (μ² + σ² - log(σ²) - 1)\n",
    "        kl_loss = 0.5 * jnp.mean(\n",
    "            -jnp.log(std ** 2) - 1.0 + std ** 2 + mean ** 2, \n",
    "            axis=-1\n",
    "        )\n",
    "        \n",
    "        # Store KL loss in state for later retrieval\n",
    "        self.kl_loss = Loss(jnp.mean(kl_loss))\n",
    "        \n",
    "        # Reparameterization trick: z = μ + σ * ε, where ε ~ N(0,1)\n",
    "        epsilon = brainstate.random.normal(size=mean.shape)\n",
    "        z = mean + std * epsilon\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decoder_section",
   "metadata": {},
   "source": [
    "### Decoder Network\n",
    "\n",
    "The decoder reconstructs images from latent codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decoder",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(brainstate.nn.Module):\n",
    "    \"\"\"Decoder network for VAE.\n",
    "    \n",
    "    Maps latent codes back to image space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, din: int, dmid: int, dout: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = brainstate.nn.Linear(din, dmid)\n",
    "        self.linear2 = brainstate.nn.Linear(dmid, dout)\n",
    "    \n",
    "    def __call__(self, z: jax.Array) -> jax.Array:\n",
    "        \"\"\"Decode latent code to reconstruction.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent codes [batch, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            logits: Reconstruction logits [batch, height * width]\n",
    "        \"\"\"\n",
    "        # Hidden layer with ReLU\n",
    "        z = self.linear1(z)\n",
    "        z = jax.nn.relu(z)\n",
    "        \n",
    "        # Output layer (logits for binary cross-entropy)\n",
    "        logits = self.linear2(z)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vae_section",
   "metadata": {},
   "source": [
    "### Complete VAE Model\n",
    "\n",
    "Combine encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(brainstate.nn.Module):\n",
    "    \"\"\"Variational Autoencoder.\n",
    "    \n",
    "    Combines encoder and decoder for generative modeling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        din: int,\n",
    "        hidden_size: int,\n",
    "        latent_size: int,\n",
    "        output_shape: tp.Sequence[int],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        # Create encoder and decoder\n",
    "        self.encoder = Encoder(din, hidden_size, latent_size)\n",
    "        self.decoder = Decoder(\n",
    "            latent_size, \n",
    "            hidden_size, \n",
    "            int(np.prod(output_shape))\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        \"\"\"Forward pass: encode then decode.\n",
    "        \n",
    "        Args:\n",
    "            x: Input images [batch, height, width]\n",
    "            \n",
    "        Returns:\n",
    "            logits: Reconstruction logits [batch, height, width]\n",
    "        \"\"\"\n",
    "        # Encode to latent space\n",
    "        z = self.encoder(x)\n",
    "        \n",
    "        # Decode to reconstruction\n",
    "        logits = self.decoder(z)\n",
    "        \n",
    "        # Reshape to image dimensions\n",
    "        logits = jnp.reshape(logits, (-1, *self.output_shape))\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def generate(self, z: jax.Array) -> jax.Array:\n",
    "        \"\"\"Generate images from latent codes.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent codes [batch, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            images: Generated images [batch, height, width]\n",
    "        \"\"\"\n",
    "        logits = self.decoder(z)\n",
    "        logits = jnp.reshape(logits, (-1, *self.output_shape))\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        return jax.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instantiate",
   "metadata": {},
   "source": [
    "### Create Model and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAE model\n",
    "model = VAE(\n",
    "    din=int(np.prod(image_shape)),\n",
    "    hidden_size=hidden_size,\n",
    "    latent_size=latent_size,\n",
    "    output_shape=image_shape,\n",
    ")\n",
    "\n",
    "# Create Adam optimizer\n",
    "optimizer = braintools.optim.Adam(lr=learning_rate)\n",
    "optimizer.register_trainable_weights(model.states(brainstate.ParamState))\n",
    "\n",
    "print(\"Model created successfully!\")\n",
    "print(f\"\\nModel architecture:\")\n",
    "print(f\"  Input: {np.prod(image_shape)} -> Encoder -> Latent: {latent_size}\")\n",
    "print(f\"  Latent: {latent_size} -> Decoder -> Output: {np.prod(image_shape)}\")\n",
    "print(f\"\\nTotal parameters: {sum(x.size for x in jax.tree.leaves(model.states(brainstate.ParamState).to_dict_values())):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training_section",
   "metadata": {},
   "source": [
    "## Training the VAE\n",
    "\n",
    "### Define Training Step\n",
    "\n",
    "The loss function combines reconstruction loss and KL divergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_step",
   "metadata": {},
   "outputs": [],
   "source": [
    "@brainstate.transform.jit\n",
    "def train_step(x: jax.Array):\n",
    "    \"\"\"Perform one training step.\n",
    "    \n",
    "    Args:\n",
    "        x: Batch of images [batch, height, width]\n",
    "        \n",
    "    Returns:\n",
    "        loss: Total loss value\n",
    "    \"\"\"\n",
    "    def loss_fn():\n",
    "        # Forward pass\n",
    "        logits = model(x)\n",
    "        \n",
    "        # Collect KL losses from encoder\n",
    "        losses = brainstate.graph.treefy_states(model, Loss)\n",
    "        kl_loss = sum(jax.tree_util.tree_leaves(losses), 0.0)\n",
    "        \n",
    "        # Reconstruction loss (binary cross-entropy)\n",
    "        reconstruction_loss = jnp.mean(\n",
    "            optax.sigmoid_binary_cross_entropy(logits, x)\n",
    "        )\n",
    "        \n",
    "        # Total loss = reconstruction + β * KL\n",
    "        total_loss = reconstruction_loss + kl_weight * kl_loss\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    # Compute gradients and update\n",
    "    grads, loss = brainstate.transform.grad(\n",
    "        loss_fn, \n",
    "        optimizer.param_states.to_pytree(), \n",
    "        return_value=True\n",
    "    )()\n",
    "    \n",
    "    optimizer.update(grads)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helper_functions",
   "metadata": {},
   "source": [
    "### Helper Functions for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "@brainstate.transform.jit\n",
    "def forward(x: jax.Array) -> jax.Array:\n",
    "    \"\"\"Forward pass with sigmoid activation.\"\"\"\n",
    "    return jax.nn.sigmoid(model(x))\n",
    "\n",
    "\n",
    "@brainstate.transform.jit\n",
    "def sample(z: jax.Array) -> jax.Array:\n",
    "    \"\"\"Generate samples from latent codes.\"\"\"\n",
    "    return model.generate(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run_training",
   "metadata": {},
   "source": [
    "### Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_losses = []\n",
    "    \n",
    "    for step in range(steps_per_epoch):\n",
    "        # Sample random batch\n",
    "        idxs = np.random.randint(0, len(X_train), size=(batch_size,))\n",
    "        x_batch = X_train[idxs]\n",
    "        \n",
    "        # Train step\n",
    "        loss = train_step(x_batch)\n",
    "        epoch_losses.append(np.asarray(loss))\n",
    "    \n",
    "    # Log progress\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    loss_history.append(avg_loss)\n",
    "    print(f'Epoch {epoch + 1:2d}/{epochs}: Loss = {avg_loss:.4f}')\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot_loss",
   "metadata": {},
   "source": [
    "### Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loss_plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, epochs + 1), loss_history, marker='o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('VAE Training Loss', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation_section",
   "metadata": {},
   "source": [
    "## Evaluation and Visualization\n",
    "\n",
    "### Reconstruction Quality\n",
    "\n",
    "Let's see how well the VAE reconstructs test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random test samples\n",
    "num_samples = 5\n",
    "idxs = np.random.randint(0, len(X_test), size=(num_samples,))\n",
    "x_sample = X_test[idxs]\n",
    "\n",
    "# Get reconstructions\n",
    "y_pred = forward(x_sample)\n",
    "\n",
    "# Plot original vs reconstruction\n",
    "fig, axes = plt.subplots(2, num_samples, figsize=(12, 5))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Original\n",
    "    axes[0, i].imshow(x_sample[i], cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Original', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # Reconstruction\n",
    "    axes[1, i].imshow(y_pred[i], cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Reconstruction', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('VAE Reconstruction Results', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generation_section",
   "metadata": {},
   "source": [
    "### Generate New Samples\n",
    "\n",
    "Sample from the latent space to generate new digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample latent codes from standard normal distribution\n",
    "z_samples = np.random.normal(scale=1.0, size=(12, latent_size))\n",
    "samples = sample(z_samples)\n",
    "\n",
    "# Plot generated samples\n",
    "fig, axes = plt.subplots(2, 6, figsize=(12, 4))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(samples):\n",
    "        ax.imshow(samples[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Generated Samples from VAE', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpolation_section",
   "metadata": {},
   "source": [
    "### Latent Space Interpolation\n",
    "\n",
    "Interpolate between two digits in latent space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two random samples\n",
    "idx1, idx2 = np.random.randint(0, len(X_test), size=2)\n",
    "x1, x2 = X_test[idx1:idx1+1], X_test[idx2:idx2+1]\n",
    "\n",
    "# Encode to latent space (using the mean, no sampling)\n",
    "# We'll do this by calling encoder directly\n",
    "z1 = model.encoder(x1)\n",
    "z2 = model.encoder(x2)\n",
    "\n",
    "# Interpolate in latent space\n",
    "n_steps = 10\n",
    "alphas = np.linspace(0, 1, n_steps)\n",
    "z_interp = jnp.array([alpha * z2 + (1 - alpha) * z1 for alpha in alphas]).squeeze()\n",
    "\n",
    "# Decode interpolated latent codes\n",
    "samples_interp = sample(z_interp)\n",
    "\n",
    "# Plot interpolation\n",
    "fig, axes = plt.subplots(1, n_steps, figsize=(15, 2))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(samples_interp[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        ax.set_title('Start', fontsize=9)\n",
    "    elif i == n_steps - 1:\n",
    "        ax.set_title('End', fontsize=9)\n",
    "\n",
    "plt.suptitle('Latent Space Interpolation', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Key Concepts Summary\n",
    "\n",
    "### VAE Architecture\n",
    "\n",
    "1. **Encoder**:\n",
    "   - Maps input to latent distribution parameters (μ, σ)\n",
    "   - Uses reparameterization trick for backpropagation\n",
    "   - Computes KL divergence as regularization\n",
    "\n",
    "2. **Decoder**:\n",
    "   - Maps latent codes to reconstructions\n",
    "   - Outputs logits (before sigmoid)\n",
    "   - Enables generation from random samples\n",
    "\n",
    "3. **Loss Function**:\n",
    "   - **Reconstruction**: Binary cross-entropy between input and output\n",
    "   - **KL Divergence**: Regularizes latent space to N(0,1)\n",
    "   - **β-VAE**: Weight parameter controls trade-off\n",
    "\n",
    "### BrainState Features Used\n",
    "\n",
    "1. **Custom State Types**: `Loss` state for tracking KL divergence\n",
    "2. **State Management**: Automatic handling via lifted transforms\n",
    "3. **JIT Compilation**: Fast training with `brainstate.transform.jit`\n",
    "4. **Automatic Differentiation**: Gradients with `brainstate.transform.grad`\n",
    "5. **Optimizers**: Adam from BrainTools\n",
    "\n",
    "### Applications of VAEs\n",
    "\n",
    "- **Image Generation**: Creating new, realistic images\n",
    "- **Data Compression**: Compact latent representations\n",
    "- **Anomaly Detection**: Identifying outliers via reconstruction error\n",
    "- **Semi-Supervised Learning**: Using latent structure\n",
    "- **Drug Discovery**: Molecular generation and optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try these to deepen your understanding:\n",
    "\n",
    "1. **Experiment with β**:\n",
    "   - Try different values of `kl_weight` (0.01, 0.1, 1.0)\n",
    "   - Observe effect on reconstruction vs. generation quality\n",
    "\n",
    "2. **Increase Latent Dimension**:\n",
    "   - Change `latent_size` to 64 or 128\n",
    "   - Compare reconstruction quality and training time\n",
    "\n",
    "3. **Convolutional VAE**:\n",
    "   - Replace linear layers with convolutional layers\n",
    "   - Use `brainstate.nn.Conv2d` and `brainstate.nn.ConvTranspose2d`\n",
    "\n",
    "4. **Conditional VAE**:\n",
    "   - Add digit labels as input to encoder and decoder\n",
    "   - Generate specific digits on demand\n",
    "\n",
    "5. **Disentangled Representations**:\n",
    "   - Implement β-VAE with high β (β > 1)\n",
    "   - Visualize individual latent dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've built a VAE, explore:\n",
    "\n",
    "1. **Advanced Generative Models**: GANs, diffusion models\n",
    "2. **Sequence Modeling**: VAEs for time-series data\n",
    "3. **Brain-Inspired Models**: Spiking VAEs\n",
    "4. **Model Deployment**: Save and serve trained VAEs\n",
    "\n",
    "## References\n",
    "\n",
    "- [Auto-Encoding Variational Bayes (Original Paper)](https://arxiv.org/abs/1312.6114)\n",
    "- [Tutorial on VAEs](https://arxiv.org/abs/1606.05908)\n",
    "- [β-VAE Paper](https://openreview.net/forum?id=Sy2fzU9gl)\n",
    "- [BrainState Documentation](https://brainstate.readthedocs.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
