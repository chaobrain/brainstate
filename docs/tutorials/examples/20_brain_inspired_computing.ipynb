{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 20: Brain-Inspired Computing\n",
    "\n",
    "In this tutorial, we'll explore brain-inspired computing models including Spiking Neural Networks (SNNs), neurodynamics, and biologically plausible learning rules.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "- Build Spiking Neural Networks (SNNs)\n",
    "- Implement neuron dynamics models (LIF, AdEx)\n",
    "- Create synaptic plasticity rules (STDP)\n",
    "- Simulate neuronal populations\n",
    "- Visualize spike trains and dynamics\n",
    "- Apply brain-inspired learning rules\n",
    "- Build event-driven computations\n",
    "\n",
    "## What We'll Build\n",
    "\n",
    "We'll create:\n",
    "- Leaky Integrate-and-Fire (LIF) neurons\n",
    "- Spiking neural network layers\n",
    "- Spike-Timing-Dependent Plasticity (STDP)\n",
    "- Population coding models\n",
    "- Complete SNN for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainstate as bst\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "# Set random seed\n",
    "bst.random.seed(42)\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Leaky Integrate-and-Fire (LIF) Neuron\n",
    "\n",
    "The LIF model is one of the most fundamental spiking neuron models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFNeuron(bst.nn.Dynamics):\n",
    "    \"\"\"Leaky Integrate-and-Fire neuron model.\n",
    "    \n",
    "    Dynamics:\n",
    "        tau * dV/dt = -(V - V_rest) + R * I\n",
    "        if V >= V_th: V = V_reset, emit spike\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        size: int,\n",
    "        tau: float = 10.0,      # Membrane time constant (ms)\n",
    "        V_rest: float = -65.0,   # Resting potential (mV)\n",
    "        V_reset: float = -70.0,  # Reset potential (mV)\n",
    "        V_th: float = -50.0,     # Threshold potential (mV)\n",
    "        R: float = 1.0,          # Membrane resistance\n",
    "        dt: float = 0.1,         # Time step (ms)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.tau = tau\n",
    "        self.V_rest = V_rest\n",
    "        self.V_reset = V_reset\n",
    "        self.V_th = V_th\n",
    "        self.R = R\n",
    "        self.dt = dt\n",
    "        \n",
    "        # State variables\n",
    "        self.V = bst.ShortTermState(jnp.ones(size) * V_rest)\n",
    "        self.spike = bst.ShortTermState(jnp.zeros(size, dtype=bool))\n",
    "    \n",
    "    def reset_state(self):\n",
    "        \"\"\"Reset to resting state.\"\"\"\n",
    "        self.V.value = jnp.ones(self.size) * self.V_rest\n",
    "        self.spike.value = jnp.zeros(self.size, dtype=bool)\n",
    "    \n",
    "    def __call__(self, I: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"Update neuron state for one time step.\n",
    "        \n",
    "        Args:\n",
    "            I: Input current of shape (size,)\n",
    "            \n",
    "        Returns:\n",
    "            spike: Binary spike array\n",
    "        \"\"\"\n",
    "        # Integrate membrane potential\n",
    "        dV = (-(self.V.value - self.V_rest) + self.R * I) / self.tau\n",
    "        V_new = self.V.value + dV * self.dt\n",
    "        \n",
    "        # Check for spikes\n",
    "        spike = V_new >= self.V_th\n",
    "        \n",
    "        # Reset spiking neurons\n",
    "        V_new = jnp.where(spike, self.V_reset, V_new)\n",
    "        \n",
    "        # Update state\n",
    "        self.V.value = V_new\n",
    "        self.spike.value = spike\n",
    "        \n",
    "        return spike.astype(jnp.float32)\n",
    "\n",
    "# Create LIF neuron\n",
    "neuron = LIFNeuron(size=1, tau=10.0, V_th=-50.0, V_reset=-70.0, dt=0.1)\n",
    "\n",
    "# Simulate with constant input\n",
    "n_steps = 1000\n",
    "I_input = 15.0  # Input current\n",
    "\n",
    "voltages = []\n",
    "spikes = []\n",
    "\n",
    "neuron.reset_state()\n",
    "for t in range(n_steps):\n",
    "    spike = neuron(jnp.array([I_input]))\n",
    "    voltages.append(float(neuron.V.value[0]))\n",
    "    spikes.append(float(spike[0]))\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "time = np.arange(n_steps) * neuron.dt\n",
    "\n",
    "# Membrane potential\n",
    "ax1.plot(time, voltages, 'b-', linewidth=1)\n",
    "ax1.axhline(neuron.V_th, color='r', linestyle='--', label='Threshold')\n",
    "ax1.axhline(neuron.V_rest, color='g', linestyle='--', label='Rest')\n",
    "ax1.set_ylabel('Voltage (mV)')\n",
    "ax1.set_title('LIF Neuron Dynamics')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Spike raster\n",
    "spike_times = time[np.array(spikes) > 0]\n",
    "ax2.eventplot(spike_times, colors='black', linewidths=2)\n",
    "ax2.set_ylabel('Spikes')\n",
    "ax2.set_xlabel('Time (ms)')\n",
    "ax2.set_ylim([0.5, 1.5])\n",
    "ax2.set_yticks([])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Firing rate: {np.sum(spikes) / (n_steps * neuron.dt) * 1000:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-I Curve (Frequency-Current Relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_firing_rate(neuron, I_input, duration=500):\n",
    "    \"\"\"Measure firing rate for given input current.\"\"\"\n",
    "    neuron.reset_state()\n",
    "    n_steps = int(duration / neuron.dt)\n",
    "    spike_count = 0\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        spike = neuron(jnp.array([I_input]))\n",
    "        spike_count += float(spike[0])\n",
    "    \n",
    "    # Convert to Hz\n",
    "    firing_rate = spike_count / duration * 1000\n",
    "    return firing_rate\n",
    "\n",
    "# Test different input currents\n",
    "currents = np.linspace(0, 30, 30)\n",
    "firing_rates = []\n",
    "\n",
    "neuron = LIFNeuron(size=1, tau=10.0, V_th=-50.0)\n",
    "\n",
    "for I in currents:\n",
    "    fr = measure_firing_rate(neuron, I)\n",
    "    firing_rates.append(fr)\n",
    "\n",
    "# Plot F-I curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(currents, firing_rates, 'b-', linewidth=2)\n",
    "plt.xlabel('Input Current (a.u.)')\n",
    "plt.ylabel('Firing Rate (Hz)')\n",
    "plt.title('F-I Curve: Frequency-Current Relationship')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Population of LIF Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFPopulation(bst.nn.Dynamics):\n",
    "    \"\"\"Population of LIF neurons.\"\"\"\n",
    "    \n",
    "    def __init__(self, size: int, **kwargs):\n",
    "        super().__init__()\n",
    "        self.neurons = LIFNeuron(size=size, **kwargs)\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.neurons.reset_state()\n",
    "    \n",
    "    def __call__(self, I: jnp.ndarray) -> jnp.ndarray:\n",
    "        return self.neurons(I)\n",
    "\n",
    "# Create population\n",
    "n_neurons = 50\n",
    "population = LIFPopulation(size=n_neurons, tau=10.0, V_th=-50.0, dt=0.1)\n",
    "\n",
    "# Simulate with random inputs\n",
    "n_steps = 500\n",
    "spike_trains = []\n",
    "\n",
    "population.reset_state()\n",
    "for t in range(n_steps):\n",
    "    # Random input to each neuron\n",
    "    I_input = bst.random.randn(n_neurons) * 5 + 15\n",
    "    spikes = population(I_input)\n",
    "    spike_trains.append(spikes)\n",
    "\n",
    "spike_trains = np.array(spike_trains)  # Shape: (n_steps, n_neurons)\n",
    "\n",
    "# Plot raster plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "time = np.arange(n_steps) * population.neurons.dt\n",
    "\n",
    "# Create raster plot\n",
    "for neuron_idx in range(n_neurons):\n",
    "    spike_times = time[spike_trains[:, neuron_idx] > 0]\n",
    "    plt.plot(spike_times, np.ones_like(spike_times) * neuron_idx, \n",
    "             'k.', markersize=2)\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Neuron Index')\n",
    "plt.title(f'Population Activity: {n_neurons} LIF Neurons')\n",
    "plt.ylim([-1, n_neurons])\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Population firing rate over time\n",
    "window = 10  # ms\n",
    "window_steps = int(window / population.neurons.dt)\n",
    "pop_rate = []\n",
    "\n",
    "for i in range(0, n_steps - window_steps):\n",
    "    rate = np.sum(spike_trains[i:i+window_steps]) / (n_neurons * window) * 1000\n",
    "    pop_rate.append(rate)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time[:len(pop_rate)], pop_rate, 'b-', linewidth=2)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Population Rate (Hz)')\n",
    "plt.title('Population Firing Rate')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spiking Neural Network Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingLayer(bst.nn.Dynamics):\n",
    "    \"\"\"Spiking neural network layer with synaptic connections.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_size: int, out_size: int, **neuron_kwargs):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        # Synaptic weights\n",
    "        self.weight = bst.ParamState(\n",
    "            bst.random.randn(in_size, out_size) * 0.1\n",
    "        )\n",
    "        \n",
    "        # Output neurons\n",
    "        self.neurons = LIFNeuron(size=out_size, **neuron_kwargs)\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.neurons.reset_state()\n",
    "    \n",
    "    def __call__(self, input_spikes: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"Process input spikes.\n",
    "        \n",
    "        Args:\n",
    "            input_spikes: Binary spike array of shape (in_size,)\n",
    "            \n",
    "        Returns:\n",
    "            output_spikes: Binary spike array of shape (out_size,)\n",
    "        \"\"\"\n",
    "        # Compute synaptic input\n",
    "        I_syn = input_spikes @ self.weight.value\n",
    "        \n",
    "        # Update neurons\n",
    "        output_spikes = self.neurons(I_syn)\n",
    "        \n",
    "        return output_spikes\n",
    "\n",
    "# Create spiking layer\n",
    "layer = SpikingLayer(in_size=10, out_size=5, tau=10.0, V_th=-50.0)\n",
    "\n",
    "# Simulate\n",
    "n_steps = 200\n",
    "input_spike_trains = []\n",
    "output_spike_trains = []\n",
    "\n",
    "layer.reset_state()\n",
    "for t in range(n_steps):\n",
    "    # Random input spikes\n",
    "    input_spikes = (bst.random.uniform(0, 1, (layer.in_size,)) > 0.9).astype(jnp.float32)\n",
    "    output_spikes = layer(input_spikes)\n",
    "    \n",
    "    input_spike_trains.append(input_spikes)\n",
    "    output_spike_trains.append(output_spikes)\n",
    "\n",
    "input_spike_trains = np.array(input_spike_trains)\n",
    "output_spike_trains = np.array(output_spike_trains)\n",
    "\n",
    "# Plot input and output\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "time = np.arange(n_steps) * layer.neurons.dt\n",
    "\n",
    "# Input spikes\n",
    "for i in range(layer.in_size):\n",
    "    spike_times = time[input_spike_trains[:, i] > 0]\n",
    "    ax1.plot(spike_times, np.ones_like(spike_times) * i, 'b.', markersize=3)\n",
    "\n",
    "ax1.set_ylabel('Input Neuron')\n",
    "ax1.set_title('Input Spike Trains')\n",
    "ax1.set_ylim([-1, layer.in_size])\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Output spikes\n",
    "for i in range(layer.out_size):\n",
    "    spike_times = time[output_spike_trains[:, i] > 0]\n",
    "    ax2.plot(spike_times, np.ones_like(spike_times) * i, 'r.', markersize=3)\n",
    "\n",
    "ax2.set_xlabel('Time (ms)')\n",
    "ax2.set_ylabel('Output Neuron')\n",
    "ax2.set_title('Output Spike Trains')\n",
    "ax2.set_ylim([-1, layer.out_size])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spike-Timing-Dependent Plasticity (STDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STDPSynapse(bst.nn.Dynamics):\n",
    "    \"\"\"Synapse with Spike-Timing-Dependent Plasticity.\n",
    "    \n",
    "    STDP rule:\n",
    "    - If pre-spike before post-spike: potentiation (strengthen)\n",
    "    - If post-spike before pre-spike: depression (weaken)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size: int,\n",
    "        out_size: int,\n",
    "        tau_pre: float = 20.0,   # Pre-synaptic trace time constant\n",
    "        tau_post: float = 20.0,  # Post-synaptic trace time constant\n",
    "        A_plus: float = 0.01,    # LTP amplitude\n",
    "        A_minus: float = 0.01,   # LTD amplitude\n",
    "        w_max: float = 1.0,      # Maximum weight\n",
    "        dt: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.tau_pre = tau_pre\n",
    "        self.tau_post = tau_post\n",
    "        self.A_plus = A_plus\n",
    "        self.A_minus = A_minus\n",
    "        self.w_max = w_max\n",
    "        self.dt = dt\n",
    "        \n",
    "        # Synaptic weights\n",
    "        self.weight = bst.ParamState(\n",
    "            bst.random.uniform(0, 0.5, (in_size, out_size))\n",
    "        )\n",
    "        \n",
    "        # Synaptic traces\n",
    "        self.trace_pre = bst.ShortTermState(jnp.zeros(in_size))\n",
    "        self.trace_post = bst.ShortTermState(jnp.zeros(out_size))\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.trace_pre.value = jnp.zeros(self.in_size)\n",
    "        self.trace_post.value = jnp.zeros(self.out_size)\n",
    "    \n",
    "    def __call__(\n",
    "        self, \n",
    "        pre_spikes: jnp.ndarray, \n",
    "        post_spikes: jnp.ndarray,\n",
    "        learning: bool = True\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"Update synapse with STDP.\n",
    "        \n",
    "        Args:\n",
    "            pre_spikes: Pre-synaptic spikes of shape (in_size,)\n",
    "            post_spikes: Post-synaptic spikes of shape (out_size,)\n",
    "            learning: Whether to apply STDP\n",
    "            \n",
    "        Returns:\n",
    "            Synaptic current to post-synaptic neurons\n",
    "        \"\"\"\n",
    "        if learning:\n",
    "            # Update traces\n",
    "            self.trace_pre.value += (-self.trace_pre.value / self.tau_pre + pre_spikes) * self.dt\n",
    "            self.trace_post.value += (-self.trace_post.value / self.tau_post + post_spikes) * self.dt\n",
    "            \n",
    "            # STDP weight update\n",
    "            # Potentiation: pre-spike causes increase based on post trace\n",
    "            dw_plus = jnp.outer(pre_spikes, self.trace_post.value) * self.A_plus\n",
    "            \n",
    "            # Depression: post-spike causes decrease based on pre trace\n",
    "            dw_minus = jnp.outer(self.trace_pre.value, post_spikes) * self.A_minus\n",
    "            \n",
    "            # Update weights\n",
    "            w_new = self.weight.value + dw_plus - dw_minus\n",
    "            \n",
    "            # Clip weights\n",
    "            w_new = jnp.clip(w_new, 0, self.w_max)\n",
    "            \n",
    "            self.weight.value = w_new\n",
    "        \n",
    "        # Compute synaptic input\n",
    "        I_syn = pre_spikes @ self.weight.value\n",
    "        \n",
    "        return I_syn\n",
    "\n",
    "# Demonstrate STDP\n",
    "stdp = STDPSynapse(in_size=1, out_size=1, A_plus=0.01, A_minus=0.01)\n",
    "\n",
    "# Simulate STDP learning\n",
    "n_steps = 1000\n",
    "weight_history = []\n",
    "\n",
    "stdp.reset_state()\n",
    "for t in range(n_steps):\n",
    "    # Create spike pairs with different timing\n",
    "    if t % 100 < 50:  # Pre before post (potentiation)\n",
    "        if t % 10 == 0:\n",
    "            pre_spike = jnp.array([1.0])\n",
    "        elif t % 10 == 5:\n",
    "            post_spike = jnp.array([1.0])\n",
    "        else:\n",
    "            pre_spike = jnp.array([0.0])\n",
    "            post_spike = jnp.array([0.0])\n",
    "    else:  # Post before pre (depression)\n",
    "        if t % 10 == 0:\n",
    "            post_spike = jnp.array([1.0])\n",
    "        elif t % 10 == 5:\n",
    "            pre_spike = jnp.array([1.0])\n",
    "        else:\n",
    "            pre_spike = jnp.array([0.0])\n",
    "            post_spike = jnp.array([0.0])\n",
    "    \n",
    "    if 'pre_spike' in locals():\n",
    "        _ = stdp(pre_spike, post_spike if 'post_spike' in locals() else jnp.array([0.0]))\n",
    "    \n",
    "    weight_history.append(float(stdp.weight.value[0, 0]))\n",
    "\n",
    "# Plot weight evolution\n",
    "plt.figure(figsize=(12, 5))\n",
    "time = np.arange(n_steps) * stdp.dt\n",
    "plt.plot(time, weight_history, 'b-', linewidth=2)\n",
    "plt.axvline(n_steps * stdp.dt / 2, color='r', linestyle='--', \n",
    "            label='Switch: Pre→Post to Post→Pre')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Synaptic Weight')\n",
    "plt.title('STDP Learning: Weight Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STDP Learning Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_stdp_window(dt_spike):\n",
    "    \"\"\"Measure weight change for given spike timing difference.\"\"\"\n",
    "    stdp = STDPSynapse(in_size=1, out_size=1, A_plus=0.01, A_minus=0.01, dt=0.1)\n",
    "    stdp.reset_state()\n",
    "    \n",
    "    initial_weight = float(stdp.weight.value[0, 0])\n",
    "    \n",
    "    # Single spike pair\n",
    "    if dt_spike > 0:  # Pre before post\n",
    "        for t in range(abs(int(dt_spike / stdp.dt)) + 50):\n",
    "            if t == 0:\n",
    "                pre, post = jnp.array([1.0]), jnp.array([0.0])\n",
    "            elif t == int(dt_spike / stdp.dt):\n",
    "                pre, post = jnp.array([0.0]), jnp.array([1.0])\n",
    "            else:\n",
    "                pre, post = jnp.array([0.0]), jnp.array([0.0])\n",
    "            _ = stdp(pre, post)\n",
    "    else:  # Post before pre\n",
    "        for t in range(abs(int(dt_spike / stdp.dt)) + 50):\n",
    "            if t == 0:\n",
    "                pre, post = jnp.array([0.0]), jnp.array([1.0])\n",
    "            elif t == abs(int(dt_spike / stdp.dt)):\n",
    "                pre, post = jnp.array([1.0]), jnp.array([0.0])\n",
    "            else:\n",
    "                pre, post = jnp.array([0.0]), jnp.array([0.0])\n",
    "            _ = stdp(pre, post)\n",
    "    \n",
    "    final_weight = float(stdp.weight.value[0, 0])\n",
    "    return final_weight - initial_weight\n",
    "\n",
    "# Measure STDP window\n",
    "dt_values = np.linspace(-50, 50, 21)\n",
    "weight_changes = [measure_stdp_window(dt) for dt in dt_values]\n",
    "\n",
    "# Plot STDP learning window\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dt_values, weight_changes, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axhline(0, color='k', linestyle='-', linewidth=0.5)\n",
    "plt.axvline(0, color='k', linestyle='-', linewidth=0.5)\n",
    "plt.xlabel('Spike Timing Difference Δt (ms)\\n(Positive = Pre before Post)')\n",
    "plt.ylabel('Weight Change Δw')\n",
    "plt.title('STDP Learning Window')\n",
    "plt.text(20, max(weight_changes)*0.8, 'LTP\\n(Potentiation)', ha='center', fontsize=12)\n",
    "plt.text(-20, min(weight_changes)*0.8, 'LTD\\n(Depression)', ha='center', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete SNN for Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingNetwork(bst.graph.Node):\n",
    "    \"\"\"Simple spiking neural network.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Layers\n",
    "        self.layer1 = SpikingLayer(input_size, hidden_size, tau=10.0, V_th=-50.0)\n",
    "        self.layer2 = SpikingLayer(hidden_size, output_size, tau=10.0, V_th=-50.0)\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.layer1.reset_state()\n",
    "        self.layer2.reset_state()\n",
    "    \n",
    "    def __call__(self, input_spikes):\n",
    "        hidden_spikes = self.layer1(input_spikes)\n",
    "        output_spikes = self.layer2(hidden_spikes)\n",
    "        return output_spikes\n",
    "\n",
    "# Create network\n",
    "snn = SpikingNetwork(input_size=10, hidden_size=20, output_size=3)\n",
    "\n",
    "# Generate input patterns\n",
    "def generate_spike_pattern(pattern_id, n_steps=100, input_size=10):\n",
    "    \"\"\"Generate input spike pattern for given pattern ID.\"\"\"\n",
    "    spikes = []\n",
    "    for t in range(n_steps):\n",
    "        # Different patterns have different spike probabilities\n",
    "        prob = 0.1 + 0.1 * (pattern_id + 1) * (np.sin(t / 10) + 1) / 2\n",
    "        spike = (np.random.random(input_size) < prob).astype(np.float32)\n",
    "        spikes.append(spike)\n",
    "    return np.array(spikes)\n",
    "\n",
    "# Simulate network with different patterns\n",
    "n_patterns = 3\n",
    "n_steps = 100\n",
    "\n",
    "fig, axes = plt.subplots(n_patterns, 2, figsize=(14, 10))\n",
    "\n",
    "for pattern_id in range(n_patterns):\n",
    "    # Generate input pattern\n",
    "    input_pattern = generate_spike_pattern(pattern_id, n_steps)\n",
    "    \n",
    "    # Simulate\n",
    "    snn.reset_state()\n",
    "    output_spikes_history = []\n",
    "    \n",
    "    for t in range(n_steps):\n",
    "        output_spikes = snn(jnp.array(input_pattern[t]))\n",
    "        output_spikes_history.append(output_spikes)\n",
    "    \n",
    "    output_spikes_history = np.array(output_spikes_history)\n",
    "    \n",
    "    # Plot input\n",
    "    ax = axes[pattern_id, 0]\n",
    "    for i in range(snn.layer1.in_size):\n",
    "        spike_times = np.where(input_pattern[:, i] > 0)[0]\n",
    "        ax.plot(spike_times, np.ones_like(spike_times) * i, 'b.', markersize=2)\n",
    "    ax.set_ylabel('Input Neuron')\n",
    "    ax.set_title(f'Pattern {pattern_id}: Input')\n",
    "    ax.set_ylim([-1, snn.layer1.in_size])\n",
    "    \n",
    "    # Plot output\n",
    "    ax = axes[pattern_id, 1]\n",
    "    for i in range(snn.layer2.out_size):\n",
    "        spike_times = np.where(output_spikes_history[:, i] > 0)[0]\n",
    "        ax.plot(spike_times, np.ones_like(spike_times) * i, 'r.', markersize=3)\n",
    "    ax.set_ylabel('Output Neuron')\n",
    "    ax.set_title(f'Pattern {pattern_id}: Output')\n",
    "    ax.set_ylim([-1, snn.layer2.out_size])\n",
    "    \n",
    "    if pattern_id == n_patterns - 1:\n",
    "        axes[pattern_id, 0].set_xlabel('Time Step')\n",
    "        axes[pattern_id, 1].set_xlabel('Time Step')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count output spikes per pattern\n",
    "print(\"Output spike counts per pattern:\")\n",
    "for pattern_id in range(n_patterns):\n",
    "    input_pattern = generate_spike_pattern(pattern_id, n_steps)\n",
    "    snn.reset_state()\n",
    "    \n",
    "    output_counts = np.zeros(snn.layer2.out_size)\n",
    "    for t in range(n_steps):\n",
    "        output_spikes = snn(jnp.array(input_pattern[t]))\n",
    "        output_counts += np.array(output_spikes)\n",
    "    \n",
    "    print(f\"  Pattern {pattern_id}: {output_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we explored brain-inspired computing:\n",
    "\n",
    "1. **LIF Neurons**: Basic spiking neuron model with integrate-and-fire dynamics\n",
    "2. **F-I Curves**: Frequency-current relationship in neurons\n",
    "3. **Neuron Populations**: Simulating groups of spiking neurons\n",
    "4. **Spiking Layers**: Feedforward connectivity with synapses\n",
    "5. **STDP**: Spike-timing-dependent plasticity for learning\n",
    "6. **STDP Window**: Temporal learning rules\n",
    "7. **Complete SNN**: Multi-layer spiking network\n",
    "8. **Pattern Recognition**: Processing spike patterns\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Spiking neurons communicate with discrete events** (spikes)\n",
    "- **Timing matters**: Spike timing encodes information\n",
    "- **STDP** implements Hebbian learning: \"neurons that fire together, wire together\"\n",
    "- **SNNs are energy-efficient**: Computation only on spikes\n",
    "- **Neurodynamics** capture biological behavior\n",
    "- **Event-driven** computation is naturally asynchronous\n",
    "- BrainState's Dynamics class is perfect for neuronal models\n",
    "\n",
    "## Advantages of SNNs\n",
    "\n",
    "1. **Biological realism**: Closer to brain computation\n",
    "2. **Energy efficiency**: Sparse, event-driven processing\n",
    "3. **Temporal processing**: Natural handling of time\n",
    "4. **Asynchronous**: No need for synchronized clock\n",
    "5. **Neuromorphic hardware**: Optimized for specialized chips\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next tutorial, we'll explore:\n",
    "- **Optimization Tricks**: Learning rate schedules, gradient clipping\n",
    "- Advanced training techniques\n",
    "- Mixed precision training\n",
    "- Checkpoint management"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
