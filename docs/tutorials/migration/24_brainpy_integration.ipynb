{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 24: BrainPy Integration\n",
    "\n",
    "In this tutorial, we'll explore how BrainState integrates with BrainPy and when to use each framework.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand the relationship between BrainState and BrainPy\n",
    "- Know when to use BrainState vs BrainPy\n",
    "- Learn how to combine both frameworks\n",
    "- Understand API interoperability\n",
    "- Build hybrid models using both libraries\n",
    "- Leverage the strengths of each framework\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**BrainState** and **BrainPy** are complementary frameworks from the same ecosystem:\n",
    "\n",
    "### BrainState\n",
    "- **Focus**: Low-level state management and transformations\n",
    "- **Purpose**: Foundation library for building neural models\n",
    "- **Key Features**:\n",
    "  - Explicit state management (ParamState, ShortTermState, etc.)\n",
    "  - JAX transformations (JIT, grad, vmap)\n",
    "  - Basic neural network layers\n",
    "  - Graph operations and utilities\n",
    "\n",
    "### BrainPy\n",
    "- **Focus**: Brain dynamics and computational neuroscience\n",
    "- **Purpose**: High-level brain modeling and simulation\n",
    "- **Key Features**:\n",
    "  - Spiking neural networks (SNNs)\n",
    "  - Neuronal models (HH, LIF, Izhikevich, etc.)\n",
    "  - Synaptic plasticity (STDP, BCM, etc.)\n",
    "  - Network connectivity and dynamics\n",
    "  - Differential equation solvers\n",
    "\n",
    "**Relationship**: BrainPy is built on top of BrainState, using its state management system and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainstate as bst\n",
    "# Note: BrainPy would be imported as:\n",
    "# import brainpy as bp\n",
    "# For this tutorial, we'll demonstrate the concepts with BrainState\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "bst.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Framework Comparison\n",
    "\n",
    "### 1.1 When to Use BrainState\n",
    "\n",
    "Use **BrainState** when you need:\n",
    "\n",
    "1. **Custom State Management**: Fine-grained control over state types\n",
    "2. **Deep Learning Models**: Standard neural networks (MLPs, CNNs, Transformers)\n",
    "3. **JAX Transformations**: Direct access to JIT, vmap, grad\n",
    "4. **Lightweight Solution**: Minimal dependencies for simple models\n",
    "5. **Building Blocks**: Foundation for custom frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: BrainState is ideal for standard deep learning\n",
    "class StandardMLP(bst.graph.Node):\n",
    "    \"\"\"Simple MLP using BrainState.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = bst.nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = bst.nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = jax.nn.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# Use case: Standard classification task\n",
    "model = StandardMLP(784, 128, 10)\n",
    "x = bst.random.randn(32, 784)\n",
    "output = model(x)\n",
    "print(f\"BrainState MLP output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 When to Use BrainPy\n",
    "\n",
    "Use **BrainPy** when you need:\n",
    "\n",
    "1. **Brain Modeling**: Biologically realistic neural simulations\n",
    "2. **Spiking Networks**: Event-driven computation with spikes\n",
    "3. **Neuronal Dynamics**: Complex differential equations (HH, Izhikevich)\n",
    "4. **Synaptic Plasticity**: STDP, BCM, and other learning rules\n",
    "5. **Neuroscience Research**: Tools for computational neuroscience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: BrainPy-style neuron model (implemented with BrainState)\n",
    "# This demonstrates the concepts that BrainPy provides\n",
    "\n",
    "class LIFNeuron(bst.nn.Dynamics):\n",
    "    \"\"\"\n",
    "    Leaky Integrate-and-Fire neuron.\n",
    "    This is the type of model you'd use BrainPy for.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, size: int, tau: float = 10.0, \n",
    "                 V_rest: float = -70.0, V_th: float = -50.0, \n",
    "                 V_reset: float = -70.0, dt: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.tau = tau\n",
    "        self.V_rest = V_rest\n",
    "        self.V_th = V_th\n",
    "        self.V_reset = V_reset\n",
    "        self.dt = dt\n",
    "        self.R = 1.0\n",
    "        \n",
    "        # State variable\n",
    "        self.V = bst.ShortTermState(jnp.ones(size) * V_rest)\n",
    "    \n",
    "    def __call__(self, I: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        Update neuron state given input current.\n",
    "        \n",
    "        Args:\n",
    "            I: Input current\n",
    "            \n",
    "        Returns:\n",
    "            Spike output (1 if spike, 0 otherwise)\n",
    "        \"\"\"\n",
    "        # Differential equation: tau * dV/dt = -(V - V_rest) + R*I\n",
    "        dV = (-(self.V.value - self.V_rest) + self.R * I) / self.tau\n",
    "        V_new = self.V.value + dV * self.dt\n",
    "        \n",
    "        # Spike and reset\n",
    "        spike = V_new >= self.V_th\n",
    "        V_new = jnp.where(spike, self.V_reset, V_new)\n",
    "        \n",
    "        # Update state\n",
    "        self.V.value = V_new\n",
    "        \n",
    "        return spike.astype(jnp.float32)\n",
    "\n",
    "# Use case: Spiking neural network\n",
    "lif = LIFNeuron(size=100, tau=10.0)\n",
    "current_input = bst.random.randn(100) * 5 + 10  # Noisy input current\n",
    "spikes = lif(current_input)\n",
    "print(f\"Number of spikes: {jnp.sum(spikes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Feature Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison = [\n",
    "    (\"Feature\", \"BrainState\", \"BrainPy\"),\n",
    "    (\"-\" * 30, \"-\" * 25, \"-\" * 25),\n",
    "    (\"State Management\", \"✓ Core feature\", \"✓ Built on BrainState\"),\n",
    "    (\"Neural Network Layers\", \"✓ Basic layers\", \"✓ + Specialized layers\"),\n",
    "    (\"JAX Transformations\", \"✓ Direct access\", \"✓ Via BrainState\"),\n",
    "    (\"Spiking Neural Networks\", \"○ Manual impl.\", \"✓ Built-in models\"),\n",
    "    (\"Neuronal Models\", \"○ Manual impl.\", \"✓ HH, Izhikevich, etc.\"),\n",
    "    (\"Synaptic Plasticity\", \"○ Manual impl.\", \"✓ STDP, BCM, etc.\"),\n",
    "    (\"Network Connectivity\", \"○ Manual impl.\", \"✓ Built-in patterns\"),\n",
    "    (\"ODE Solvers\", \"○ Basic\", \"✓ Advanced solvers\"),\n",
    "    (\"Deep Learning Focus\", \"✓ Primary\", \"○ Secondary\"),\n",
    "    (\"Neuroscience Focus\", \"○ Secondary\", \"✓ Primary\"),\n",
    "    (\"Package Size\", \"Lightweight\", \"Full-featured\"),\n",
    "    (\"Learning Curve\", \"Moderate\", \"Steeper\"),\n",
    "]\n",
    "\n",
    "print(\"BrainState vs BrainPy Feature Comparison\")\n",
    "print(\"=\" * 80)\n",
    "for row in comparison:\n",
    "    print(f\"{row[0]:<30} {row[1]:<25} {row[2]:<25}\")\n",
    "\n",
    "print(\"\\nLegend: ✓ = Full support, ○ = Partial/Manual implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Shared State Management\n",
    "\n",
    "Both frameworks use the same state management system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shared State Types\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# State types used by both frameworks\n",
    "state_types = [\n",
    "    (\"ParamState\", \"Trainable parameters (weights, biases)\", \"Both\"),\n",
    "    (\"ShortTermState\", \"Temporary state (hidden states, membrane potentials)\", \"Both\"),\n",
    "    (\"LongTermState\", \"Accumulated state (running stats, counters)\", \"Both\"),\n",
    "    (\"HiddenState\", \"Internal hidden variables\", \"Both\"),\n",
    "]\n",
    "\n",
    "print(f\"{'State Type':<20} {'Description':<40} {'Used By':<10}\")\n",
    "print(\"-\" * 70)\n",
    "for state_type, desc, used in state_types:\n",
    "    print(f\"{state_type:<20} {desc:<40} {used:<10}\")\n",
    "\n",
    "# Example: Same state system\n",
    "class HybridModel(bst.graph.Node):\n",
    "    \"\"\"Model using shared state types.\"\"\"\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        # Parameters (trainable)\n",
    "        self.W = bst.ParamState(bst.random.randn(size, size) * 0.1)\n",
    "        \n",
    "        # Short-term state (reset per episode)\n",
    "        self.activity = bst.ShortTermState(jnp.zeros(size))\n",
    "        \n",
    "        # Long-term state (accumulated)\n",
    "        self.total_spikes = bst.LongTermState(jnp.array(0))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Compute new activity\n",
    "        new_activity = jax.nn.tanh(self.W.value @ x + self.activity.value)\n",
    "        \n",
    "        # Update states\n",
    "        self.activity.value = new_activity\n",
    "        self.total_spikes.value = self.total_spikes.value + jnp.sum(new_activity > 0.5)\n",
    "        \n",
    "        return new_activity\n",
    "\n",
    "model = HybridModel(10)\n",
    "x = bst.random.randn(10)\n",
    "y = model(x)\n",
    "\n",
    "print(f\"\\nState counts:\")\n",
    "print(f\"  ParamState: {len(model.states(bst.ParamState))}\")\n",
    "print(f\"  ShortTermState: {len(model.states(bst.ShortTermState))}\")\n",
    "print(f\"  LongTermState: {len(model.states(bst.LongTermState))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. API Interoperability\n",
    "\n",
    "### 3.1 Common Base: bst.graph.Node\n",
    "\n",
    "Both frameworks use `bst.graph.Node` as the base class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BrainState layer\n",
    "class BrainStateLayer(bst.graph.Node):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.linear = bst.nn.Linear(dim, dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return jax.nn.relu(self.linear(x))\n",
    "\n",
    "# BrainPy-style dynamics layer\n",
    "class BrainPyStyleLayer(bst.nn.Dynamics):\n",
    "    def __init__(self, dim, tau=10.0):\n",
    "        super().__init__()\n",
    "        self.linear = bst.nn.Linear(dim, dim)\n",
    "        self.tau = tau\n",
    "        self.state = bst.ShortTermState(jnp.zeros(dim))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Dynamics integration\n",
    "        dx = (-self.state.value + self.linear(x)) / self.tau\n",
    "        self.state.value = self.state.value + dx * 0.1\n",
    "        return self.state.value\n",
    "\n",
    "# Both can be combined!\n",
    "class CombinedModel(bst.graph.Node):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.bst_layer = BrainStateLayer(dim)\n",
    "        self.bp_layer = BrainPyStyleLayer(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = self.bst_layer(x)  # BrainState processing\n",
    "        x = self.bp_layer(x)   # BrainPy-style dynamics\n",
    "        return x\n",
    "\n",
    "# Test combined model\n",
    "combined = CombinedModel(20)\n",
    "x = bst.random.randn(5, 20)\n",
    "output = combined(x)\n",
    "print(f\"Combined model output shape: {output.shape}\")\n",
    "print(f\"Total parameters: {sum(p.value.size for p in combined.states(bst.ParamState).values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Shared Transformations\n",
    "\n",
    "Both frameworks use the same JAX transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shared JAX Transformations\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# JIT compilation works for both\n",
    "model = CombinedModel(10)\n",
    "x_test = bst.random.randn(3, 10)\n",
    "\n",
    "# JIT compile\n",
    "@bst.transform.jit\n",
    "def forward_jit(x):\n",
    "    return model(x)\n",
    "\n",
    "output_jit = forward_jit(x_test)\n",
    "print(f\"JIT output shape: {output_jit.shape}\")\n",
    "\n",
    "# Gradient computation\n",
    "def loss_fn(x):\n",
    "    return jnp.sum(model(x) ** 2)\n",
    "\n",
    "params = model.states(bst.ParamState)\n",
    "loss, grads = bst.transform.grad(loss_fn, grad_states=params, return_value=True)(x_test)\n",
    "print(f\"\\nLoss: {loss:.4f}\")\n",
    "print(f\"Gradient keys: {list(grads.keys())[:3]}...\")  # Show first 3\n",
    "\n",
    "# Vectorization\n",
    "def process_single(x_single):\n",
    "    return jnp.sum(model(x_single.reshape(1, -1)))\n",
    "\n",
    "batch_vmap = jax.vmap(process_single)\n",
    "results = batch_vmap(x_test)\n",
    "print(f\"\\nvmap results shape: {results.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Hybrid Models\n",
    "\n",
    "Combine deep learning (BrainState) with brain dynamics (BrainPy-style)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingCNN(bst.graph.Node):\n",
    "    \"\"\"\n",
    "    Hybrid model: CNN feature extraction + Spiking output layer.\n",
    "    Demonstrates combining traditional DL with neuromorphic computing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Standard CNN layers (BrainState)\n",
    "        self.conv1 = bst.nn.Conv2d(1, 32, kernel_size=(3, 3), padding='SAME')\n",
    "        self.conv2 = bst.nn.Conv2d(32, 64, kernel_size=(3, 3), padding='SAME')\n",
    "        self.fc = bst.nn.Linear(64 * 7 * 7, 256)\n",
    "        \n",
    "        # Spiking output layer (BrainPy-style)\n",
    "        self.spiking_out = LIFNeuron(\n",
    "            size=num_classes,\n",
    "            tau=10.0,\n",
    "            V_th=-50.0,\n",
    "            V_reset=-70.0\n",
    "        )\n",
    "        \n",
    "        # Readout weights\n",
    "        self.readout = bst.nn.Linear(256, num_classes)\n",
    "    \n",
    "    def __call__(self, x: jnp.ndarray, return_spikes: bool = False) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x: Input image (batch, channels, height, width)\n",
    "            return_spikes: If True, return spike trains\n",
    "            \n",
    "        Returns:\n",
    "            Output logits or spike counts\n",
    "        \"\"\"\n",
    "        # CNN feature extraction\n",
    "        x = jax.nn.relu(self.conv1(x))\n",
    "        x = bst.functional.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        \n",
    "        x = jax.nn.relu(self.conv2(x))\n",
    "        x = bst.functional.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        \n",
    "        # Flatten and FC\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = jax.nn.relu(self.fc(x))\n",
    "        \n",
    "        if return_spikes:\n",
    "            # Convert to current and simulate spiking\n",
    "            current = self.readout(x)\n",
    "            spike_counts = jnp.zeros_like(current)\n",
    "            \n",
    "            # Simulate for multiple time steps\n",
    "            for t in range(10):\n",
    "                spikes = self.spiking_out(current[0])  # Process first sample\n",
    "                spike_counts = spike_counts.at[0].add(spikes)\n",
    "            \n",
    "            return spike_counts\n",
    "        else:\n",
    "            # Standard output\n",
    "            return self.readout(x)\n",
    "\n",
    "# Create and test hybrid model\n",
    "hybrid_model = SpikingCNN(num_classes=10)\n",
    "test_image = bst.random.randn(1, 1, 28, 28)\n",
    "\n",
    "# Standard forward pass\n",
    "logits = hybrid_model(test_image, return_spikes=False)\n",
    "print(f\"Logits shape: {logits.shape}\")\n",
    "print(f\"Logits: {logits[0]}\")\n",
    "\n",
    "# Spiking output\n",
    "spike_counts = hybrid_model(test_image, return_spikes=True)\n",
    "print(f\"\\nSpike counts shape: {spike_counts.shape}\")\n",
    "print(f\"Spike counts: {spike_counts[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use Case Scenarios\n",
    "\n",
    "### 5.1 Scenario 1: Image Classification (BrainState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Use Case 1: Standard Image Classification\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Framework: BrainState\")\n",
    "print(\"Reason: Standard deep learning task, no brain dynamics needed\\n\")\n",
    "\n",
    "class ImageClassifier(bst.graph.Node):\n",
    "    \"\"\"Standard CNN for image classification.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = bst.nn.Conv2d(3, 64, kernel_size=(3, 3), padding='SAME')\n",
    "        self.conv2 = bst.nn.Conv2d(64, 128, kernel_size=(3, 3), padding='SAME')\n",
    "        self.fc1 = bst.nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = bst.nn.Linear(256, 10)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = jax.nn.relu(self.conv1(x))\n",
    "        x = bst.functional.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = jax.nn.relu(self.conv2(x))\n",
    "        x = bst.functional.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = jax.nn.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "classifier = ImageClassifier()\n",
    "sample = bst.random.randn(4, 3, 32, 32)  # CIFAR-like\n",
    "preds = classifier(sample)\n",
    "print(f\"Predictions shape: {preds.shape}\")\n",
    "print(f\"Parameters: {sum(p.value.size for p in classifier.states(bst.ParamState).values()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Scenario 2: Spiking Network Simulation (BrainPy-style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nUse Case 2: Spiking Neural Network Simulation\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Framework: BrainPy (demonstrated with BrainState)\")\n",
    "print(\"Reason: Need biological neuron models and spike dynamics\\n\")\n",
    "\n",
    "class SpikingNetwork(bst.graph.Node):\n",
    "    \"\"\"Simple spiking neural network.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Synaptic weights\n",
    "        self.W_in = bst.ParamState(bst.random.randn(input_size, hidden_size) * 0.1)\n",
    "        self.W_out = bst.ParamState(bst.random.randn(hidden_size, output_size) * 0.1)\n",
    "        \n",
    "        # Neuron populations\n",
    "        self.hidden_neurons = LIFNeuron(hidden_size, tau=10.0)\n",
    "        self.output_neurons = LIFNeuron(output_size, tau=20.0)\n",
    "    \n",
    "    def __call__(self, spike_input: jnp.ndarray, num_steps: int = 100) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "        \"\"\"\n",
    "        Simulate network for multiple time steps.\n",
    "        \n",
    "        Args:\n",
    "            spike_input: Input spike train (time, input_size)\n",
    "            num_steps: Number of simulation steps\n",
    "            \n",
    "        Returns:\n",
    "            Hidden and output spike trains\n",
    "        \"\"\"\n",
    "        hidden_spikes = []\n",
    "        output_spikes = []\n",
    "        \n",
    "        for t in range(num_steps):\n",
    "            # Get input for this timestep\n",
    "            if t < len(spike_input):\n",
    "                inp = spike_input[t]\n",
    "            else:\n",
    "                inp = jnp.zeros(spike_input.shape[1])\n",
    "            \n",
    "            # Hidden layer\n",
    "            hidden_current = inp @ self.W_in.value\n",
    "            h_spikes = self.hidden_neurons(hidden_current)\n",
    "            hidden_spikes.append(h_spikes)\n",
    "            \n",
    "            # Output layer\n",
    "            output_current = h_spikes @ self.W_out.value\n",
    "            o_spikes = self.output_neurons(output_current)\n",
    "            output_spikes.append(o_spikes)\n",
    "        \n",
    "        return jnp.stack(hidden_spikes), jnp.stack(output_spikes)\n",
    "\n",
    "# Create spiking network\n",
    "snn = SpikingNetwork(input_size=50, hidden_size=100, output_size=10)\n",
    "\n",
    "# Generate random spike input\n",
    "spike_input = (bst.random.rand(50, 50) < 0.1).astype(jnp.float32)  # Sparse spikes\n",
    "\n",
    "# Simulate\n",
    "hidden_activity, output_activity = snn(spike_input, num_steps=50)\n",
    "\n",
    "print(f\"Hidden activity shape: {hidden_activity.shape}\")\n",
    "print(f\"Output activity shape: {output_activity.shape}\")\n",
    "print(f\"Total output spikes: {jnp.sum(output_activity)}\")\n",
    "\n",
    "# Visualize spike raster\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6))\n",
    "\n",
    "# Hidden layer spikes\n",
    "spike_times, spike_neurons = jnp.where(hidden_activity > 0.5)\n",
    "ax1.scatter(spike_times, spike_neurons, s=1, c='black', alpha=0.5)\n",
    "ax1.set_ylabel('Neuron Index')\n",
    "ax1.set_title('Hidden Layer Spike Raster')\n",
    "ax1.set_xlim(0, 50)\n",
    "\n",
    "# Output layer spikes\n",
    "spike_times, spike_neurons = jnp.where(output_activity > 0.5)\n",
    "ax2.scatter(spike_times, spike_neurons, s=5, c='red', alpha=0.7)\n",
    "ax2.set_xlabel('Time Step')\n",
    "ax2.set_ylabel('Neuron Index')\n",
    "ax2.set_title('Output Layer Spike Raster')\n",
    "ax2.set_xlim(0, 50)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Scenario 3: Hybrid Model (Both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Use Case 3: Neuromorphic Vision System\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Framework: Both BrainState + BrainPy\")\n",
    "print(\"Reason: CNN feature extraction + spiking decision making\\n\")\n",
    "\n",
    "class NeuromorphicVision(bst.graph.Node):\n",
    "    \"\"\"Vision system with CNN features and spiking decision layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature extraction (BrainState - standard DL)\n",
    "        self.features = bst.nn.Sequential(\n",
    "            bst.nn.Conv2d(1, 32, kernel_size=(3, 3), padding='SAME'),\n",
    "            bst.nn.Conv2d(32, 64, kernel_size=(3, 3), padding='SAME'),\n",
    "        )\n",
    "        \n",
    "        # Feature to current converter\n",
    "        self.fc_current = bst.nn.Linear(64 * 7 * 7, 100)\n",
    "        \n",
    "        # Decision layer (BrainPy-style - spiking)\n",
    "        self.decision = LIFNeuron(size=num_classes, tau=10.0)\n",
    "        \n",
    "        # Current weights to decision neurons\n",
    "        self.W_decision = bst.ParamState(bst.random.randn(100, num_classes) * 0.1)\n",
    "    \n",
    "    def extract_features(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"Extract features using CNN.\"\"\"\n",
    "        for layer in self.features.children().values():\n",
    "            x = jax.nn.relu(layer(x))\n",
    "            x = bst.functional.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        return x.reshape(x.shape[0], -1)\n",
    "    \n",
    "    def decide(self, features: jnp.ndarray, num_steps: int = 20) -> jnp.ndarray:\n",
    "        \"\"\"Make decision using spiking neurons.\"\"\"\n",
    "        # Convert features to current\n",
    "        current_base = self.fc_current(features)\n",
    "        \n",
    "        # Accumulate spikes over time\n",
    "        spike_counts = jnp.zeros(10)\n",
    "        \n",
    "        for t in range(num_steps):\n",
    "            # Add noise to current\n",
    "            current = current_base[0] @ self.W_decision.value\n",
    "            spikes = self.decision(current)\n",
    "            spike_counts = spike_counts + spikes\n",
    "        \n",
    "        return spike_counts\n",
    "    \n",
    "    def __call__(self, x: jnp.ndarray, mode: str = 'spike') -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x: Input image\n",
    "            mode: 'spike' for spike-based, 'rate' for rate-based\n",
    "        \"\"\"\n",
    "        features = self.extract_features(x)\n",
    "        \n",
    "        if mode == 'spike':\n",
    "            return self.decide(features, num_steps=20)\n",
    "        else:\n",
    "            # Rate-based (standard)\n",
    "            current = self.fc_current(features)\n",
    "            return current @ self.W_decision.value\n",
    "\n",
    "# Test neuromorphic vision\n",
    "neuro_vision = NeuromorphicVision(num_classes=10)\n",
    "test_img = bst.random.randn(1, 1, 28, 28)\n",
    "\n",
    "# Spike-based decision\n",
    "spike_output = neuro_vision(test_img, mode='spike')\n",
    "print(f\"Spike-based output (counts): {spike_output}\")\n",
    "print(f\"Predicted class: {jnp.argmax(spike_output)}\")\n",
    "\n",
    "# Rate-based decision\n",
    "rate_output = neuro_vision(test_img, mode='rate')\n",
    "print(f\"\\nRate-based output: {rate_output[0]}\")\n",
    "print(f\"Predicted class: {jnp.argmax(rate_output[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Migration Between Frameworks\n",
    "\n",
    "### 6.1 Converting BrainState to BrainPy-style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting BrainState Model to BrainPy-style\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Original BrainState model\n",
    "class OriginalBrainState(bst.graph.Node):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc = bst.nn.Linear(dim, dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return jax.nn.relu(self.fc(x))\n",
    "\n",
    "# Converted to BrainPy-style with dynamics\n",
    "class ConvertedBrainPyStyle(bst.nn.Dynamics):\n",
    "    def __init__(self, dim, tau=10.0, dt=0.1):\n",
    "        super().__init__()\n",
    "        self.fc = bst.nn.Linear(dim, dim)\n",
    "        self.tau = tau\n",
    "        self.dt = dt\n",
    "        \n",
    "        # Add membrane potential dynamics\n",
    "        self.V = bst.ShortTermState(jnp.zeros(dim))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Compute target activity\n",
    "        target = jax.nn.relu(self.fc(x))\n",
    "        \n",
    "        # Integrate with first-order dynamics\n",
    "        dV = (target - self.V.value) / self.tau\n",
    "        self.V.value = self.V.value + dV * self.dt\n",
    "        \n",
    "        return self.V.value\n",
    "\n",
    "# Compare\n",
    "dim = 10\n",
    "x = bst.random.randn(5, dim)\n",
    "\n",
    "orig = OriginalBrainState(dim)\n",
    "conv = ConvertedBrainPyStyle(dim)\n",
    "\n",
    "# Initialize both\n",
    "_ = orig(x)\n",
    "_ = conv(x)\n",
    "\n",
    "# Copy weights\n",
    "orig_params = orig.states(bst.ParamState)\n",
    "conv_params = conv.states(bst.ParamState)\n",
    "for k in conv_params:\n",
    "    if k in orig_params:\n",
    "        conv_params[k].value = orig_params[k].value\n",
    "\n",
    "# Run both\n",
    "out_orig = orig(x)\n",
    "out_conv = conv(x)\n",
    "\n",
    "print(f\"Original output (instant): {out_orig[0, :5]}\")\n",
    "print(f\"Converted output (dynamics): {out_conv[0, :5]}\")\n",
    "print(\"\\nNote: Converted version has temporal dynamics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices\n",
    "\n",
    "### 7.1 Decision Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Framework Selection Decision Tree\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "decision_tree = \"\"\"\n",
    "START: What are you building?\n",
    "│\n",
    "├─ Standard ML/DL model (CNN, Transformer, etc.)\n",
    "│  └─> Use BrainState ✓\n",
    "│\n",
    "├─ Brain-inspired but rate-based neural network\n",
    "│  └─> Use BrainState ✓\n",
    "│\n",
    "├─ Spiking neural network\n",
    "│  ├─ Simple LIF neurons\n",
    "│  │  └─> Either (BrainState can do it)\n",
    "│  └─ Complex neuron models (HH, Izhikevich)\n",
    "│     └─> Use BrainPy ✓✓\n",
    "│\n",
    "├─ Computational neuroscience simulation\n",
    "│  └─> Use BrainPy ✓✓\n",
    "│\n",
    "├─ Need synaptic plasticity (STDP, BCM)\n",
    "│  └─> Use BrainPy ✓✓\n",
    "│\n",
    "└─ Hybrid: DL features + brain dynamics\n",
    "   └─> Use Both BrainState + BrainPy ✓✓\n",
    "\"\"\"\n",
    "\n",
    "print(decision_tree)\n",
    "\n",
    "print(\"\\nKey Questions to Ask:\")\n",
    "questions = [\n",
    "    \"1. Do I need biologically realistic neuron models? → BrainPy\",\n",
    "    \"2. Am I doing standard deep learning? → BrainState\",\n",
    "    \"3. Do I need spike timing dependent plasticity? → BrainPy\",\n",
    "    \"4. Am I building a simple feedforward network? → BrainState\",\n",
    "    \"5. Do I need differential equation solvers? → BrainPy\",\n",
    "    \"6. Am I prototyping quickly? → BrainState (simpler)\",\n",
    "    \"7. Is this for neuroscience research? → BrainPy\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"  {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Performance Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerformance Tips for Both Frameworks\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tips = [\n",
    "    (\"JIT Compilation\", \"Always use @bst.transform.jit for production\", \"Both\"),\n",
    "    (\"Vectorization\", \"Use vmap instead of Python loops\", \"Both\"),\n",
    "    (\"State Management\", \"Use appropriate state types (Param vs ShortTerm)\", \"Both\"),\n",
    "    (\"Memory\", \"Reset ShortTermState between episodes\", \"Both\"),\n",
    "    (\"Gradient Computation\", \"Specify grad_states to avoid unnecessary grads\", \"Both\"),\n",
    "    (\"Batch Processing\", \"Process multiple samples simultaneously\", \"Both\"),\n",
    "    (\"Time Steps\", \"For spiking: Balance accuracy vs speed\", \"BrainPy\"),\n",
    "    (\"Connectivity\", \"Use sparse matrices for large networks\", \"BrainPy\"),\n",
    "]\n",
    "\n",
    "print(f\"{'Aspect':<20} {'Tip':<40} {'Framework':<10}\")\n",
    "print(\"-\" * 70)\n",
    "for aspect, tip, framework in tips:\n",
    "    print(f\"{aspect:<20} {tip:<40} {framework:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Complementary Frameworks**:\n",
    "   - BrainState: Foundation for state management and basic DL\n",
    "   - BrainPy: Advanced brain modeling built on BrainState\n",
    "\n",
    "2. **Shared Foundation**:\n",
    "   - Same state management system\n",
    "   - Same base class (bst.graph.Node)\n",
    "   - Compatible JAX transformations\n",
    "\n",
    "3. **When to Use Each**:\n",
    "   - BrainState: Standard ML/DL, simple models, rapid prototyping\n",
    "   - BrainPy: Brain simulation, SNNs, neuroscience research\n",
    "   - Both: Hybrid models combining DL with brain dynamics\n",
    "\n",
    "4. **Interoperability**:\n",
    "   - Models from both can be combined seamlessly\n",
    "   - Share parameters and states\n",
    "   - Use same training infrastructure\n",
    "\n",
    "5. **Best Practices**:\n",
    "   - Start with BrainState for simplicity\n",
    "   - Add BrainPy when you need biological realism\n",
    "   - Use JIT and vmap for performance in both\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore BrainPy documentation for advanced features\n",
    "- Experiment with hybrid models\n",
    "- Try converting existing models between frameworks\n",
    "- Build neuromorphic applications\n",
    "\n",
    "For more information:\n",
    "- [BrainState Documentation](https://brainstate.readthedocs.io/)\n",
    "- [BrainPy Documentation](https://brainpy.readthedocs.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
