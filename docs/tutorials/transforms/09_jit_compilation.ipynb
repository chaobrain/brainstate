{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# JIT Compilation with BrainState\n",
    "\n",
    "Just-In-Time (JIT) compilation is one of JAX's most powerful features, allowing Python code to run at near-C speeds. BrainState provides state-aware JIT compilation that works seamlessly with stateful computations.\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "\n",
    "- ‚ö° **JIT Basics** - Speed up your code with `@jit`\n",
    "- üîß **Static vs Dynamic** - Understanding argument types\n",
    "- üéØ **Optimization Techniques** - Best practices for JIT\n",
    "- üìä **Performance Analysis** - Measuring speedups\n",
    "- üß† **Stateful JIT** - Compiling with BrainState objects\n",
    "\n",
    "## Why JIT?\n",
    "\n",
    "**Benefits:**\n",
    "- ‚ö° **10-100x speedup** for numerical computations\n",
    "- üöÄ **GPU/TPU acceleration** automatic\n",
    "- üîÑ **Optimized execution** - fused operations, reduced memory\n",
    "- üìà **Scales to large models** efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainstate as bst\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jit_basics",
   "metadata": {},
   "source": [
    "## 1. JIT Basics\n",
    "\n",
    "The simplest way to use JIT is with the `@jit` decorator:\n",
    "\n",
    "### Pure Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic_jit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without JIT\n",
    "def compute_sum_no_jit(x):\n",
    "    \"\"\"Sum of squares without JIT.\"\"\"\n",
    "    return jnp.sum(x ** 2)\n",
    "\n",
    "# With JIT\n",
    "@bst.transform.jit\n",
    "def compute_sum_jit(x):\n",
    "    \"\"\"Sum of squares with JIT.\"\"\"\n",
    "    return jnp.sum(x ** 2)\n",
    "\n",
    "# Test data\n",
    "x = bst.random.randn(1000)\n",
    "\n",
    "# First call (compilation + execution)\n",
    "print(\"First call (includes compilation):\")\n",
    "start = time.time()\n",
    "result_jit = compute_sum_jit(x)\n",
    "first_time = time.time() - start\n",
    "print(f\"  JIT result: {result_jit:.4f}, Time: {first_time*1000:.3f} ms\")\n",
    "\n",
    "# Second call (cached, just execution)\n",
    "print(\"\\nSecond call (cached):\")\n",
    "start = time.time()\n",
    "result_jit = compute_sum_jit(x)\n",
    "jit_time = time.time() - start\n",
    "print(f\"  JIT result: {result_jit:.4f}, Time: {jit_time*1000:.3f} ms\")\n",
    "\n",
    "# No JIT\n",
    "start = time.time()\n",
    "result_no_jit = compute_sum_no_jit(x)\n",
    "no_jit_time = time.time() - start\n",
    "print(f\"  No JIT result: {result_no_jit:.4f}, Time: {no_jit_time*1000:.3f} ms\")\n",
    "\n",
    "print(f\"\\n‚úÖ Speedup: {no_jit_time / jit_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compilation_process",
   "metadata": {},
   "source": [
    "### Understanding Compilation\n",
    "\n",
    "JIT compilation happens in two stages:\n",
    "\n",
    "1. **First call**: Trace ‚Üí Optimize ‚Üí Compile ‚Üí Execute\n",
    "2. **Subsequent calls**: Execute (cached)\n",
    "\n",
    "Let's visualize this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compilation_timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bst.transform.jit\n",
    "def complex_computation(x, n_iterations=100):\n",
    "    \"\"\"More complex computation for timing.\"\"\"\n",
    "    result = x\n",
    "    for i in range(n_iterations):\n",
    "        result = jnp.sin(result) + jnp.cos(result)\n",
    "        result = result / (jnp.sum(result) + 1e-8)\n",
    "    return result\n",
    "\n",
    "# Measure compilation + execution\n",
    "x = bst.random.randn(100)\n",
    "\n",
    "times = []\n",
    "for i in range(5):\n",
    "    start = time.time()\n",
    "    result = complex_computation(x)\n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    times.append(elapsed)\n",
    "    print(f\"Call {i+1}: {elapsed:.2f} ms\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(1, 6), times, color=['red', 'green', 'green', 'green', 'green'], alpha=0.7)\n",
    "plt.xlabel('Call Number')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('JIT Compilation: First Call vs Cached Calls', fontweight='bold')\n",
    "plt.axhline(y=times[1], color='green', linestyle='--', alpha=0.5, label='Cached time')\n",
    "plt.legend(['Cached baseline', 'Execution time'])\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFirst call (compilation): {times[0]:.2f} ms\")\n",
    "print(f\"Cached calls (average): {np.mean(times[1:]):.2f} ms\")\n",
    "print(f\"Compilation overhead: {times[0] - times[1]:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static_dynamic",
   "metadata": {},
   "source": [
    "## 2. Static vs Dynamic Arguments\n",
    "\n",
    "JAX distinguishes between **static** (compile-time) and **dynamic** (runtime) arguments.\n",
    "\n",
    "### Dynamic Arguments (Default)\n",
    "\n",
    "Most arguments are dynamic - the function reuses the compiled code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic_args",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bst.transform.jit\n",
    "def add_arrays(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Different array values, same shape - reuses compilation\n",
    "a = jnp.array([1.0, 2.0, 3.0])\n",
    "b = jnp.array([4.0, 5.0, 6.0])\n",
    "c = jnp.array([7.0, 8.0, 9.0])\n",
    "d = jnp.array([10.0, 11.0, 12.0])\n",
    "\n",
    "print(\"Calling with different values, same shape:\")\n",
    "print(f\"add_arrays(a, b) = {add_arrays(a, b)}  # Compiles\")\n",
    "print(f\"add_arrays(c, d) = {add_arrays(c, d)}  # Reuses compilation\")\n",
    "\n",
    "# Different shape - triggers recompilation\n",
    "e = jnp.array([1.0, 2.0])\n",
    "f = jnp.array([3.0, 4.0])\n",
    "\n",
    "print(f\"\\nadd_arrays(e, f) = {add_arrays(e, f)}  # Recompiles (different shape)\")\n",
    "\n",
    "print(\"\\n‚úÖ Array values are dynamic (no recompilation)\")\n",
    "print(\"‚ö†Ô∏è  Array shapes are static (triggers recompilation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static_args",
   "metadata": {},
   "source": [
    "### Static Arguments\n",
    "\n",
    "Use `static_argnums` to mark arguments as static:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bst.transform.jit(static_argnums=(1,))  # n is static\n",
    "def power(x, n):\n",
    "    \"\"\"Raise x to the power n.\"\"\"\n",
    "    result = x\n",
    "    for _ in range(n - 1):\n",
    "        result = result * x\n",
    "    return result\n",
    "\n",
    "x = jnp.array([2.0, 3.0])\n",
    "\n",
    "print(\"Static argument (n):\")\n",
    "print(f\"power(x, 2) = {power(x, 2)}  # Compiles for n=2\")\n",
    "print(f\"power(x, 2) = {power(x, 2)}  # Reuses\")\n",
    "print(f\"power(x, 3) = {power(x, 3)}  # Recompiles for n=3\")\n",
    "print(f\"power(x, 3) = {power(x, 3)}  # Reuses\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  Each unique static value triggers a separate compilation\")\n",
    "print(\"‚úÖ Use static args for: loop bounds, shape parameters, flags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical_example",
   "metadata": {},
   "source": [
    "### Practical Example: Configurable Network Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "layer_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurableLayer(bst.graph.Node):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.w = bst.ParamState(bst.random.randn(in_features, out_features) * 0.1)\n",
    "        self.b = bst.ParamState(jnp.zeros(out_features))\n",
    "    \n",
    "    @bst.transform.jit(static_argnums=(2,))  # use_activation is static\n",
    "    def forward(self, x, use_activation=True):\n",
    "        \"\"\"Forward with optional activation.\"\"\"\n",
    "        out = x @ self.w.value + self.b.value\n",
    "        if use_activation:\n",
    "            out = jnp.maximum(0, out)  # ReLU\n",
    "        return out\n",
    "\n",
    "# Create layer\n",
    "bst.random.seed(42)\n",
    "layer = ConfigurableLayer(10, 5)\n",
    "\n",
    "x = bst.random.randn(10)\n",
    "\n",
    "print(\"With activation:\")\n",
    "y1 = layer.forward(x, use_activation=True)\n",
    "print(f\"  Output: {y1}\")\n",
    "\n",
    "print(\"\\nWithout activation:\")\n",
    "y2 = layer.forward(x, use_activation=False)\n",
    "print(f\"  Output: {y2}\")\n",
    "\n",
    "print(\"\\n‚úÖ Two separate compiled versions (use_activation=True/False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stateful_jit",
   "metadata": {},
   "source": [
    "## 3. JIT with Stateful Objects\n",
    "\n",
    "BrainState allows JIT compilation of stateful computations:\n",
    "\n",
    "### Stateful Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stateful_counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter(bst.graph.Node):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.count = bst.ShortTermState(jnp.array(0))\n",
    "    \n",
    "    @bst.transform.jit\n",
    "    def increment(self, value):\n",
    "        \"\"\"Increment counter by value.\"\"\"\n",
    "        self.count.value = self.count.value + value\n",
    "        return self.count.value\n",
    "\n",
    "# Create and use\n",
    "counter = Counter()\n",
    "\n",
    "print(\"Stateful JIT compilation:\")\n",
    "for i in range(5):\n",
    "    result = counter.increment(jnp.array(i + 1))\n",
    "    print(f\"  Increment by {i+1}: count = {result}\")\n",
    "\n",
    "print(\"\\n‚úÖ State updates work inside JIT-compiled functions\")\n",
    "print(\"‚úÖ BrainState handles state threading automatically\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural_network_jit",
   "metadata": {},
   "source": [
    "### Neural Network with JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "network_jit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithJIT(bst.graph.Node):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.linears = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            linear = bst.nn.Linear(layers[i], layers[i+1])\n",
    "            setattr(self, f'linear{i}', linear)\n",
    "            self.linears.append(linear)\n",
    "    \n",
    "    @bst.transform.jit\n",
    "    def __call__(self, x):\n",
    "        \"\"\"JIT-compiled forward pass.\"\"\"\n",
    "        for i, linear in enumerate(self.linears):\n",
    "            x = linear(x)\n",
    "            if i < len(self.linears) - 1:  # No activation on last layer\n",
    "                x = jnp.maximum(0, x)  # ReLU\n",
    "        return x\n",
    "\n",
    "# Create network\n",
    "bst.random.seed(0)\n",
    "model = MLPWithJIT([784, 256, 128, 10])\n",
    "\n",
    "# Benchmark\n",
    "x = bst.random.randn(784)\n",
    "\n",
    "# Warmup (compilation)\n",
    "_ = model(x)\n",
    "\n",
    "# Measure\n",
    "n_runs = 1000\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    y = model(x)\n",
    "elapsed = (time.time() - start) * 1000 / n_runs\n",
    "\n",
    "print(f\"MLP with JIT:\")\n",
    "print(f\"  Input: {x.shape}\")\n",
    "print(f\"  Output: {y.shape}\")\n",
    "print(f\"  Average time: {elapsed:.4f} ms/forward\")\n",
    "print(f\"  Throughput: {1000/elapsed:.0f} forwards/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance",
   "metadata": {},
   "source": [
    "## 4. Performance Analysis\n",
    "\n",
    "Let's compare JIT vs non-JIT performance across different scenarios:\n",
    "\n",
    "### Matrix Multiplication Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matmul_benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_no_jit(A, B):\n",
    "    return jnp.dot(A, B)\n",
    "\n",
    "@bst.transform.jit\n",
    "def matmul_jit(A, B):\n",
    "    return jnp.dot(A, B)\n",
    "\n",
    "# Test different sizes\n",
    "sizes = [10, 50, 100, 500, 1000]\n",
    "times_no_jit = []\n",
    "times_jit = []\n",
    "\n",
    "for size in sizes:\n",
    "    A = bst.random.randn(size, size)\n",
    "    B = bst.random.randn(size, size)\n",
    "    \n",
    "    # Warmup JIT\n",
    "    _ = matmul_jit(A, B)\n",
    "    \n",
    "    # No JIT\n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        _ = matmul_no_jit(A, B)\n",
    "    time_no_jit = (time.time() - start) / 10\n",
    "    times_no_jit.append(time_no_jit * 1000)\n",
    "    \n",
    "    # JIT\n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        _ = matmul_jit(A, B)\n",
    "    time_jit = (time.time() - start) / 10\n",
    "    times_jit.append(time_jit * 1000)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(sizes, times_no_jit, 'o-', label='No JIT', linewidth=2, markersize=8)\n",
    "plt.plot(sizes, times_jit, 's-', label='JIT', linewidth=2, markersize=8)\n",
    "plt.xlabel('Matrix Size')\n",
    "plt.ylabel('Time (ms)')\n",
    "plt.title('Execution Time: JIT vs No JIT', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "speedups = [no_jit / jit for no_jit, jit in zip(times_no_jit, times_jit)]\n",
    "plt.bar(range(len(sizes)), speedups, color='green', alpha=0.7)\n",
    "plt.xticks(range(len(sizes)), sizes)\n",
    "plt.xlabel('Matrix Size')\n",
    "plt.ylabel('Speedup (x)')\n",
    "plt.title('JIT Speedup Factor', fontweight='bold')\n",
    "plt.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='No speedup')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSpeedup Summary:\")\n",
    "for size, speedup in zip(sizes, speedups):\n",
    "    print(f\"  Size {size:4d}: {speedup:.2f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimization_tips",
   "metadata": {},
   "source": [
    "## 5. Optimization Tips and Best Practices\n",
    "\n",
    "### Tip 1: Minimize Python Overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "python_overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå BAD: Python loop (not JIT-friendly)\n",
    "def sum_bad(arr):\n",
    "    total = 0\n",
    "    for x in arr:\n",
    "        total += x\n",
    "    return total\n",
    "\n",
    "# ‚úÖ GOOD: JAX operations\n",
    "@bst.transform.jit\n",
    "def sum_good(arr):\n",
    "    return jnp.sum(arr)\n",
    "\n",
    "arr = bst.random.randn(1000)\n",
    "\n",
    "# Compare\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    _ = sum_bad(arr)\n",
    "time_bad = (time.time() - start) * 1000 / 100\n",
    "\n",
    "_ = sum_good(arr)  # Warmup\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    _ = sum_good(arr)\n",
    "time_good = (time.time() - start) * 1000 / 100\n",
    "\n",
    "print(f\"Python loop: {time_bad:.4f} ms\")\n",
    "print(f\"JAX operations: {time_good:.4f} ms\")\n",
    "print(f\"Speedup: {time_bad / time_good:.1f}x\")\n",
    "print(\"\\n‚úÖ Use JAX/NumPy operations instead of Python loops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tip2",
   "metadata": {},
   "source": [
    "### Tip 2: Avoid Side Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "side_effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå BAD: Side effects (modifying external state)\n",
    "global_list = []\n",
    "\n",
    "def bad_function(x):\n",
    "    global_list.append(x)  # Side effect!\n",
    "    return x * 2\n",
    "\n",
    "# ‚úÖ GOOD: Pure function or BrainState states\n",
    "@bst.transform.jit\n",
    "def good_function(x):\n",
    "    return x * 2\n",
    "\n",
    "# With BrainState states (OK)\n",
    "class GoodCounter(bst.graph.Node):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.values = bst.ShortTermState(jnp.array([]))\n",
    "    \n",
    "    @bst.transform.jit\n",
    "    def append(self, x):\n",
    "        # This is OK - BrainState handles it\n",
    "        self.values.value = jnp.concatenate([self.values.value, jnp.array([x])])\n",
    "        return x * 2\n",
    "\n",
    "print(\"‚úÖ Avoid modifying global variables\")\n",
    "print(\"‚úÖ Use BrainState states for mutable data\")\n",
    "print(\"‚úÖ Keep functions pure when possible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tip3",
   "metadata": {},
   "source": [
    "### Tip 3: Batch Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå BAD: Multiple calls\n",
    "@bst.transform.jit\n",
    "def process_single(x):\n",
    "    return jnp.sin(x) + jnp.cos(x)\n",
    "\n",
    "# ‚úÖ GOOD: Batch processing\n",
    "@bst.transform.jit\n",
    "def process_batch(X):\n",
    "    return jnp.sin(X) + jnp.cos(X)\n",
    "\n",
    "# Generate data\n",
    "data = [bst.random.randn(100) for _ in range(100)]\n",
    "data_batch = jnp.stack(data)\n",
    "\n",
    "# Multiple calls\n",
    "start = time.time()\n",
    "results = [process_single(x) for x in data]\n",
    "time_single = (time.time() - start) * 1000\n",
    "\n",
    "# Batch call\n",
    "_ = process_batch(data_batch)  # Warmup\n",
    "start = time.time()\n",
    "result_batch = process_batch(data_batch)\n",
    "time_batch = (time.time() - start) * 1000\n",
    "\n",
    "print(f\"Multiple calls: {time_single:.2f} ms\")\n",
    "print(f\"Batch call: {time_batch:.2f} ms\")\n",
    "print(f\"Speedup: {time_single / time_batch:.1f}x\")\n",
    "print(\"\\n‚úÖ Batch operations for maximum performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debugging",
   "metadata": {},
   "source": [
    "## 6. Debugging JIT Code\n",
    "\n",
    "### Disabling JIT for Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debug_jit",
   "metadata": {},
   "outputs": [],
   "source": [
    "@bst.transform.jit\n",
    "def complex_function(x):\n",
    "    # Intermediate values are traced, can't be printed during JIT\n",
    "    y = jnp.sin(x)\n",
    "    z = jnp.cos(y)\n",
    "    return z\n",
    "\n",
    "# To debug, temporarily disable JIT\n",
    "import jax\n",
    "\n",
    "print(\"With JIT (can't see intermediate values):\")\n",
    "result = complex_function(jnp.array(1.0))\n",
    "print(f\"  Result: {result}\")\n",
    "\n",
    "print(\"\\nWith JIT disabled (for debugging):\")\n",
    "with jax.disable_jit():\n",
    "    x = jnp.array(1.0)\n",
    "    # Now we can add print statements\n",
    "    y = jnp.sin(x)\n",
    "    print(f\"  Intermediate y: {y}\")\n",
    "    z = jnp.cos(y)\n",
    "    print(f\"  Intermediate z: {z}\")\n",
    "\n",
    "print(\"\\nüí° Use jax.disable_jit() context manager for debugging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "‚úÖ **JIT Basics**\n",
    "  - Using `@bst.transform.jit` decorator\n",
    "  - Compilation vs execution time\n",
    "  - Caching compiled functions\n",
    "\n",
    "‚úÖ **Static vs Dynamic Arguments**\n",
    "  - Dynamic args (values) don't trigger recompilation\n",
    "  - Static args (shapes, flags) create separate compilations\n",
    "  - Using `static_argnums` parameter\n",
    "\n",
    "‚úÖ **Stateful JIT**\n",
    "  - JIT with BrainState objects\n",
    "  - State updates inside compiled functions\n",
    "  - Neural networks with JIT\n",
    "\n",
    "‚úÖ **Performance**\n",
    "  - 10-100x speedups typical\n",
    "  - Benchmarking techniques\n",
    "  - Understanding overhead\n",
    "\n",
    "‚úÖ **Best Practices**\n",
    "  - Use JAX operations, not Python loops\n",
    "  - Avoid side effects (or use States)\n",
    "  - Batch operations when possible\n",
    "  - Debug with `jax.disable_jit()`\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Concept | Code | When to Use |\n",
    "|---------|------|-------------|\n",
    "| **Basic JIT** | `@bst.transform.jit` | Most functions |\n",
    "| **Static args** | `@bst.transform.jit(static_argnums=(1,))` | Loop bounds, flags |\n",
    "| **Disable JIT** | `with jax.disable_jit():` | Debugging |\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "‚ùå **Don't:** Use Python loops over arrays  \n",
    "‚úÖ **Do:** Use JAX operations (jnp.sum, jnp.mean, etc.)\n",
    "\n",
    "‚ùå **Don't:** Modify global variables  \n",
    "‚úÖ **Do:** Use BrainState states or return values\n",
    "\n",
    "‚ùå **Don't:** Call JIT function in a loop with single items  \n",
    "‚úÖ **Do:** Batch the data and call once\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "1. üéØ **JIT everything** that runs repeatedly\n",
    "2. üì¶ **Batch operations** for maximum throughput\n",
    "3. üîß **Use static args** sparingly (each value = new compilation)\n",
    "4. üíæ **Warmup** before benchmarking\n",
    "5. üß™ **Profile** to find bottlenecks\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue with:\n",
    "- **Automatic Differentiation** - Computing gradients with JIT\n",
    "- **Vectorization** - vmap for automatic batching\n",
    "- **Advanced Transforms** - Combining JIT with other transforms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
