{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Differentiation with State-Aware Gradients"
   ],
   "id": "fe382f21b6eba564"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`brainstate.transform.grad` behaves like `jax.grad` but understands BrainState's\n",
    "state system. This notebook shows how to differentiate functions that depend on\n",
    "`State` objects, return auxiliary values, and mix parameter and argument\n",
    "sensitivities."
   ],
   "id": "2821e8b2725c6121"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:28:35.202920Z",
     "start_time": "2025-10-10T16:28:33.849522Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import brainstate\n",
    "from brainstate.transform import grad"
   ],
   "id": "1e3372b3c75857ad",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "We'll fit a tiny linear regression problem so gradients are easy to interpret."
   ],
   "id": "c1402d929310abde"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:28:35.348694Z",
     "start_time": "2025-10-10T16:28:35.202920Z"
    }
   },
   "source": [
    "xs = jnp.linspace(-1.0, 1.0, 5).reshape(-1, 1)\n",
    "y_true = 3.0 * xs + 1.0"
   ],
   "id": "95ed72b30f33646",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gradients with respect to `ParamState`\n",
    "\n",
    "Parameters live in `ParamState` containers. `grad_states` tells the transform to\n",
    "differentiate with respect to those states."
   ],
   "id": "8c92fbb160f2fac4"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:28:35.615231Z",
     "start_time": "2025-10-10T16:28:35.354982Z"
    }
   },
   "source": [
    "class LinearRegressor(brainstate.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int = 1):\n",
    "        super().__init__()\n",
    "        self.weight = brainstate.ParamState(jnp.zeros((in_features, out_features)))\n",
    "        self.bias = brainstate.ParamState(jnp.zeros((out_features,)))\n",
    "\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:\n",
    "        return x @ self.weight.value + self.bias.value\n",
    "\n",
    "\n",
    "model = LinearRegressor(in_features=1)\n",
    "\n",
    "\n",
    "def mse_loss(x: jax.Array, target: jax.Array) -> jax.Array:\n",
    "    prediction = model(x)\n",
    "    return jnp.mean((prediction - target) ** 2)\n",
    "\n",
    "\n",
    "loss_and_grads = grad(mse_loss, grad_states=model.states(brainstate.ParamState), return_value=True)\n",
    "param_grads, loss_value = loss_and_grads(xs, y_true)\n",
    "print('loss:', float(loss_value))\n",
    "print('gradients:')\n",
    "for path, g in param_grads.items():\n",
    "    print(' ', path, g)"
   ],
   "id": "bfce59773332503",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.5\n",
      "gradients:\n",
      "  ('bias',) [-2.]\n",
      "  ('weight',) [[-3.]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient dictionary mirrors the parameter tree. Updating the parameters is\n",
    "as simple as iterating through both structures."
   ],
   "id": "8391127548365328"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:28:35.704947Z",
     "start_time": "2025-10-10T16:28:35.636066Z"
    }
   },
   "source": [
    "learning_rate = 0.1\n",
    "params = model.states(brainstate.ParamState)\n",
    "for path, state in params.items():\n",
    "    state.value = state.value - learning_rate * param_grads[path]\n",
    "\n",
    "print('updated weight:', model.weight.value)\n",
    "print('updated bias:', model.bias.value)"
   ],
   "id": "4df0d617005b8e06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated weight: [[0.3]]\n",
      "updated bias: [0.2]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Returning auxiliary data\n",
    "\n",
    "Set `has_aux=True` when your function returns extra values (e.g. metrics).\n",
    "With `return_value=True` you receive `(grads, loss, aux)`."
   ],
   "id": "c5995a41a98374f0"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:28:35.793188Z",
     "start_time": "2025-10-10T16:28:35.727796Z"
    }
   },
   "source": [
    "model_aux = LinearRegressor(1)\n",
    "\n",
    "\n",
    "def loss_with_metrics(x: jax.Array, target: jax.Array):\n",
    "    pred = model_aux(x)\n",
    "    mse = jnp.mean((pred - target) ** 2)\n",
    "    metrics = {\n",
    "        'mae': jnp.mean(jnp.abs(pred - target)),\n",
    "        'mean_pred': jnp.mean(pred),\n",
    "    }\n",
    "    return mse, metrics\n",
    "\n",
    "\n",
    "grad_with_aux = grad(\n",
    "    loss_with_metrics,\n",
    "    grad_states=model_aux.states(brainstate.ParamState),\n",
    "    has_aux=True,\n",
    "    return_value=True,\n",
    ")\n",
    "\n",
    "param_grads_aux, loss_val_aux, metrics = grad_with_aux(xs, y_true)\n",
    "print('loss:', float(loss_val_aux))\n",
    "print('grad(weight):', param_grads_aux[('weight',)])\n",
    "print('metrics:', {k: float(v) for k, v in metrics.items()})"
   ],
   "id": "2a3d3c1391bd1111",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.5\n",
      "grad(weight): [[-3.]]\n",
      "metrics: {'mae': 2.0, 'mean_pred': 0.0}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradients w.r.t. states *and* arguments\n",
    "\n",
    "Provide `argnums` to differentiate with respect to positional arguments while\n",
    "also differentiating states. The result bundles `(state_grads, arg_grads)`."
   ],
   "id": "c4c440663f910cfd"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-10T16:28:36.040640Z",
     "start_time": "2025-10-10T16:28:35.815069Z"
    }
   },
   "source": [
    "model_reg = LinearRegressor(1)\n",
    "\n",
    "\n",
    "def penalised_loss(l2_coeff: float, x: jax.Array, target: jax.Array) -> jax.Array:\n",
    "    pred = model_reg(x)\n",
    "    mse = jnp.mean((pred - target) ** 2)\n",
    "    reg = l2_coeff * (jnp.sum(model_reg.weight.value ** 2) + jnp.sum(model_reg.bias.value ** 2))\n",
    "    return mse + reg\n",
    "\n",
    "\n",
    "grad_penalised = grad(\n",
    "    penalised_loss,\n",
    "    grad_states=model_reg.states(brainstate.ParamState),\n",
    "    argnums=0,\n",
    "    return_value=True,\n",
    ")\n",
    "\n",
    "(grads_pair, loss_val_penalised) = grad_penalised(0.1, xs, y_true)\n",
    "state_grads, coeff_grad = grads_pair\n",
    "print('loss:', float(loss_val_penalised))\n",
    "print('coeff gradient:', float(coeff_grad))\n",
    "for path, g in state_grads.items():\n",
    "    print('state grad', path, g)"
   ],
   "id": "cdc770a0078a6df6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.5\n",
      "coeff gradient: 0.0\n",
      "state grad ('bias',) [-2.]\n",
      "state grad ('weight',) [[-3.]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Pass `grad_states` to target specific `State` objects.\n",
    "- `has_aux` and `return_value` control whether loss values or metrics are\n",
    "  returned alongside gradients.\n",
    "- Combine `grad_states` with `argnums` to differentiate both states and regular\n",
    "  arguments in one call."
   ],
   "id": "af7cf27e5b334825"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
