{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 程序功能增强\n",
    "\n",
    "`BrainState` 框架基于[`pygraph` 语法](./pygraph-zh.ipynb)提供了强大的程序功能增强机制，允许用户在基本计算模型的基础上添加额外的功能，如自动微分、批处理、多设备并行等。本教程将详细介绍如何使用这些功能增强特性来优化和扩展你的模型。在阅读本教程之前，建议先阅读[`pygraph` 语法](./pygraph-zh.ipynb)教程。\n",
    "\n",
    "## 1. 自动微分\n",
    "\n",
    "自动微分是深度学习中最基础和最重要的功能之一。`BrainState`基于JAX的自动微分系统，提供了[简单直观的API](../apis/augment.rst)来计算梯度。\n",
    "\n",
    "\n",
    "### 1.1 自动微分语法\n",
    "\n",
    "\n",
    "`brainstate`提供的自动微分接口需要用户提供所需要求导的``State``集合。基本语法如下：\n",
    "\n",
    "```python\n",
    "gradients = brainstate.augment.grad(loss_fn, states)\n",
    "```\n",
    "\n",
    "其中，`loss_fn`是损失函数，`states`是需要求导的参数集合。`grad`函数返回一个新的函数，这个函数的输入和`loss_fn`相同，但是返回值是`states`中每个参数的梯度。`grad`针对标量损失函数进行求导，针对别的形式的损失函数，可以将其替换为其它形式的求导函数。目前我们支持的自动微分接口有：\n",
    "\n",
    "- `brainstate.augment.grad`：标量损失函数的自动微分，使用反向模式自动微分（reverse-mode automatic differentiation）\n",
    "- `brainstate.augment.vector_grad`：向量函数的自动微分，使用反向模式自动微分\n",
    "- `brainstate.augment.jacrev`：标量函数的雅可比矩阵，使用反向模式自动微分\n",
    "- `brainstate.augment.jacfwd`：标量函数的雅可比矩阵，使用前向模式自动微分（forward-mode automatic differentiation）\n",
    "- `brainstate.augment.jacobian`：标量函数的雅可比矩阵，与`brainstate.augment.jacrev`等价\n",
    "- `brainstate.augment.hessian`：标量函数的海森矩阵，使用反向模式自动微分\n",
    "- 更多详细信息请参考[API文档](../apis/augment.rst)\n",
    "\n",
    "\n",
    "`brainstate`提供的自动微分接口支持返回损失函数值(``return_value=True``)和支持返回辅助数据(auxiliary data, `has_aux=True`)。\n",
    "\n",
    "当``return_value=True``时，返回值是一个元组，第一个元素是梯度，第二个元素是损失函数值。\n",
    "\n",
    "\n",
    "```python\n",
    "gradients, loss = brainstate.augment.grad(loss_fn, states)\n",
    "```\n",
    "\n",
    "\n",
    "当``has_aux=True``时，返回值是一个元组，第一个元素是梯度，第二个元素是辅助数据。此时，``loss_fn``需要返回一个元组，第一个元素是损失函数值，第二个元素是辅助数据。\n",
    "\n",
    "```python\n",
    "def loss_fn(*args):\n",
    "    ...\n",
    "    return loss, aux\n",
    "\n",
    "gradients, aux = brainstate.augment.grad(loss_fn, states, has_aux=True)\n",
    "```\n",
    "\n",
    "当``return_value=True``和``has_aux=True``同时为True时，返回值是一个元组，第一个元素是梯度，第二个元素是损失函数值，第三个元素是辅助数据。\n",
    "\n",
    "```python\n",
    "def loss_fn(*args):\n",
    "    ...\n",
    "    return loss, aux\n",
    "\n",
    "gradients, loss, aux = brainstate.augment.grad(loss_fn, states, return_value=True, has_aux=True)\n",
    "```\n",
    "\n",
    "\n",
    "### 1.2 基础梯度计算\n",
    "\n",
    "`brainstate`提供的`grad`和`vector_grad`等函数支持一阶梯度计算。下面是一个简单的例子：\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f8a4ec2a6fd215"
  },
  {
   "cell_type": "code",
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "import brainunit as u\n",
    "import brainstate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T08:05:04.329810Z",
     "start_time": "2025-01-20T08:05:03.144513Z"
    }
   },
   "id": "916ff8eb23dede07",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# 创建一个简单的线性层模型\n",
    "model = brainstate.nn.Linear(2, 3)\n",
    "\n",
    "# 准备输入数据\n",
    "x = jnp.ones((1, 2))\n",
    "y = jnp.ones((1, 3))\n",
    "\n",
    "\n",
    "# 定义损失函数\n",
    "def loss_fn(x, y):\n",
    "    return jnp.mean((y - model(x)) ** 2)\n",
    "\n",
    "\n",
    "# 获取模型参数\n",
    "weights = model.states()\n",
    "\n",
    "# 计算梯度\n",
    "grads = brainstate.augment.grad(loss_fn, weights)(x, y)\n",
    "\n",
    "# 打印梯度信息\n",
    "print(\"Gradients:\", grads)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T08:05:05.277602Z",
     "start_time": "2025-01-20T08:05:04.481393Z"
    }
   },
   "id": "9cc1665cea6e886d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients: {('weight',): {'bias': Array([-0.66015077,  0.02036158, -1.7672682 ], dtype=float32), 'weight': Array([[-0.66015077,  0.02036158, -1.7672682 ],\n",
      "       [-0.66015077,  0.02036158, -1.7672682 ]], dtype=float32)}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 高阶梯度计算\n",
    "\n",
    "`BrainState`支持计算高阶导数，这在某些优化任务中非常有用："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "616828df3ce8786d"
  },
  {
   "cell_type": "code",
   "source": [
    "# 计算二阶导数\n",
    "hessian = brainstate.augment.hessian(loss_fn, weights)(x, y)\n",
    "\n",
    "# 计算雅可比矩阵\n",
    "jacobian = brainstate.augment.jacobian(loss_fn, weights)(x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T08:05:05.998844Z",
     "start_time": "2025-01-20T08:05:05.280880Z"
    }
   },
   "id": "a26d5b46ec08a05f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 梯度变换和链式法则\n",
    "\n",
    "你可以组合多个梯度计算操作："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6a27a71ffa63373"
  },
  {
   "cell_type": "code",
   "source": [
    "# 组合多个梯度操作\n",
    "def composite_grad(fn, params):\n",
    "    grad_fn = brainstate.augment.grad(fn, params)\n",
    "    return lambda *args: brainstate.augment.grad(grad_fn, params)(*args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T08:05:06.017489Z",
     "start_time": "2025-01-20T08:05:06.014108Z"
    }
   },
   "id": "8407b9350764c10c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 批处理增强\n",
    "\n",
    "批处理(Batching)是深度学习中提高计算效率的关键技术。它通过同时处理多个样本来提高硬件利用率，减少计算开销。``brainstate``支持对[``pygraph``模型](./pygraph-zh.ipynb)进行批处理，用户可以通过简单的API来实现批处理。\n",
    "\n",
    "`brainstate.augment.vmap` 相比于 `jax.vmap`，添加了两个新的参数``in_states`` 和 ``out_states``，用于指定用到的模型中哪些``State``需要进行批处理。``in_states`` 和 ``out_states`` 是一个字典，键是批处理的维度，值是需要进行批处理的``State``（可以是任意的``State``组合的PyTree）。\n",
    "\n",
    "与`jax.vmap`相同，`brainstate.augment.vmap`函数接收`in_axes`和`out_axes`参数，用于指定非`State`的参数的哪些维度是批处理的维度。`in_axes`和`out_axes`的用法与`jax.vmap`相同。\n",
    "\n",
    "以下是一些简单的例子："
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26af5c69efdec719"
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 4\n",
    "\n",
    "# 创建批处理数据和模型\n",
    "x_batch = jnp.ones((batch_size, 3)) * u.mA\n",
    "model = brainstate.nn.LIF(3)\n",
    "model.init_state(batch_size)\n",
    "\n",
    "\n",
    "# 对每一个批次计算损失\n",
    "@brainstate.augment.vmap(\n",
    "    in_states=model.states()  # 所有State都进行批处理\n",
    ")\n",
    "def eval(x):\n",
    "    with brainstate.environ.context(dt=0.1 * u.ms):\n",
    "        return model(x)\n",
    "\n",
    "eval(x_batch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T08:05:06.574394Z",
     "start_time": "2025-01-20T08:05:06.036308Z"
    }
   },
   "id": "f5495b50c88edb2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "``brainstate.augment.vmap``会自动识别没有正确设置批处理维度的``State``，并给出警告。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e8ed721d95f85b1"
  },
  {
   "cell_type": "code",
   "source": [
    "class Foo(brainstate.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = brainstate.ParamState(jnp.arange(4))\n",
    "        self.b = brainstate.ShortTermState(jnp.arange(4))\n",
    "\n",
    "    def __call__(self):\n",
    "        self.b.value = self.a.value * self.b.value\n",
    "\n",
    "\n",
    "foo = Foo()\n",
    "r = brainstate.augment.vmap(foo, in_states=foo.a)()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T08:05:08.978761Z",
     "start_time": "2025-01-20T08:05:06.581951Z"
    }
   },
   "id": "d70a54c649639d10",
   "outputs": [
    {
     "ename": "BatchAxisError",
     "evalue": "The value of State ShortTermState(\n  value=Traced<ShapedArray(int32[4])>with<BatchTrace> with\n    val = Array([[0, 0, 0, 0],\n         [0, 1, 2, 3],\n         [0, 2, 4, 6],\n         [0, 3, 6, 9]], dtype=int32)\n    batch_dim = 0\n) is batched, but it is not in the out_states.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mJaxStackTraceBeforeTransformation\u001B[0m         Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\runpy.py:198\u001B[0m, in \u001B[0;36m_run_module_as_main\u001B[1;34m()\u001B[0m\n\u001B[0;32m    197\u001B[0m     sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m mod_spec\u001B[38;5;241m.\u001B[39morigin\n\u001B[1;32m--> 198\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _run_code(code, main_globals, \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    199\u001B[0m                  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m, mod_spec)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\runpy.py:88\u001B[0m, in \u001B[0;36m_run_code\u001B[1;34m()\u001B[0m\n\u001B[0;32m     81\u001B[0m run_globals\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m=\u001B[39m mod_name,\n\u001B[0;32m     82\u001B[0m                    \u001B[38;5;18m__file__\u001B[39m \u001B[38;5;241m=\u001B[39m fname,\n\u001B[0;32m     83\u001B[0m                    __cached__ \u001B[38;5;241m=\u001B[39m cached,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     86\u001B[0m                    __package__ \u001B[38;5;241m=\u001B[39m pkg_name,\n\u001B[0;32m     87\u001B[0m                    __spec__ \u001B[38;5;241m=\u001B[39m mod_spec)\n\u001B[1;32m---> 88\u001B[0m exec(code, run_globals)\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m run_globals\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel_launcher.py:18\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mipykernel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m kernelapp \u001B[38;5;28;01mas\u001B[39;00m app\n\u001B[1;32m---> 18\u001B[0m app\u001B[38;5;241m.\u001B[39mlaunch_new_instance()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\traitlets\\config\\application.py:1075\u001B[0m, in \u001B[0;36mlaunch_instance\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1074\u001B[0m app\u001B[38;5;241m.\u001B[39minitialize(argv)\n\u001B[1;32m-> 1075\u001B[0m app\u001B[38;5;241m.\u001B[39mstart()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel\\kernelapp.py:739\u001B[0m, in \u001B[0;36mstart\u001B[1;34m()\u001B[0m\n\u001B[0;32m    738\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 739\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mio_loop\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m    740\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\tornado\\platform\\asyncio.py:195\u001B[0m, in \u001B[0;36mstart\u001B[1;34m()\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstart\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 195\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39masyncio_loop\u001B[38;5;241m.\u001B[39mrun_forever()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\asyncio\\base_events.py:607\u001B[0m, in \u001B[0;36mrun_forever\u001B[1;34m()\u001B[0m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 607\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_once()\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stopping:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\asyncio\\base_events.py:1922\u001B[0m, in \u001B[0;36m_run_once\u001B[1;34m()\u001B[0m\n\u001B[0;32m   1921\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1922\u001B[0m         handle\u001B[38;5;241m.\u001B[39m_run()\n\u001B[0;32m   1923\u001B[0m handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\asyncio\\events.py:80\u001B[0m, in \u001B[0;36m_run\u001B[1;34m()\u001B[0m\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 80\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_context\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_args)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mSystemExit\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel\\kernelbase.py:545\u001B[0m, in \u001B[0;36mdispatch_queue\u001B[1;34m()\u001B[0m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 545\u001B[0m     \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_one()\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel\\kernelbase.py:534\u001B[0m, in \u001B[0;36mprocess_one\u001B[1;34m()\u001B[0m\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 534\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m dispatch(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel\\kernelbase.py:437\u001B[0m, in \u001B[0;36mdispatch_shell\u001B[1;34m()\u001B[0m\n\u001B[0;32m    436\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misawaitable(result):\n\u001B[1;32m--> 437\u001B[0m         \u001B[38;5;28;01mawait\u001B[39;00m result\n\u001B[0;32m    438\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel\\ipkernel.py:362\u001B[0m, in \u001B[0;36mexecute_request\u001B[1;34m()\u001B[0m\n\u001B[0;32m    361\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_associate_new_top_level_threads_with(parent_header)\n\u001B[1;32m--> 362\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mexecute_request(stream, ident, parent)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel\\kernelbase.py:778\u001B[0m, in \u001B[0;36mexecute_request\u001B[1;34m()\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39misawaitable(reply_content):\n\u001B[1;32m--> 778\u001B[0m     reply_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m reply_content\n\u001B[0;32m    780\u001B[0m \u001B[38;5;66;03m# Flush output before sending the reply.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel\\ipkernel.py:449\u001B[0m, in \u001B[0;36mdo_execute\u001B[1;34m()\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m accepts_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m--> 449\u001B[0m     res \u001B[38;5;241m=\u001B[39m shell\u001B[38;5;241m.\u001B[39mrun_cell(\n\u001B[0;32m    450\u001B[0m         code,\n\u001B[0;32m    451\u001B[0m         store_history\u001B[38;5;241m=\u001B[39mstore_history,\n\u001B[0;32m    452\u001B[0m         silent\u001B[38;5;241m=\u001B[39msilent,\n\u001B[0;32m    453\u001B[0m         cell_id\u001B[38;5;241m=\u001B[39mcell_id,\n\u001B[0;32m    454\u001B[0m     )\n\u001B[0;32m    455\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\ipykernel\\zmqshell.py:549\u001B[0m, in \u001B[0;36mrun_cell\u001B[1;34m()\u001B[0m\n\u001B[0;32m    548\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_traceback \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 549\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrun_cell(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3075\u001B[0m, in \u001B[0;36mrun_cell\u001B[1;34m()\u001B[0m\n\u001B[0;32m   3074\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3075\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_cell(\n\u001B[0;32m   3076\u001B[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001B[0;32m   3077\u001B[0m     )\n\u001B[0;32m   3078\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3130\u001B[0m, in \u001B[0;36m_run_cell\u001B[1;34m()\u001B[0m\n\u001B[0;32m   3129\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3130\u001B[0m     result \u001B[38;5;241m=\u001B[39m runner(coro)\n\u001B[0;32m   3131\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\IPython\\core\\async_helpers.py:128\u001B[0m, in \u001B[0;36m_pseudo_sync_runner\u001B[1;34m()\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 128\u001B[0m     coro\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3334\u001B[0m, in \u001B[0;36mrun_cell_async\u001B[1;34m()\u001B[0m\n\u001B[0;32m   3331\u001B[0m interactivity \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m silent \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mast_node_interactivity\n\u001B[1;32m-> 3334\u001B[0m has_raised \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_ast_nodes(code_ast\u001B[38;5;241m.\u001B[39mbody, cell_name,\n\u001B[0;32m   3335\u001B[0m        interactivity\u001B[38;5;241m=\u001B[39minteractivity, compiler\u001B[38;5;241m=\u001B[39mcompiler, result\u001B[38;5;241m=\u001B[39mresult)\n\u001B[0;32m   3337\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_execution_succeeded \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m has_raised\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3517\u001B[0m, in \u001B[0;36mrun_ast_nodes\u001B[1;34m()\u001B[0m\n\u001B[0;32m   3516\u001B[0m     asy \u001B[38;5;241m=\u001B[39m compare(code)\n\u001B[1;32m-> 3517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_code(code, result, async_\u001B[38;5;241m=\u001B[39masy):\n\u001B[0;32m   3518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\brainpy-dev\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001B[0m, in \u001B[0;36mrun_code\u001B[1;34m()\u001B[0m\n\u001B[0;32m   3576\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3577\u001B[0m         exec(code_obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_global_ns, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_ns)\n\u001B[0;32m   3578\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   3579\u001B[0m     \u001B[38;5;66;03m# Reset our crash handler in place\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb\u001B[38;5;241m.\u001B[39mvalue\n\u001B[1;32m---> 11\u001B[0m foo \u001B[38;5;241m=\u001B[39m Foo()\n\u001B[0;32m     12\u001B[0m r \u001B[38;5;241m=\u001B[39m bst\u001B[38;5;241m.\u001B[39maugment\u001B[38;5;241m.\u001B[39mvmap(foo, in_states\u001B[38;5;241m=\u001B[39mfoo\u001B[38;5;241m.\u001B[39ma)()\n",
      "File \u001B[1;32mD:\\codes\\projects\\brainstate\\brainstate\\graph\\_graph_node.py:45\u001B[0m, in \u001B[0;36m__call__\u001B[1;34m()\u001B[0m\n\u001B[0;32m     44\u001B[0m node \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 45\u001B[0m node\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m node\n",
      "Cell \u001B[1;32mIn[6], line 5\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma \u001B[38;5;241m=\u001B[39m bst\u001B[38;5;241m.\u001B[39mParamState(jnp\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m4\u001B[39m))\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb \u001B[38;5;241m=\u001B[39m bst\u001B[38;5;241m.\u001B[39mShortTermState(jnp\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m4\u001B[39m))\n",
      "File \u001B[1;32mD:\\codes\\projects\\brainstate\\brainstate\\_state.py:234\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m()\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;66;03m# update metadata\u001B[39;00m\n\u001B[0;32m    232\u001B[0m metadata\u001B[38;5;241m.\u001B[39mupdate(_value\u001B[38;5;241m=\u001B[39mvalue,\n\u001B[0;32m    233\u001B[0m                 _level\u001B[38;5;241m=\u001B[39m_get_trace_stack_level(),\n\u001B[1;32m--> 234\u001B[0m                 _source_info\u001B[38;5;241m=\u001B[39msource_info_util\u001B[38;5;241m.\u001B[39mcurrent(),\n\u001B[0;32m    235\u001B[0m                 _name\u001B[38;5;241m=\u001B[39mname,\n\u001B[0;32m    236\u001B[0m                 tag\u001B[38;5;241m=\u001B[39mtag,\n\u001B[0;32m    237\u001B[0m                 _been_writen\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    239\u001B[0m \u001B[38;5;66;03m# avoid using self._setattr to avoid the check\u001B[39;00m\n",
      "\u001B[1;31mJaxStackTraceBeforeTransformation\u001B[0m: brainstate.augment._mapping.BatchAxisError: The value of State ShortTermState(\n  value=Traced<ShapedArray(int32[4])>with<BatchTrace> with\n    val = Array([[0, 0, 0, 0],\n         [0, 1, 2, 3],\n         [0, 2, 4, 6],\n         [0, 3, 6, 9]], dtype=int32)\n    batch_dim = 0\n) is batched, but it is not in the out_states.\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mBatchAxisError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 12\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb\u001B[38;5;241m.\u001B[39mvalue\n\u001B[0;32m     11\u001B[0m foo \u001B[38;5;241m=\u001B[39m Foo()\n\u001B[1;32m---> 12\u001B[0m r \u001B[38;5;241m=\u001B[39m bst\u001B[38;5;241m.\u001B[39maugment\u001B[38;5;241m.\u001B[39mvmap(foo, in_states\u001B[38;5;241m=\u001B[39mfoo\u001B[38;5;241m.\u001B[39ma)()\n",
      "File \u001B[1;32mD:\\codes\\projects\\brainstate\\brainstate\\augment\\_mapping.py:147\u001B[0m, in \u001B[0;36m_vmap_transform.<locals>.vmapped_fn\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out_axes_st) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    146\u001B[0m     out_axes_st \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 147\u001B[0m out_state_vals, outs \u001B[38;5;241m=\u001B[39m restore_rngs(\n\u001B[0;32m    148\u001B[0m     jax\u001B[38;5;241m.\u001B[39mvmap(\n\u001B[0;32m    149\u001B[0m         new_fn,\n\u001B[0;32m    150\u001B[0m         in_axes\u001B[38;5;241m=\u001B[39m(in_axes_st, in_axes),\n\u001B[0;32m    151\u001B[0m         out_axes\u001B[38;5;241m=\u001B[39m(out_axes_st, out_axes),\n\u001B[0;32m    152\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mtransform_kwargs\n\u001B[0;32m    153\u001B[0m     ),\n\u001B[0;32m    154\u001B[0m     rngs\u001B[38;5;241m=\u001B[39mrngs\n\u001B[0;32m    155\u001B[0m )(in_state_vals, args)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;66;03m# restore mapped state values\u001B[39;00m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, states \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(axis_to_out_states\u001B[38;5;241m.\u001B[39mvalues()):\n",
      "File \u001B[1;32mD:\\codes\\projects\\brainstate\\brainstate\\augment\\_random.py:64\u001B[0m, in \u001B[0;36m_rng_backup.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m rng_restorer\u001B[38;5;241m.\u001B[39mbackup()\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# call the function\u001B[39;00m\n\u001B[1;32m---> 64\u001B[0m out \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# restore the random state\u001B[39;00m\n\u001B[0;32m     66\u001B[0m rng_restorer\u001B[38;5;241m.\u001B[39mrestore()\n",
      "    \u001B[1;31m[... skipping hidden 6 frame]\u001B[0m\n",
      "File \u001B[1;32mD:\\codes\\projects\\brainstate\\brainstate\\augment\\_mapping.py:123\u001B[0m, in \u001B[0;36m_vmap_transform.<locals>.new_fn\u001B[1;34m(in_states_, args)\u001B[0m\n\u001B[0;32m    121\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(state, RandomState) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mid\u001B[39m(state) \u001B[38;5;129;01min\u001B[39;00m rng_ids:\n\u001B[0;32m    122\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m--> 123\u001B[0m         state\u001B[38;5;241m.\u001B[39mraise_error_with_source_info(\n\u001B[0;32m    124\u001B[0m             BatchAxisError(\n\u001B[0;32m    125\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe value of State \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is batched, but it is not in the out_states.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    126\u001B[0m             )\n\u001B[0;32m    127\u001B[0m         )\n\u001B[0;32m    129\u001B[0m out_states_ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    130\u001B[0m     [state\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;28;01mfor\u001B[39;00m state \u001B[38;5;129;01min\u001B[39;00m states]\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m axis, states \u001B[38;5;129;01min\u001B[39;00m axis_to_out_states\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m    132\u001B[0m ]\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out_states_, outs\n",
      "File \u001B[1;32mD:\\codes\\projects\\brainstate\\brainstate\\_state.py:351\u001B[0m, in \u001B[0;36mState.raise_error_with_source_info\u001B[1;34m(self, error)\u001B[0m\n\u001B[0;32m    349\u001B[0m name_stack \u001B[38;5;241m=\u001B[39m source_info_util\u001B[38;5;241m.\u001B[39mcurrent_name_stack() \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_info\u001B[38;5;241m.\u001B[39mname_stack\n\u001B[0;32m    350\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m source_info_util\u001B[38;5;241m.\u001B[39muser_context(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_info\u001B[38;5;241m.\u001B[39mtraceback, name_stack\u001B[38;5;241m=\u001B[39mname_stack):\n\u001B[1;32m--> 351\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\n",
      "\u001B[1;31mBatchAxisError\u001B[0m: The value of State ShortTermState(\n  value=Traced<ShapedArray(int32[4])>with<BatchTrace> with\n    val = Array([[0, 0, 0, 0],\n         [0, 1, 2, 3],\n         [0, 2, 4, 6],\n         [0, 3, 6, 9]], dtype=int32)\n    batch_dim = 0\n) is batched, but it is not in the out_states."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": "在上面的例子中，我们定义了一个简单的模型`Foo`，只批处理了`a`，而没有批处理`b`。`brainstate`会自动检测到这个问题，并给出报错。正确的做法是将`b`也批处理，比如将其设置为`out_states`.\n",
   "metadata": {
    "collapsed": false
   },
   "id": "7280a78b0c0cbc56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T08:05:19.295992Z",
     "start_time": "2025-01-20T08:05:19.281450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "foo = Foo()\n",
    "r = brainstate.augment.vmap(foo, in_states=foo.a, out_states=foo.b)()\n",
    "\n",
    "foo.b.value"
   ],
   "id": "dd95a9fa90bfab73",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0, 0, 0, 0],\n",
       "       [0, 1, 2, 3],\n",
       "       [0, 2, 4, 6],\n",
       "       [0, 3, 6, 9]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. 多设备并行计算\n",
    "\n",
    "\n",
    "不仅仅是批处理，`brainstate`还支持多设备并行计算。我们可以通过`brainstate.augment.pmap`函数将一个模型转换为支持多设备并行计算的模型。\n",
    "\n",
    "`brainstate.augment.pmap`增强函数的用法基本上跟`brainstate.augment.vmap`函数是一样的，只是`pmap`函数会将模型转换为支持多设备并行计算的模型，而`vmap`函数只是但设备上不同线程上的并行计算。"
   ],
   "id": "9ad4b4839e7da547"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 组合使用功能增强\n",
    "\n",
    "在实际应用中，我们常常需要组合使用多种功能增强。``brainstate``中各种功能增强函数和编译函数之间是可以互相组合使用的。下面是一个简单的例子：\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5f99438c0155576"
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 5\n",
    "xs = brainstate.random.rand(batch_size, 3)\n",
    "ys = brainstate.random.rand(batch_size, 4)\n",
    "\n",
    "net = brainstate.nn.Linear(3, 4)\n",
    "\n",
    "@brainstate.augment.vmap\n",
    "def batch_run(x):\n",
    "    return net(x)\n",
    "\n",
    "\n",
    "def loss_fn(x, y):\n",
    "    return jnp.mean((y - batch_run(x)) ** 2)\n",
    "\n",
    "\n",
    "weights = net.states(brainstate.ParamState)\n",
    "opt = brainstate.optim.Adam(1e-3)\n",
    "opt.register_trainable_weights(weights)\n",
    "\n",
    "\n",
    "@brainstate.compile.jit\n",
    "def batch_train(xs, ys):\n",
    "    grads, l = brainstate.augment.grad(loss_fn, weights, return_value=True)(xs, ys)\n",
    "    opt.update(grads)\n",
    "    return l\n",
    "\n",
    "\n",
    "l = batch_train(xs, ys)\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T08:05:21.411033Z",
     "start_time": "2025-01-20T08:05:20.697280Z"
    }
   },
   "id": "aa35946074dde5ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.9318466, dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 性能优化建议\n",
    "\n",
    "使用功能增强时，需要注意以下几点以获得最佳性能：\n",
    "\n",
    "1. **合理的批大小**：根据设备内存和计算能力选择适当的批大小\n",
    "2. **梯度累积**：当批大小受限时，考虑使用梯度累积\n",
    "3. **缓存编译**：重复使用已编译的函数以减少编译开销\n",
    "4. **内存管理**：使用`jax.device_get()`及时释放设备内存"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18759f159070f3eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 6. 调试技巧\n",
    "\n",
    "在使用功能增强时，调试是一个重要话题。`brainstate`完全支持jax中提供的调试工具，如`jax.debug`中的`print`函数。下面是一个简单的例子：\n",
    "\n",
    "```python\n",
    "# 使用jax.debug.print进行调试\n",
    "@bst.compile.jit\n",
    "def batch_train(xs, ys):\n",
    "    grads, l = bst.augment.grad(loss_fn, weights, return_value=True)(xs, ys)\n",
    "    jax.debug.print(\"Gradients: {g}\", g=grads)\n",
    "    opt.update(grads)\n",
    "    return l\n",
    "\n",
    "```\n",
    "\n",
    "详细用法用户可以参考[JAX调试文档](https://jax.readthedocs.io/en/latest/debugging/index.html)。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bb5cd69808f7f8e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 总结\n",
    "\n",
    "基于`pygraph`的程序功能增强是`BrainState`框架的核心特性之一，通过合理使用这些功能，可以显著提升模型的推理、训练效率和性能。本教程涵盖了主要的功能增强特性及其使用方法，为进一步探索和应用这些特性提供了基础。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa3b4d036fc2132"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
