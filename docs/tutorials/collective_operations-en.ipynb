{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collective Operations for Neural Network Modules\n",
    "\n",
    "When building complex neural networks, especially recurrent neural networks (RNNs) and deep hierarchical models, you often need to manage states across multiple modules. BrainState provides a set of powerful **collective operations** that allow you to efficiently initialize, reset, and manage states across an entire network hierarchy.\n",
    "\n",
    "This tutorial covers:\n",
    "\n",
    "1. **`call_order`**: A decorator to control execution order of methods\n",
    "2. **`call_all_fns`**: Call any method across all modules in a network\n",
    "3. **`init_all_states`**: Initialize states for all modules\n",
    "4. **`reset_all_states`**: Reset states for all modules\n",
    "5. **Vectorized operations**: `vmap_*` variants for creating batched ensembles\n",
    "\n",
    "These operations are essential for:\n",
    "- Managing recurrent neural network states\n",
    "- Building ensemble models\n",
    "- Creating complex hierarchical networks\n",
    "- Implementing stateful computations\n",
    "\n",
    " Content Coverage:\n",
    "\n",
    "1. Introduction - Overview of collective operations and their use cases\n",
    "2. call_order Decorator (Section 1)\n",
    "    - Basic usage and execution order control\n",
    "    - Practical examples with ordered methods\n",
    "3. Basic State Management (Section 2)\n",
    "    - init_all_states - Initializing module states\n",
    "    - reset_all_states - Resetting states between sequences\n",
    "    - Practical examples with GRU cells\n",
    "4. Nested Modules (Section 3)\n",
    "    - Working with hierarchical networks\n",
    "    - Stacked RNN example\n",
    "    - Automatic traversal demonstration\n",
    "5. Custom Methods with call_all_fns (Section 4)\n",
    "    - Calling custom methods across modules\n",
    "    - Passing arguments and keyword arguments\n",
    "6. Vectorized Operations (Section 5)\n",
    "    - vmap_init_all_states - Creating ensembles\n",
    "    - vmap_reset_all_states - Resetting ensemble states\n",
    "    - Practical ensemble learning examples\n",
    "7. Practical Example (Section 6)\n",
    "    - Complete sequence classification task\n",
    "    - Training loop with proper state management\n",
    "    - Synthetic data generation\n",
    "8. Advanced Features (Section 7)\n",
    "    - Selective operations with node_to_exclude\n",
    "    - Using fn_if_not_exist parameter\n",
    "    - Filter functions\n",
    "9. Performance Tips (Section 8)\n",
    "    - JIT compilation with state management\n",
    "    - Batch processing multiple sequences\n",
    "    - Performance benchmarking\n",
    "10. Summary - Best practices and key takeaways\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T02:05:31.326565Z",
     "start_time": "2025-10-03T02:05:29.805943Z"
    }
   },
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import brainstate"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T02:05:31.353893Z",
     "start_time": "2025-10-03T02:05:31.348706Z"
    }
   },
   "source": [
    "print(f\"BrainState version: {brainstate.__version__}\")\n",
    "print(f\"JAX version: {jax.__version__}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BrainState version: 0.2.0\n",
      "JAX version: 0.7.1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The `call_order` Decorator\n",
    "\n",
    "The `call_order` decorator allows you to specify the execution order of methods when they are called collectively. This is particularly useful when you need certain initialization or reset operations to happen in a specific sequence.\n",
    "\n",
    "### Basic Usage\n",
    "\n",
    "Methods decorated with `@call_order(level)` are executed in ascending order of their level values. Methods without the decorator are executed first."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T02:05:31.491773Z",
     "start_time": "2025-10-03T02:05:31.379821Z"
    }
   },
   "source": [
    "class OrderedModule(brainstate.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.execution_log = []\n",
    "    \n",
    "    # This executes first (no decorator)\n",
    "    def init_state(self):\n",
    "        self.execution_log.append('init_state (no order)')\n",
    "        self.state = brainstate.State(jnp.zeros(3))\n",
    "    \n",
    "    # This executes second (order 0)\n",
    "    @brainstate.nn.call_order(0)\n",
    "    def setup_connections(self):\n",
    "        self.execution_log.append('setup_connections (order 0)')\n",
    "    \n",
    "    # This executes third (order 1)\n",
    "    @brainstate.nn.call_order(1)\n",
    "    def finalize(self):\n",
    "        self.execution_log.append('finalize (order 1)')\n",
    "\n",
    "module = OrderedModule()\n",
    "\n",
    "# Call init_state on all modules\n",
    "brainstate.nn.call_all_fns(module, 'init_state')\n",
    "print(\"After calling init_state:\")\n",
    "print(module.execution_log)\n",
    "\n",
    "# Call setup_connections\n",
    "brainstate.nn.call_all_fns(module, 'setup_connections')\n",
    "print(\"\\nAfter calling setup_connections:\")\n",
    "print(module.execution_log)\n",
    "\n",
    "# Call finalize\n",
    "brainstate.nn.call_all_fns(module, 'finalize')\n",
    "print(\"\\nAfter calling finalize:\")\n",
    "print(module.execution_log)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After calling init_state:\n",
      "['init_state (no order)']\n",
      "\n",
      "After calling setup_connections:\n",
      "['init_state (no order)', 'setup_connections (order 0)']\n",
      "\n",
      "After calling finalize:\n",
      "['init_state (no order)', 'setup_connections (order 0)', 'finalize (order 1)']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic State Management: `init_all_states` and `reset_all_states`\n",
    "\n",
    "### Initializing States\n",
    "\n",
    "The `init_all_states` function calls the `init_state` method on all modules in a network hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple RNN cell\n",
    "gru = brainstate.nn.GRUCell(input_size=10, hidden_size=20)\n",
    "\n",
    "# Initialize states for batch_size=5\n",
    "brainstate.nn.init_all_states(gru, batch_size=5)\n",
    "\n",
    "# Check the hidden state\n",
    "print(\"Hidden state shape:\", gru.h.value.shape)\n",
    "print(\"Hidden state (initialized to zeros):\")\n",
    "print(gru.h.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting States\n",
    "\n",
    "The `reset_all_states` function is crucial for RNNs. It resets the hidden states between sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a sequence\n",
    "sequence_length = 10\n",
    "input_data = jax.random.normal(jax.random.PRNGKey(0), (sequence_length, 5, 10))\n",
    "\n",
    "print(\"Processing first sequence...\")\n",
    "for t in range(sequence_length):\n",
    "    output = gru(input_data[t])\n",
    "    if t == 0:\n",
    "        print(f\"  Step {t}, hidden state mean: {gru.h.value.mean():.6f}\")\n",
    "\n",
    "print(f\"\\nAfter sequence, hidden state mean: {gru.h.value.mean():.6f}\")\n",
    "\n",
    "# Reset states before processing next sequence\n",
    "brainstate.nn.reset_all_states(gru, batch_size=5)\n",
    "print(f\"After reset, hidden state mean: {gru.h.value.mean():.6f}\")\n",
    "\n",
    "# Process second sequence with reset states\n",
    "print(\"\\nProcessing second sequence...\")\n",
    "for t in range(3):\n",
    "    output = gru(input_data[t])\n",
    "    if t == 0:\n",
    "        print(f\"  Step {t}, hidden state mean: {gru.h.value.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with Nested Modules\n",
    "\n",
    "Collective operations automatically traverse the entire module hierarchy, making it easy to manage complex networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedRNN(brainstate.nn.Module):\n",
    "    \"\"\"A stacked RNN with multiple GRU layers\"\"\"\n",
    "    def __init__(self, input_size, hidden_sizes):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        \n",
    "        # Create multiple GRU layers\n",
    "        prev_size = input_size\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            layer = brainstate.nn.GRUCell(prev_size, hidden_size)\n",
    "            setattr(self, f'gru_{i}', layer)\n",
    "            self.layers.append(layer)\n",
    "            prev_size = hidden_size\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Forward pass through all layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Create a 3-layer stacked RNN\n",
    "stacked_rnn = StackedRNN(input_size=10, hidden_sizes=[20, 15, 10])\n",
    "\n",
    "# Initialize all states at once\n",
    "brainstate.nn.init_all_states(stacked_rnn, batch_size=8)\n",
    "\n",
    "# Check states in each layer\n",
    "print(\"States after initialization:\")\n",
    "for i, layer in enumerate(stacked_rnn.layers):\n",
    "    print(f\"  Layer {i}: hidden state shape = {layer.h.value.shape}\")\n",
    "\n",
    "# Process some data\n",
    "x = jax.random.normal(jax.random.PRNGKey(1), (8, 10))\n",
    "output = stacked_rnn(x)\n",
    "print(f\"\\nAfter forward pass:\")\n",
    "for i, layer in enumerate(stacked_rnn.layers):\n",
    "    print(f\"  Layer {i}: hidden state mean = {layer.h.value.mean():.6f}\")\n",
    "\n",
    "# Reset all states at once\n",
    "brainstate.nn.reset_all_states(stacked_rnn, batch_size=8)\n",
    "print(f\"\\nAfter reset:\")\n",
    "for i, layer in enumerate(stacked_rnn.layers):\n",
    "    print(f\"  Layer {i}: hidden state mean = {layer.h.value.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Methods with `call_all_fns`\n",
    "\n",
    "You can use `call_all_fns` to call any custom method across all modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModule(brainstate.nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.counter = 0\n",
    "    \n",
    "    def init_state(self, batch_size=1):\n",
    "        self.state = brainstate.State(jnp.zeros((batch_size, self.size)))\n",
    "    \n",
    "    def custom_operation(self, scale=1.0):\n",
    "        \"\"\"A custom method that scales the state\"\"\"\n",
    "        self.counter += 1\n",
    "        if hasattr(self, 'state'):\n",
    "            self.state.value = self.state.value * scale\n",
    "        print(f\"  Module with size {self.size}: called {self.counter} times\")\n",
    "\n",
    "class Network(brainstate.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.module1 = CustomModule(size=5)\n",
    "        self.module2 = CustomModule(size=10)\n",
    "        self.module3 = CustomModule(size=3)\n",
    "\n",
    "network = Network()\n",
    "\n",
    "# Initialize all states\n",
    "brainstate.nn.init_all_states(network, batch_size=4)\n",
    "\n",
    "# Call custom operation on all modules with a scaling factor\n",
    "print(\"Calling custom_operation with scale=2.0:\")\n",
    "brainstate.nn.call_all_fns(network, 'custom_operation', kwargs={'scale': 2.0}, fn_if_not_exist='pass')\n",
    "\n",
    "print(\"\\nCalling again with scale=0.5:\")\n",
    "brainstate.nn.call_all_fns(network, 'custom_operation', kwargs={'scale': 0.5}, fn_if_not_exist='pass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vectorized Operations: Creating Ensembles\n",
    "\n",
    "The `vmap_*` variants use JAX's vectorization to create multiple independent instances of a module, useful for ensemble learning or population-based methods.\n",
    "\n",
    "### `vmap_init_all_states`: Creating Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single GRU cell\n",
    "gru_ensemble = brainstate.nn.GRUCell(input_size=5, hidden_size=10)\n",
    "\n",
    "# Create 20 independent instances (ensemble members)\n",
    "# Each with batch_size=3\n",
    "ensemble_size = 20\n",
    "brainstate.nn.vmap_init_all_states(gru_ensemble, batch_size=3, axis_size=ensemble_size)\n",
    "\n",
    "# Check the shape: (ensemble_size, batch_size, hidden_size)\n",
    "print(f\"Hidden state shape: {gru_ensemble.h.value.shape}\")\n",
    "print(f\"Expected: ({ensemble_size}, 3, 10)\")\n",
    "\n",
    "# Each ensemble member has different random initialization\n",
    "print(f\"\\nHidden state statistics across ensemble:\")\n",
    "print(f\"  Mean: {gru_ensemble.h.value.mean():.6f}\")\n",
    "print(f\"  Std:  {gru_ensemble.h.value.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Data with Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input data: (batch_size, input_size)\n",
    "x = jax.random.normal(jax.random.PRNGKey(42), (3, 5))\n",
    "\n",
    "# We need to vmap the forward pass to handle the ensemble dimension\n",
    "@jax.vmap\n",
    "def ensemble_forward(ensemble_member):\n",
    "    # This function is called for each ensemble member\n",
    "    return ensemble_member(x)\n",
    "\n",
    "# Note: For simplicity, we'll just show the shape transformation\n",
    "# In practice, you'd integrate this with the actual GRU forward pass\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"After ensemble forward: each member processes the same input\")\n",
    "print(f\"Output would have shape: ({ensemble_size}, 3, 10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting Ensemble States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all ensemble members at once\n",
    "brainstate.nn.vmap_reset_all_states(gru_ensemble, batch_size=3, axis_size=ensemble_size)\n",
    "\n",
    "print(\"After reset:\")\n",
    "print(f\"  Hidden state shape: {gru_ensemble.h.value.shape}\")\n",
    "print(f\"  All zeros? {jnp.allclose(gru_ensemble.h.value, 0.0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical Example: Sequence Classification with State Management\n",
    "\n",
    "Let's build a complete example that uses collective operations for a sequence classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassifier(brainstate.nn.Module):\n",
    "    \"\"\"A simple RNN-based sequence classifier\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.rnn = brainstate.nn.GRUCell(input_size, hidden_size)\n",
    "        self.output_layer = brainstate.nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def __call__(self, sequence):\n",
    "        \"\"\"\n",
    "        Process a sequence and return classification logits.\n",
    "        \n",
    "        Args:\n",
    "            sequence: (seq_len, batch_size, input_size)\n",
    "        \n",
    "        Returns:\n",
    "            logits: (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # Process sequence step by step\n",
    "        for t in range(sequence.shape[0]):\n",
    "            hidden = self.rnn(sequence[t])\n",
    "        \n",
    "        # Use final hidden state for classification\n",
    "        logits = self.output_layer(hidden)\n",
    "        return logits\n",
    "\n",
    "# Create model\n",
    "model = SequenceClassifier(input_size=8, hidden_size=16, num_classes=3)\n",
    "\n",
    "# Initialize states\n",
    "batch_size = 4\n",
    "brainstate.nn.init_all_states(model, batch_size=batch_size)\n",
    "\n",
    "print(\"Model initialized!\")\n",
    "print(f\"RNN hidden state shape: {model.rnn.h.value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random sequences\n",
    "num_sequences = 20\n",
    "seq_length = 15\n",
    "input_size = 8\n",
    "\n",
    "key = jax.random.PRNGKey(123)\n",
    "sequences = jax.random.normal(key, (num_sequences, seq_length, input_size))\n",
    "labels = jax.random.randint(jax.random.PRNGKey(456), (num_sequences,), 0, 3)\n",
    "\n",
    "print(f\"Generated {num_sequences} sequences\")\n",
    "print(f\"Sequence shape: {sequences.shape}\")\n",
    "print(f\"Labels: {labels[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop with State Reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = brainstate.optim.Adam(lr=1e-3)\n",
    "optimizer.register_trainable_weights(model.states(brainstate.ParamState))\n",
    "\n",
    "def loss_fn(predictions, targets):\n",
    "    \"\"\"Cross-entropy loss\"\"\"\n",
    "    return -jnp.mean(jnp.sum(jax.nn.one_hot(targets, 3) * jax.nn.log_softmax(predictions), axis=-1))\n",
    "\n",
    "@brainstate.compile.jit\n",
    "def train_step(sequence, label):\n",
    "    \"\"\"Single training step\"\"\"\n",
    "    def forward():\n",
    "        logits = model(sequence)\n",
    "        return loss_fn(logits, label)\n",
    "    \n",
    "    # Compute gradients\n",
    "    grads = brainstate.augment.grad(forward, model.states(brainstate.ParamState))()\n",
    "    \n",
    "    # Update parameters\n",
    "    optimizer.update(grads)\n",
    "    \n",
    "    return forward()\n",
    "\n",
    "# Training loop\n",
    "print(\"Training...\")\n",
    "for epoch in range(3):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for i in range(0, num_sequences, batch_size):\n",
    "        # Get batch\n",
    "        batch_seq = sequences[i:i+batch_size]\n",
    "        batch_labels = labels[i:i+batch_size]\n",
    "        \n",
    "        # Transpose to (seq_len, batch_size, input_size)\n",
    "        batch_seq = jnp.transpose(batch_seq, (1, 0, 2))\n",
    "        \n",
    "        # Reset states before each sequence\n",
    "        brainstate.nn.reset_all_states(model, batch_size=batch_seq.shape[1])\n",
    "        \n",
    "        # Train step\n",
    "        loss = train_step(batch_seq, batch_labels)\n",
    "        epoch_loss += loss\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / (num_sequences // batch_size):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced: Selective Operations\n",
    "\n",
    "### Excluding Specific Modules\n",
    "\n",
    "Sometimes you may want to exclude certain modules from collective operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedNetwork(brainstate.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn1 = brainstate.nn.GRUCell(10, 20)\n",
    "        self.rnn2 = brainstate.nn.GRUCell(20, 15)\n",
    "        self.static_layer = brainstate.nn.Linear(15, 5)  # No state to initialize\n",
    "\n",
    "network = MixedNetwork()\n",
    "\n",
    "# Initialize only RNN cells (Linear doesn't have init_state)\n",
    "# Use fn_if_not_exist='pass' to skip modules without the method\n",
    "brainstate.nn.init_all_states(network, batch_size=8, fn_if_not_exist='pass')\n",
    "\n",
    "print(\"States initialized:\")\n",
    "print(f\"  RNN1 hidden state: {network.rnn1.h.value.shape}\")\n",
    "print(f\"  RNN2 hidden state: {network.rnn2.h.value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Filters to Exclude Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset only the first RNN, exclude others\n",
    "brainstate.nn.reset_all_states(\n",
    "    network,\n",
    "    batch_size=8,\n",
    "    node_to_exclude=lambda node: node is network.rnn2\n",
    ")\n",
    "\n",
    "print(\"After selective reset:\")\n",
    "print(f\"  RNN1 hidden state mean: {network.rnn1.h.value.mean():.6f}\")\n",
    "print(f\"  RNN2 hidden state mean: {network.rnn2.h.value.mean():.6f}\")\n",
    "print(\"  (RNN1 is reset to zeros, RNN2 keeps its values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Tips\n",
    "\n",
    "### 1. Use JIT Compilation with State Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "rnn = brainstate.nn.GRUCell(10, 20)\n",
    "brainstate.nn.init_all_states(rnn, batch_size=32)\n",
    "\n",
    "# Define a JIT-compiled function that processes sequences\n",
    "@brainstate.compile.jit\n",
    "def process_sequence(sequence):\n",
    "    outputs = []\n",
    "    for t in range(sequence.shape[0]):\n",
    "        output = rnn(sequence[t])\n",
    "        outputs.append(output)\n",
    "    return jnp.stack(outputs)\n",
    "\n",
    "# Generate test data\n",
    "test_seq = jax.random.normal(jax.random.PRNGKey(0), (50, 32, 10))\n",
    "\n",
    "# First call: compilation\n",
    "import time\n",
    "start = time.time()\n",
    "result = process_sequence(test_seq)\n",
    "compile_time = time.time() - start\n",
    "\n",
    "# Second call: using compiled version\n",
    "brainstate.nn.reset_all_states(rnn, batch_size=32)\n",
    "start = time.time()\n",
    "result = process_sequence(test_seq)\n",
    "run_time = time.time() - start\n",
    "\n",
    "print(f\"First call (with compilation): {compile_time*1000:.2f}ms\")\n",
    "print(f\"Second call (compiled): {run_time*1000:.2f}ms\")\n",
    "print(f\"Speedup: {compile_time/run_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Batch Processing Multiple Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple_sequences(sequences_list):\n",
    "    \"\"\"\n",
    "    Process multiple independent sequences efficiently.\n",
    "    \n",
    "    Args:\n",
    "        sequences_list: List of sequences, each (seq_len, batch_size, input_size)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sequence in sequences_list:\n",
    "        # Reset states before each sequence\n",
    "        brainstate.nn.reset_all_states(rnn, batch_size=sequence.shape[1])\n",
    "        \n",
    "        # Process sequence\n",
    "        result = process_sequence(sequence)\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create multiple sequences\n",
    "sequences = [jax.random.normal(jax.random.PRNGKey(i), (30, 32, 10)) for i in range(5)]\n",
    "\n",
    "# Process all sequences\n",
    "outputs = process_multiple_sequences(sequences)\n",
    "print(f\"Processed {len(outputs)} sequences\")\n",
    "print(f\"Each output shape: {outputs[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "BrainState's collective operations provide powerful tools for managing complex neural networks:\n",
    "\n",
    "1. **`call_order(level)`**: Control method execution order\n",
    "2. **`call_all_fns(target, fn_name, ...)`**: Call any method across all modules\n",
    "3. **`init_all_states(target, ...)`**: Initialize all module states\n",
    "4. **`reset_all_states(target, ...)`**: Reset all module states (critical for RNNs)\n",
    "5. **`vmap_*` variants**: Create vectorized ensembles\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- Always reset RNN states between independent sequences\n",
    "- Use `fn_if_not_exist='pass'` when calling methods that may not exist on all modules\n",
    "- Leverage `vmap_init_all_states` for ensemble methods\n",
    "- Combine with JIT compilation for best performance\n",
    "- Use `node_to_exclude` for fine-grained control\n",
    "\n",
    "These operations make it easy to build and manage complex hierarchical networks while maintaining clean, readable code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
