{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: Delay Mechanisms in BrainState\n",
    "\n",
    "**Author:** BrainState Development Team  \n",
    "**Date:** 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Delays are fundamental in neural systems, arising from:\n",
    "- **Axonal conduction delays**: Signal propagation along axons takes time\n",
    "- **Synaptic delays**: Chemical transmission across synapses introduces latency\n",
    "- **Network delays**: Multi-step information processing creates temporal lags\n",
    "\n",
    "BrainState provides three powerful APIs for handling delays:\n",
    "\n",
    "1. **`brainstate.nn.Delay`**: General-purpose delay buffer for any data\n",
    "2. **`brainstate.nn.DelayAccess`**: Named accessor for specific delay entries\n",
    "3. **`brainstate.nn.StateWithDelay`**: Automatic delay tracking for module states\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "- ✅ Understand the two delay buffer methods: rotation vs concatenation\n",
    "- ✅ Use `Delay` to create flexible delay buffers with multiple delay taps\n",
    "- ✅ Access delayed values using `DelayAccess` and named entries\n",
    "- ✅ Leverage `StateWithDelay` for automatic state history tracking\n",
    "- ✅ Implement realistic neural models with synaptic and axonal delays\n",
    "- ✅ Choose between step-based and time-based delay retrieval\n",
    "- ✅ Use linear vs round interpolation for continuous-time delays\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainstate as bst\n",
    "import brainunit as u\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bst.environ.set(dt=0.1 * u.ms)  # 0.1 ms time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding `brainstate.nn.Delay`\n",
    "\n",
    "### 1.1 What is a Delay Buffer?\n",
    "\n",
    "A delay buffer stores a **rolling history** of values over time. Think of it as a time window looking into the past:\n",
    "\n",
    "```\n",
    "Time:  t-3    t-2    t-1    t (now)\n",
    "       │      │      │      │\n",
    "Data:  [10] → [20] → [30] → [40]\n",
    "       ↑      ↑      ↑      ↑\n",
    "     delay=3 delay=2 delay=1 delay=0\n",
    "```\n",
    "\n",
    "The `Delay` class maintains this history efficiently using two methods:\n",
    "\n",
    "1. **Rotation method** (default): Uses a ring buffer with modulo indexing\n",
    "2. **Concatenation method**: Shifts data by concatenating new values\n",
    "\n",
    "### 1.2 Creating a Basic Delay\n",
    "\n",
    "Let's create a simple delay buffer for a scalar signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a delay buffer for a scalar value\n",
    "# We need to specify the shape/dtype of data we'll store\n",
    "target_data = jnp.array([0.0])  # Example: scalar in array form\n",
    "\n",
    "# Create delay with 5ms maximum delay\n",
    "delay_buffer = bst.nn.Delay(\n",
    "    target_info=target_data,  # Shape/dtype template\n",
    "    time=5.0 * u.ms,          # Maximum delay time\n",
    "    init=0.0,                 # Initial history value\n",
    "    delay_method='rotation'   # Use ring buffer (default)\n",
    ")\n",
    "\n",
    "# Initialize the state\n",
    "delay_buffer.init_state()\n",
    "\n",
    "print(f\"Maximum delay time: {delay_buffer.max_time}\")\n",
    "print(f\"Maximum delay length (steps): {delay_buffer.max_length}\")\n",
    "print(f\"History buffer shape: {delay_buffer.history.value.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Registering Delay Entries\n",
    "\n",
    "You can register **multiple named entries** for different delay times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create delay buffer with multiple taps\n",
    "delay_buffer = bst.nn.Delay(\n",
    "    target_info=jnp.array([0.0]),\n",
    "    time=10.0 * u.ms,  # Support delays up to 10ms\n",
    "    init=0.0\n",
    ")\n",
    "\n",
    "# Register different delay times with names\n",
    "delay_buffer.register_entry('immediate', 0.0 * u.ms)   # No delay\n",
    "delay_buffer.register_entry('short', 2.0 * u.ms)       # 2ms delay\n",
    "delay_buffer.register_entry('medium', 5.0 * u.ms)      # 5ms delay\n",
    "delay_buffer.register_entry('long', 10.0 * u.ms)       # 10ms delay\n",
    "\n",
    "delay_buffer.init_state()\n",
    "\n",
    "print(\"Registered delay entries:\")\n",
    "for name, delay_info in delay_buffer._registered_entries.items():\n",
    "    print(f\"  {name}: {delay_info} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Updating and Accessing Delayed Values\n",
    "\n",
    "Now let's simulate a signal and access its delayed versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "duration = 50.0 * u.ms\n",
    "dt = bst.environ.get_dt()\n",
    "num_steps = int(duration / dt)\n",
    "\n",
    "# Storage for visualization\n",
    "times = []\n",
    "current_values = []\n",
    "delayed_short = []\n",
    "delayed_medium = []\n",
    "delayed_long = []\n",
    "\n",
    "# Simulate a sinusoidal signal\n",
    "for i in range(num_steps):\n",
    "    t = i * dt\n",
    "    bst.environ.set(i=i, t=t)\n",
    "    \n",
    "    # Current signal: sin(2π * 50Hz * t)\n",
    "    current = jnp.sin(2 * jnp.pi * 50.0 * (t / u.second)) \n",
    "    current_array = jnp.array([current])\n",
    "    \n",
    "    # Update delay buffer with current value\n",
    "    delay_buffer.update(current_array)\n",
    "    \n",
    "    # Retrieve delayed values\n",
    "    val_immediate = delay_buffer.at('immediate')[0]\n",
    "    val_short = delay_buffer.at('short')[0]\n",
    "    val_medium = delay_buffer.at('medium')[0]\n",
    "    val_long = delay_buffer.at('long')[0]\n",
    "    \n",
    "    # Store for plotting\n",
    "    times.append(float(t / u.ms))\n",
    "    current_values.append(float(val_immediate))\n",
    "    delayed_short.append(float(val_short))\n",
    "    delayed_medium.append(float(val_medium))\n",
    "    delayed_long.append(float(val_long))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(times, current_values, label='Current (0ms delay)', linewidth=2)\n",
    "plt.plot(times, delayed_short, label='Short (2ms delay)', alpha=0.7)\n",
    "plt.plot(times, delayed_medium, label='Medium (5ms delay)', alpha=0.7)\n",
    "plt.plot(times, delayed_long, label='Long (10ms delay)', alpha=0.7)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Signal Value')\n",
    "plt.title('Delay Buffer: Multiple Delay Taps on 50Hz Sinusoid')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Delay buffer successfully stores and retrieves delayed values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Rotation vs Concatenation Methods\n",
    "\n",
    "**Rotation method** (ring buffer):\n",
    "- More memory efficient\n",
    "- Uses modulo indexing: `index = (current_step - delay_step) % max_length`\n",
    "- Default and recommended for most cases\n",
    "\n",
    "**Concatenation method**:\n",
    "- Shifts entire buffer on each update\n",
    "- Easier to understand conceptually\n",
    "- Can be slower for large buffers\n",
    "\n",
    "Let's compare both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two delay buffers with different methods\n",
    "delay_rotation = bst.nn.Delay(\n",
    "    target_info=jnp.array([0.0]),\n",
    "    time=5.0 * u.ms,\n",
    "    delay_method='rotation'\n",
    ")\n",
    "delay_rotation.register_entry('test', 3.0 * u.ms)\n",
    "delay_rotation.init_state()\n",
    "\n",
    "delay_concat = bst.nn.Delay(\n",
    "    target_info=jnp.array([0.0]),\n",
    "    time=5.0 * u.ms,\n",
    "    delay_method='concat'\n",
    ")\n",
    "delay_concat.register_entry('test', 3.0 * u.ms)\n",
    "delay_concat.init_state()\n",
    "\n",
    "# Simulate 10 steps\n",
    "print(\"Comparing rotation vs concatenation methods:\\n\")\n",
    "for i in range(10):\n",
    "    bst.environ.set(i=i)\n",
    "    \n",
    "    # Update both with same value\n",
    "    value = jnp.array([float(i)])\n",
    "    delay_rotation.update(value)\n",
    "    delay_concat.update(value)\n",
    "    \n",
    "    # Retrieve delayed values\n",
    "    val_rotation = delay_rotation.at('test')[0]\n",
    "    val_concat = delay_concat.at('test')[0]\n",
    "    \n",
    "    print(f\"Step {i}: Rotation={val_rotation:.1f}, Concat={val_concat:.1f}, Match={jnp.allclose(val_rotation, val_concat)}\")\n",
    "\n",
    "print(\"\\n✅ Both methods produce identical results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Time-based vs Step-based Retrieval\n",
    "\n",
    "### 2.1 Step-based Retrieval\n",
    "\n",
    "When you know the exact delay in **integer time steps**, use `retrieve_at_step()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_buffer = bst.nn.Delay(\n",
    "    target_info=jnp.array([0.0]),\n",
    "    time=10.0 * u.ms,\n",
    ")\n",
    "delay_buffer.init_state()\n",
    "\n",
    "# Populate buffer\n",
    "for i in range(20):\n",
    "    bst.environ.set(i=i)\n",
    "    delay_buffer.update(jnp.array([float(i * 10)]))\n",
    "\n",
    "# Retrieve by step (integer delay)\n",
    "bst.environ.set(i=19)  # At step 19\n",
    "current = delay_buffer.retrieve_at_step(0)      # 0 steps back\n",
    "delayed_5 = delay_buffer.retrieve_at_step(5)    # 5 steps back\n",
    "delayed_10 = delay_buffer.retrieve_at_step(10)  # 10 steps back\n",
    "\n",
    "print(\"Step-based retrieval at step 19:\")\n",
    "print(f\"  0 steps back (current):  {current[0]:.1f} (expected: {19*10})\")\n",
    "print(f\"  5 steps back:            {delayed_5[0]:.1f} (expected: {(19-5)*10})\")\n",
    "print(f\"  10 steps back:           {delayed_10[0]:.1f} (expected: {(19-10)*10})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Time-based Retrieval\n",
    "\n",
    "When delays are specified in **continuous time**, use `retrieve_at_time()`. This supports interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create delay with linear interpolation\n",
    "delay_linear = bst.nn.Delay(\n",
    "    target_info=jnp.array([0.0]),\n",
    "    time=5.0 * u.ms,\n",
    "    interp_method='linear_interp'  # Linear interpolation\n",
    ")\n",
    "delay_linear.init_state()\n",
    "\n",
    "# Create delay with round interpolation\n",
    "delay_round = bst.nn.Delay(\n",
    "    target_info=jnp.array([0.0]),\n",
    "    time=5.0 * u.ms,\n",
    "    interp_method='round'  # Round to nearest step\n",
    ")\n",
    "delay_round.init_state()\n",
    "\n",
    "# Populate both buffers\n",
    "for i in range(100):\n",
    "    t = i * bst.environ.get_dt()\n",
    "    bst.environ.set(i=i, t=t)\n",
    "    value = jnp.array([float(i)])\n",
    "    delay_linear.update(value)\n",
    "    delay_round.update(value)\n",
    "\n",
    "# Retrieve at non-integer delay times\n",
    "t_current = 99 * bst.environ.get_dt()\n",
    "bst.environ.set(i=99, t=t_current)\n",
    "\n",
    "delay_time = 2.5 * u.ms  # 2.5ms = 25 steps (non-integer at 0.1ms resolution)\n",
    "target_time = t_current - delay_time\n",
    "\n",
    "val_linear = delay_linear.retrieve_at_time(target_time)[0]\n",
    "val_round = delay_round.retrieve_at_time(target_time)[0]\n",
    "\n",
    "print(f\"Time-based retrieval at t={float(t_current / u.ms):.1f}ms, delay={float(delay_time / u.ms)}ms:\")\n",
    "print(f\"  Linear interpolation: {val_linear:.2f} (between steps 74 and 75)\")\n",
    "print(f\"  Round interpolation:  {val_round:.2f} (rounds to nearest step)\")\n",
    "print(f\"  Expected exact value: {99 - 25} (25 steps back from step 99)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Interpolation Comparison\n",
    "\n",
    "Let's visualize the difference between linear and round interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create delays with different interpolation\n",
    "delay_linear = bst.nn.Delay(jnp.array([0.0]), time=10.0 * u.ms, interp_method='linear_interp')\n",
    "delay_round = bst.nn.Delay(jnp.array([0.0]), time=10.0 * u.ms, interp_method='round')\n",
    "delay_linear.init_state()\n",
    "delay_round.init_state()\n",
    "\n",
    "# Populate with ramp signal\n",
    "for i in range(200):\n",
    "    t = i * bst.environ.get_dt()\n",
    "    bst.environ.set(i=i, t=t)\n",
    "    value = jnp.array([float(i)])\n",
    "    delay_linear.update(value)\n",
    "    delay_round.update(value)\n",
    "\n",
    "# Test various delay times (non-integer steps)\n",
    "t_now = 199 * bst.environ.get_dt()\n",
    "bst.environ.set(i=199, t=t_now)\n",
    "\n",
    "delay_times_ms = jnp.linspace(0.0, 10.0, 101)  # 0 to 10ms\n",
    "linear_vals = []\n",
    "round_vals = []\n",
    "\n",
    "for delay_ms in delay_times_ms:\n",
    "    delay_time = delay_ms * u.ms\n",
    "    target_time = t_now - delay_time\n",
    "    \n",
    "    val_linear = delay_linear.retrieve_at_time(target_time)[0]\n",
    "    val_round = delay_round.retrieve_at_time(target_time)[0]\n",
    "    \n",
    "    linear_vals.append(float(val_linear))\n",
    "    round_vals.append(float(val_round))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(delay_times_ms, linear_vals, label='Linear Interpolation', linewidth=2)\n",
    "plt.plot(delay_times_ms, round_vals, label='Round Interpolation', linewidth=2, alpha=0.7, linestyle='--')\n",
    "plt.xlabel('Delay Time (ms)')\n",
    "plt.ylabel('Retrieved Value')\n",
    "plt.title('Linear vs Round Interpolation in Time-based Delay Retrieval')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Linear interpolation provides smooth continuous values\")\n",
    "print(\"✅ Round interpolation snaps to nearest discrete time step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: `brainstate.nn.DelayAccess`\n",
    "\n",
    "### 3.1 What is DelayAccess?\n",
    "\n",
    "`DelayAccess` creates a **reusable accessor** for a specific delay entry. It's useful when:\n",
    "- You need to pass delay accessors to other modules\n",
    "- You want to encapsulate delay configuration\n",
    "- Building modular neural network components\n",
    "\n",
    "### 3.2 Creating and Using DelayAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a delay buffer\n",
    "delay_buffer = bst.nn.Delay(\n",
    "    target_info=jnp.array([0.0, 0.0, 0.0]),  # 3D vector\n",
    "    time=10.0 * u.ms,\n",
    ")\n",
    "delay_buffer.init_state()\n",
    "\n",
    "# Create DelayAccess objects for different delays\n",
    "# Method 1: Using .access() method\n",
    "accessor_2ms = delay_buffer.access('entry_2ms', 2.0 * u.ms)\n",
    "accessor_5ms = delay_buffer.access('entry_5ms', 5.0 * u.ms)\n",
    "\n",
    "# Simulate signal\n",
    "for i in range(200):\n",
    "    bst.environ.set(i=i)\n",
    "    \n",
    "    # Update with [i, i*2, i*3]\n",
    "    value = jnp.array([float(i), float(i*2), float(i*3)])\n",
    "    delay_buffer.update(value)\n",
    "\n",
    "# Access delayed values through DelayAccess objects\n",
    "delayed_2ms = accessor_2ms.update()  # Call update() to retrieve\n",
    "delayed_5ms = accessor_5ms.update()\n",
    "\n",
    "print(\"DelayAccess retrieval at step 199:\")\n",
    "print(f\"  2ms delay (20 steps): {delayed_2ms}\")\n",
    "print(f\"  5ms delay (50 steps): {delayed_5ms}\")\n",
    "print(f\"  Expected 2ms: [{199-20}, {(199-20)*2}, {(199-20)*3}]\")\n",
    "print(f\"  Expected 5ms: [{199-50}, {(199-50)*2}, {(199-50)*3}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Using DelayAccess in Modules\n",
    "\n",
    "DelayAccess is particularly useful when building modular components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelayedConnection(bst.nn.Module):\n",
    "    \"\"\"A module that applies delayed weighted connection.\"\"\"\n",
    "    \n",
    "    def __init__(self, size, weight, delay_time):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "        # Create delay buffer and accessor\n",
    "        self.delay_buffer = bst.nn.Delay(\n",
    "            target_info=jnp.zeros(size),\n",
    "            time=delay_time * 2,  # Buffer size\n",
    "        )\n",
    "        self.delay_access = self.delay_buffer.access('conn', delay_time)\n",
    "    \n",
    "    def update(self, current_input):\n",
    "        # Store current input\n",
    "        self.delay_buffer.update(current_input)\n",
    "        \n",
    "        # Get delayed input\n",
    "        delayed_input = self.delay_access.update()\n",
    "        \n",
    "        # Apply weight to delayed input\n",
    "        return self.weight * delayed_input\n",
    "\n",
    "# Create delayed connection\n",
    "conn = DelayedConnection(size=5, weight=0.5, delay_time=3.0 * u.ms)\n",
    "conn.delay_buffer.init_state()\n",
    "\n",
    "# Simulate\n",
    "print(\"Testing DelayedConnection module:\\n\")\n",
    "for i in range(50):\n",
    "    bst.environ.set(i=i)\n",
    "    \n",
    "    # Input: [i, i, i, i, i]\n",
    "    input_signal = jnp.ones(5) * i\n",
    "    output = conn.update(input_signal)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"Step {i:2d}: Input={float(input_signal[0]):5.1f}, Output={float(output[0]):5.1f}\")\n",
    "\n",
    "print(\"\\n✅ DelayAccess enables modular delay handling in custom modules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: `brainstate.nn.StateWithDelay`\n",
    "\n",
    "### 4.1 What is StateWithDelay?\n",
    "\n",
    "`StateWithDelay` is a **specialized delay** that automatically tracks a `State` variable in a module:\n",
    "\n",
    "- Automatically bound to a module's state (e.g., membrane potential `V`)\n",
    "- Updates history buffer after each simulation step\n",
    "- Commonly created via `prefetch_delay()` helper\n",
    "- Ideal for delayed feedback and recurrent connections\n",
    "\n",
    "### 4.2 Using StateWithDelay via `prefetch_delay()`\n",
    "\n",
    "The easiest way to use `StateWithDelay` is through the Dynamics `prefetch_delay()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFWithDelayedFeedback(bst.nn.Dynamics):\n",
    "    \"\"\"LIF neuron with delayed self-feedback.\"\"\"\n",
    "    \n",
    "    def __init__(self, size, feedback_delay=5.0 * u.ms, feedback_strength=0.3):\n",
    "        super().__init__(in_size=size)\n",
    "        \n",
    "        # Neuron parameters\n",
    "        self.tau = 10.0 * u.ms\n",
    "        self.V_rest = -65.0 * u.mV\n",
    "        self.V_th = -50.0 * u.mV\n",
    "        self.V_reset = -65.0 * u.mV\n",
    "        self.R = 1.0 * u.ohm\n",
    "        self.feedback_strength = feedback_strength\n",
    "        \n",
    "        # States\n",
    "        self.V = bst.State(jnp.ones(size) * self.V_rest)\n",
    "        self.spike = bst.State(jnp.zeros(size, dtype=bool))\n",
    "        \n",
    "        # Create StateWithDelay for V using prefetch_delay()\n",
    "        # This automatically creates a StateWithDelay and registers it\n",
    "        self.V_delayed = self.prefetch_delay('V', feedback_delay)\n",
    "    \n",
    "    def update(self, I):\n",
    "        # Get delayed voltage for feedback\n",
    "        V_delayed = self.V_delayed()  # Call to retrieve delayed value\n",
    "        \n",
    "        # Add delayed feedback to input current\n",
    "        feedback_current = (V_delayed - self.V_rest) * self.feedback_strength / self.R\n",
    "        I_total = I + feedback_current\n",
    "        \n",
    "        # Update voltage (exponential Euler)\n",
    "        dt = bst.environ.get_dt()\n",
    "        alpha = jnp.exp(-dt / self.tau)\n",
    "        V_inf = self.V_rest + I_total * self.R\n",
    "        self.V.value = self.V.value * alpha + V_inf * (1 - alpha)\n",
    "        \n",
    "        # Spike detection and reset\n",
    "        self.spike.value = self.V.value >= self.V_th\n",
    "        self.V.value = jnp.where(self.spike.value, self.V_reset, self.V.value)\n",
    "        \n",
    "        return self.spike.value\n",
    "\n",
    "# Create neuron with delayed feedback\n",
    "neuron = LIFWithDelayedFeedback(size=1, feedback_delay=3.0 * u.ms, feedback_strength=0.4)\n",
    "neuron.init_state()\n",
    "\n",
    "# Simulate\n",
    "duration = 100.0 * u.ms\n",
    "num_steps = int(duration / bst.environ.get_dt())\n",
    "\n",
    "times = []\n",
    "voltages = []\n",
    "spikes = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    t = i * bst.environ.get_dt()\n",
    "    bst.environ.set(i=i, t=t)\n",
    "    \n",
    "    # Constant input current\n",
    "    I_input = 1.5 * u.nA * jnp.ones(1)\n",
    "    \n",
    "    spike_output = neuron.update(I_input)\n",
    "    \n",
    "    times.append(float(t / u.ms))\n",
    "    voltages.append(float(neuron.V.value[0] / u.mV))\n",
    "    spikes.append(float(spike_output[0]))\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Voltage trace\n",
    "ax1.plot(times, voltages, linewidth=1.5)\n",
    "ax1.axhline(y=-50.0, color='r', linestyle='--', alpha=0.5, label='Threshold')\n",
    "ax1.set_ylabel('Membrane Potential (mV)')\n",
    "ax1.set_title('LIF Neuron with Delayed Self-Feedback (3ms delay)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Spike raster\n",
    "spike_times = [times[i] for i in range(len(spikes)) if spikes[i] > 0.5]\n",
    "ax2.eventplot([spike_times], lineoffsets=0.5, linelengths=0.8, colors='red')\n",
    "ax2.set_ylabel('Spikes')\n",
    "ax2.set_xlabel('Time (ms)')\n",
    "ax2.set_ylim([0, 1])\n",
    "ax2.set_yticks([])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ StateWithDelay automatically tracks module states for delayed feedback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Direct StateWithDelay Creation\n",
    "\n",
    "You can also create `StateWithDelay` explicitly (advanced usage):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuron(bst.nn.Dynamics):\n",
    "    \"\"\"Simple neuron for demonstration.\"\"\"\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        super().__init__(in_size=size)\n",
    "        self.V = bst.State(jnp.zeros(size))\n",
    "    \n",
    "    def update(self, x):\n",
    "        self.V.value = self.V.value * 0.9 + x\n",
    "        return self.V.value\n",
    "\n",
    "# Create neuron\n",
    "neuron = SimpleNeuron(size=3)\n",
    "neuron.init_state()\n",
    "\n",
    "# Manually create StateWithDelay for neuron.V\n",
    "state_delay = bst.nn.StateWithDelay(\n",
    "    target=neuron,          # The module owning the state\n",
    "    item='V',               # Name of the state attribute\n",
    "    delay_method='rotation'\n",
    ")\n",
    "\n",
    "# Register a delay time\n",
    "state_delay.register_entry('V_5ms', 5.0 * u.ms)\n",
    "\n",
    "# Initialize\n",
    "state_delay.init_state()\n",
    "\n",
    "# Simulate\n",
    "print(\"Manual StateWithDelay creation:\\n\")\n",
    "for i in range(100):\n",
    "    bst.environ.set(i=i)\n",
    "    \n",
    "    # Update neuron\n",
    "    neuron.update(jnp.array([1.0, 2.0, 3.0]) * (i / 10.0))\n",
    "    \n",
    "    # Update delay buffer (must be done manually in this case)\n",
    "    state_delay.update()\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        current_V = neuron.V.value\n",
    "        delayed_V = state_delay.at('V_5ms')\n",
    "        print(f\"Step {i:3d}: Current V={current_V}, Delayed V={delayed_V}\")\n",
    "\n",
    "print(\"\\n✅ StateWithDelay can be created explicitly for fine-grained control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Practical Example - Synaptic Transmission with Delays\n",
    "\n",
    "Let's build a realistic synapse model with axonal and dendritic delays:\n",
    "\n",
    "### 5.1 Delayed Synaptic Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLIF(bst.nn.Dynamics):\n",
    "    \"\"\"Simple LIF neuron.\"\"\"\n",
    "    \n",
    "    def __init__(self, size, tau=10.0 * u.ms, V_rest=-65.0 * u.mV,\n",
    "                 V_th=-50.0 * u.mV, V_reset=-65.0 * u.mV, R=1.0 * u.ohm):\n",
    "        super().__init__(in_size=size)\n",
    "        \n",
    "        self.tau = tau\n",
    "        self.V_rest = V_rest\n",
    "        self.V_th = V_th\n",
    "        self.V_reset = V_reset\n",
    "        self.R = R\n",
    "        \n",
    "        self.V = bst.State(jnp.ones(size) * V_rest)\n",
    "        self.spike = bst.State(jnp.zeros(size, dtype=bool))\n",
    "    \n",
    "    def update(self, I):\n",
    "        dt = bst.environ.get_dt()\n",
    "        alpha = jnp.exp(-dt / self.tau)\n",
    "        \n",
    "        V_inf = self.V_rest + I * self.R\n",
    "        self.V.value = self.V.value * alpha + V_inf * (1 - alpha)\n",
    "        \n",
    "        self.spike.value = self.V.value >= self.V_th\n",
    "        self.V.value = jnp.where(self.spike.value, self.V_reset, self.V.value)\n",
    "        \n",
    "        return self.spike.value\n",
    "\n",
    "\n",
    "class DelayedSynapse(bst.nn.Dynamics):\n",
    "    \"\"\"Synapse with conduction delay.\"\"\"\n",
    "    \n",
    "    def __init__(self, pre_size, post_size, weight_matrix, \n",
    "                 axonal_delay=2.0 * u.ms, tau_syn=5.0 * u.ms):\n",
    "        super().__init__(in_size=pre_size)\n",
    "        \n",
    "        self.weight = weight_matrix\n",
    "        self.tau_syn = tau_syn\n",
    "        \n",
    "        # Synaptic current state\n",
    "        self.I_syn = bst.State(jnp.zeros(post_size))\n",
    "        \n",
    "        # Create delay buffer for presynaptic spikes\n",
    "        self.spike_delay = bst.nn.Delay(\n",
    "            target_info=jnp.zeros(pre_size, dtype=bool),\n",
    "            time=axonal_delay * 2,\n",
    "            init=False\n",
    "        )\n",
    "        self.spike_delay.register_entry('axonal', axonal_delay)\n",
    "    \n",
    "    def update(self, pre_spike):\n",
    "        # Store presynaptic spikes\n",
    "        self.spike_delay.update(pre_spike)\n",
    "        \n",
    "        # Retrieve delayed spikes\n",
    "        delayed_spike = self.spike_delay.at('axonal')\n",
    "        \n",
    "        # Synaptic current injection\n",
    "        I_input = self.weight @ delayed_spike.astype(jnp.float32)\n",
    "        \n",
    "        # Synaptic current decay\n",
    "        dt = bst.environ.get_dt()\n",
    "        alpha = jnp.exp(-dt / self.tau_syn)\n",
    "        self.I_syn.value = self.I_syn.value * alpha + I_input\n",
    "        \n",
    "        return self.I_syn.value\n",
    "\n",
    "\n",
    "# Create network: pre -> synapse -> post\n",
    "pre_neuron = SimpleLIF(size=1)\n",
    "post_neuron = SimpleLIF(size=1)\n",
    "\n",
    "# Synaptic weight\n",
    "weight = jnp.array([[2.0]])  # Strong connection\n",
    "\n",
    "synapse = DelayedSynapse(\n",
    "    pre_size=1, \n",
    "    post_size=1, \n",
    "    weight_matrix=weight,\n",
    "    axonal_delay=5.0 * u.ms,  # 5ms axonal delay\n",
    "    tau_syn=3.0 * u.ms\n",
    ")\n",
    "\n",
    "# Initialize\n",
    "pre_neuron.init_state()\n",
    "post_neuron.init_state()\n",
    "synapse.spike_delay.init_state()\n",
    "\n",
    "# Simulate\n",
    "duration = 100.0 * u.ms\n",
    "num_steps = int(duration / bst.environ.get_dt())\n",
    "\n",
    "times = []\n",
    "pre_voltages = []\n",
    "post_voltages = []\n",
    "syn_currents = []\n",
    "pre_spikes = []\n",
    "post_spikes = []\n",
    "\n",
    "for i in range(num_steps):\n",
    "    t = i * bst.environ.get_dt()\n",
    "    bst.environ.set(i=i, t=t)\n",
    "    \n",
    "    # Strong input to presynaptic neuron\n",
    "    I_pre = 2.0 * u.nA * jnp.ones(1)\n",
    "    \n",
    "    # Update presynaptic neuron\n",
    "    pre_spike = pre_neuron.update(I_pre)\n",
    "    \n",
    "    # Update synapse with delayed transmission\n",
    "    I_syn = synapse.update(pre_spike)\n",
    "    \n",
    "    # Update postsynaptic neuron\n",
    "    post_spike = post_neuron.update(I_syn)\n",
    "    \n",
    "    # Record\n",
    "    times.append(float(t / u.ms))\n",
    "    pre_voltages.append(float(pre_neuron.V.value[0] / u.mV))\n",
    "    post_voltages.append(float(post_neuron.V.value[0] / u.mV))\n",
    "    syn_currents.append(float(I_syn[0] / u.nA))\n",
    "    pre_spikes.append(float(pre_spike[0]))\n",
    "    post_spikes.append(float(post_spike[0]))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Presynaptic voltage\n",
    "axes[0].plot(times, pre_voltages, 'b', linewidth=1.5)\n",
    "axes[0].axhline(y=-50.0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[0].set_ylabel('Pre V (mV)')\n",
    "axes[0].set_title('Synaptic Transmission with 5ms Axonal Delay')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Presynaptic spikes\n",
    "pre_spike_times = [times[i] for i in range(len(pre_spikes)) if pre_spikes[i] > 0.5]\n",
    "axes[1].eventplot([pre_spike_times], lineoffsets=0.5, linelengths=0.8, colors='blue')\n",
    "axes[1].set_ylabel('Pre Spikes')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].set_yticks([])\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Synaptic current\n",
    "axes[2].plot(times, syn_currents, 'g', linewidth=1.5)\n",
    "axes[2].set_ylabel('Syn Current (nA)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Postsynaptic voltage\n",
    "axes[3].plot(times, post_voltages, 'r', linewidth=1.5)\n",
    "axes[3].axhline(y=-50.0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[3].set_ylabel('Post V (mV)')\n",
    "axes[3].set_xlabel('Time (ms)')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Delayed synaptic transmission: presynaptic spikes appear at postsynaptic neuron after 5ms delay\")\n",
    "if len(pre_spike_times) > 0:\n",
    "    print(f\"   First pre spike: ~{pre_spike_times[0]:.1f}ms\")\n",
    "    print(f\"   First syn current rise: ~{pre_spike_times[0] + 5.0:.1f}ms (5ms delay)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Advanced - Heterogeneous Delays\n",
    "\n",
    "### 6.1 Vector Delays\n",
    "\n",
    "BrainState supports **heterogeneous delays** where each element can have a different delay time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create delay buffer for 3 neurons\n",
    "delay_buffer = bst.nn.Delay(\n",
    "    target_info=jnp.zeros(3),\n",
    "    time=10.0 * u.ms,\n",
    ")\n",
    "\n",
    "# Register heterogeneous delays: different delay for each neuron\n",
    "# Delays: [2ms, 5ms, 8ms]\n",
    "delay_times = jnp.array([2.0, 5.0, 8.0]) * u.ms\n",
    "neuron_indices = jnp.array([0, 1, 2])  # Which neuron\n",
    "\n",
    "delay_buffer.register_entry('heterogeneous', delay_times, neuron_indices)\n",
    "delay_buffer.init_state()\n",
    "\n",
    "# Simulate\n",
    "for i in range(200):\n",
    "    bst.environ.set(i=i)\n",
    "    \n",
    "    # Update with [i, i*10, i*100]\n",
    "    values = jnp.array([float(i), float(i*10), float(i*100)])\n",
    "    delay_buffer.update(values)\n",
    "\n",
    "# Retrieve heterogeneous delays\n",
    "delayed_values = delay_buffer.at('heterogeneous')\n",
    "\n",
    "expected_delays_steps = jnp.array([20, 50, 80])  # in steps (0.1ms each)\n",
    "expected_values = jnp.array([\n",
    "    199 - 20,\n",
    "    (199 - 50) * 10,\n",
    "    (199 - 80) * 100\n",
    "])\n",
    "\n",
    "print(\"Heterogeneous delays at step 199:\")\n",
    "print(f\"  Delays: [2ms, 5ms, 8ms] = {expected_delays_steps} steps\")\n",
    "print(f\"  Retrieved values: {delayed_values}\")\n",
    "print(f\"  Expected values:  {expected_values}\")\n",
    "print(f\"  Match: {jnp.allclose(delayed_values, expected_values)}\")\n",
    "\n",
    "print(\"\\n✅ Vector delays enable different delay times for each element\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **`brainstate.nn.Delay`**: General-purpose delay buffer\n",
    "   - Stores rolling history of values\n",
    "   - Supports rotation (ring buffer) or concatenation methods\n",
    "   - Multiple named delay entries via `register_entry()`\n",
    "   - Step-based (`retrieve_at_step`) or time-based (`retrieve_at_time`) retrieval\n",
    "   - Linear or round interpolation for continuous-time queries\n",
    "\n",
    "2. **`brainstate.nn.DelayAccess`**: Named accessor for delay entries\n",
    "   - Created via `delay.access(entry, delay_time)`\n",
    "   - Encapsulates delay configuration\n",
    "   - Useful for modular design\n",
    "   - Call `.update()` to retrieve delayed value\n",
    "\n",
    "3. **`brainstate.nn.StateWithDelay`**: Automatic state tracking\n",
    "   - Bound to a module's `State` variable\n",
    "   - Created via `prefetch_delay(state_name, delay_time)`\n",
    "   - Automatically updates after each step\n",
    "   - Ideal for delayed feedback and recurrent connections\n",
    "   - Call as function `()` to retrieve delayed state\n",
    "\n",
    "### API Comparison Table\n",
    "\n",
    "| Feature | `Delay` | `DelayAccess` | `StateWithDelay` |\n",
    "|---------|---------|---------------|------------------|\n",
    "| **Use Case** | General data buffering | Named accessors | Module state tracking |\n",
    "| **Creation** | Manual instantiation | Via `delay.access()` | Via `prefetch_delay()` |\n",
    "| **Updates** | Manual `update(value)` | Inherits from Delay | Automatic after step |\n",
    "| **Retrieval** | `at(entry)` or `retrieve_at_*` | `.update()` | Call as function `()` |\n",
    "| **Multiple delays** | ✅ Multiple entries | ✅ One per accessor | ✅ Multiple registrations |\n",
    "| **Interpolation** | ✅ Linear or round | ✅ Via underlying Delay | ✅ Via underlying Delay |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Choose the right tool**:\n",
    "   - Use `Delay` for general data buffering (synaptic inputs, external signals)\n",
    "   - Use `DelayAccess` when passing delay accessors to other modules\n",
    "   - Use `StateWithDelay` (via `prefetch_delay()`) for module state feedback\n",
    "\n",
    "2. **Delay method selection**:\n",
    "   - Default to `rotation` (ring buffer) for efficiency\n",
    "   - Use `concat` only if you need sequential buffer structure\n",
    "\n",
    "3. **Interpolation**:\n",
    "   - Use `linear_interp` for smooth continuous-time delays\n",
    "   - Use `round` for discrete time steps\n",
    "\n",
    "4. **Buffer sizing**:\n",
    "   - Set `time` parameter larger than maximum expected delay\n",
    "   - Buffer size = `ceil(max_delay / dt) + 1` steps\n",
    "\n",
    "5. **Initialization**:\n",
    "   - Always call `.init_state()` before simulation\n",
    "   - Provide meaningful `init` values for t < 0 history\n",
    "\n",
    "### Common Patterns\n",
    "\n",
    "**Pattern 1: Delayed synaptic connection**\n",
    "```python\n",
    "# In synapse __init__:\n",
    "self.spike_delay = bst.nn.Delay(jnp.zeros(pre_size), time=delay_time)\n",
    "self.spike_delay.register_entry('syn', delay_time)\n",
    "\n",
    "# In synapse update:\n",
    "self.spike_delay.update(pre_spike)\n",
    "delayed_spike = self.spike_delay.at('syn')\n",
    "```\n",
    "\n",
    "**Pattern 2: Delayed feedback**\n",
    "```python\n",
    "# In neuron __init__:\n",
    "self.V_delayed = self.prefetch_delay('V', feedback_delay)\n",
    "\n",
    "# In neuron update:\n",
    "V_past = self.V_delayed()\n",
    "feedback = compute_feedback(V_past)\n",
    "```\n",
    "\n",
    "**Pattern 3: Multiple delay taps**\n",
    "```python\n",
    "delay = bst.nn.Delay(data, time=max_delay)\n",
    "delay.register_entry('short', 2.0 * u.ms)\n",
    "delay.register_entry('medium', 5.0 * u.ms)\n",
    "delay.register_entry('long', 10.0 * u.ms)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Exercise\n",
    "\n",
    "**Challenge**: Implement a network of 3 LIF neurons with the following connections:\n",
    "- Neuron 0 → Neuron 1 (2ms delay, weight=1.0)\n",
    "- Neuron 1 → Neuron 2 (5ms delay, weight=1.5)\n",
    "- Neuron 2 → Neuron 0 (3ms delay, weight=-0.5, inhibitory)\n",
    "\n",
    "Use `bst.nn.Delay` for the synaptic connections and simulate for 200ms.\n",
    "\n",
    "**Hints**:\n",
    "1. Create 3 `SimpleLIF` neurons\n",
    "2. Create 3 `DelayedSynapse` objects for the connections\n",
    "3. Drive Neuron 0 with external input\n",
    "4. Plot voltage traces of all 3 neurons\n",
    "5. Observe the sequential activation with delays\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "- **Tutorial 7: Collective Operations** - Learn about communication patterns in neural populations\n",
    "- **Advanced Delays** - Explore plastic delays and state-dependent delays\n",
    "- **Network Architecture** - Build large-scale networks with distributed delays\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You now understand BrainState's powerful delay mechanisms for modeling realistic neural dynamics. 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
