{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are designed to process sequential data by maintaining hidden states that capture temporal dependencies.\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "\n",
    "- üîÑ **RNN Basics** - Understanding recurrence and hidden states\n",
    "- üß† **LSTM** - Long Short-Term Memory for long-term dependencies\n",
    "- ‚ö° **GRU** - Gated Recurrent Unit as efficient alternative\n",
    "- üìä **Sequence Processing** - Handling variable-length sequences\n",
    "- üí° **Practical Examples** - Sentiment analysis, time series\n",
    "\n",
    "## Why RNNs?\n",
    "\n",
    "RNNs excel at:\n",
    "- üìù Natural language processing\n",
    "- üéµ Speech and audio\n",
    "- üìà Time series forecasting\n",
    "- üé¨ Video analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainstate as bst\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rnn_basics",
   "metadata": {},
   "source": [
    "## 1. RNN Basics\n",
    "\n",
    "An RNN processes sequences one element at a time, updating its hidden state:\n",
    "\n",
    "**h_t = tanh(W_xh @ x_t + W_hh @ h_{t-1} + b)**\n",
    "\n",
    "### Simple RNN Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rnn_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNCell: Basic recurrent unit\n",
    "bst.random.seed(42)\n",
    "rnn_cell = bst.nn.RNNCell(\n",
    "    input_size=10,\n",
    "    hidden_size=20\n",
    ")\n",
    "\n",
    "print(\"RNNCell:\")\n",
    "print(rnn_cell)\n",
    "print(f\"\\nInput size: {rnn_cell.input_size}\")\n",
    "print(f\"Hidden size: {rnn_cell.hidden_size}\")\n",
    "\n",
    "# Initialize hidden state\n",
    "hidden = jnp.zeros(20)\n",
    "\n",
    "# Process a single timestep\n",
    "x_t = bst.random.randn(10)\n",
    "hidden_new = rnn_cell(x_t, hidden)\n",
    "\n",
    "print(f\"\\nInput shape: {x_t.shape}\")\n",
    "print(f\"Previous hidden: {hidden.shape}\")\n",
    "print(f\"New hidden: {hidden_new.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rnn_sequence",
   "metadata": {},
   "source": [
    "### Processing Sequences\n",
    "\n",
    "Let's process a complete sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rnn_sequence_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(bst.graph.Node):\n",
    "    \"\"\"Simple RNN for sequence processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn_cell = bst.nn.RNNCell(input_size, hidden_size)\n",
    "        self.output_layer = bst.nn.Linear(hidden_size, output_size)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def __call__(self, sequence):\n",
    "        \"\"\"\n",
    "        Process a sequence.\n",
    "        \n",
    "        Args:\n",
    "            sequence: (seq_length, input_size)\n",
    "            \n",
    "        Returns:\n",
    "            outputs: (seq_length, output_size)\n",
    "        \"\"\"\n",
    "        seq_length = sequence.shape[0]\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        hidden = jnp.zeros(self.hidden_size)\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(seq_length):\n",
    "            # Update hidden state\n",
    "            hidden = self.rnn_cell(sequence[t], hidden)\n",
    "            \n",
    "            # Generate output\n",
    "            output = self.output_layer(hidden)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        return jnp.stack(outputs)\n",
    "\n",
    "# Create RNN\n",
    "bst.random.seed(0)\n",
    "rnn = SimpleRNN(input_size=5, hidden_size=10, output_size=3)\n",
    "\n",
    "# Test sequence\n",
    "sequence = bst.random.randn(7, 5)  # 7 timesteps, 5 features\n",
    "outputs = rnn(sequence)\n",
    "\n",
    "print(f\"Input sequence shape: {sequence.shape}\")\n",
    "print(f\"Output sequence shape: {outputs.shape}\")\n",
    "print(f\"\\nOutputs:\\n{outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rnn_visualization",
   "metadata": {},
   "source": [
    "### Visualizing RNN Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rnn_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sine wave sequence\n",
    "t = jnp.linspace(0, 4 * jnp.pi, 50)\n",
    "sine_wave = jnp.sin(t)\n",
    "\n",
    "# Prepare as sequence (add feature dimension)\n",
    "sequence = sine_wave[:, None]\n",
    "\n",
    "# Create RNN\n",
    "bst.random.seed(42)\n",
    "rnn = SimpleRNN(input_size=1, hidden_size=16, output_size=1)\n",
    "\n",
    "# Process sequence\n",
    "outputs = rnn(sequence).flatten()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(t, sine_wave, linewidth=2, label='Input (Sine)', alpha=0.7)\n",
    "plt.plot(t, outputs, linewidth=2, label='RNN Output', alpha=0.7)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('RNN Processing Temporal Sequence', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"RNN learns to process temporal patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm_intro",
   "metadata": {},
   "source": [
    "## 2. LSTM - Long Short-Term Memory\n",
    "\n",
    "LSTM addresses the vanishing gradient problem with gating mechanisms:\n",
    "\n",
    "- **Forget gate**: What to forget from cell state\n",
    "- **Input gate**: What new information to store\n",
    "- **Output gate**: What to output from cell state\n",
    "\n",
    "### LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTMCell: Advanced recurrent unit\n",
    "bst.random.seed(42)\n",
    "lstm_cell = bst.nn.LSTMCell(\n",
    "    input_size=10,\n",
    "    hidden_size=20\n",
    ")\n",
    "\n",
    "print(\"LSTMCell:\")\n",
    "print(lstm_cell)\n",
    "\n",
    "# LSTM has two states: hidden (h) and cell (c)\n",
    "hidden = jnp.zeros(20)\n",
    "cell = jnp.zeros(20)\n",
    "\n",
    "# Process one timestep\n",
    "x_t = bst.random.randn(10)\n",
    "hidden_new, cell_new = lstm_cell(x_t, (hidden, cell))\n",
    "\n",
    "print(f\"\\nInput: {x_t.shape}\")\n",
    "print(f\"Hidden state: {hidden_new.shape}\")\n",
    "print(f\"Cell state: {cell_new.shape}\")\n",
    "print(\"\\n‚úÖ LSTM maintains both hidden and cell states\")\n",
    "print(\"‚úÖ Cell state provides long-term memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lstm_network",
   "metadata": {},
   "source": [
    "### LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lstm_network_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(bst.graph.Node):\n",
    "    \"\"\"LSTM network for sequence processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm_cell = bst.nn.LSTMCell(input_size, hidden_size)\n",
    "        self.output_layer = bst.nn.Linear(hidden_size, output_size)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def __call__(self, sequence):\n",
    "        seq_length = sequence.shape[0]\n",
    "        \n",
    "        # Initialize states\n",
    "        hidden = jnp.zeros(self.hidden_size)\n",
    "        cell = jnp.zeros(self.hidden_size)\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(seq_length):\n",
    "            # Update LSTM states\n",
    "            hidden, cell = self.lstm_cell(sequence[t], (hidden, cell))\n",
    "            \n",
    "            # Generate output\n",
    "            output = self.output_layer(hidden)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        return jnp.stack(outputs)\n",
    "\n",
    "# Create LSTM\n",
    "bst.random.seed(0)\n",
    "lstm = LSTMNet(input_size=5, hidden_size=20, output_size=3)\n",
    "\n",
    "# Test\n",
    "sequence = bst.random.randn(10, 5)\n",
    "outputs = lstm(sequence)\n",
    "\n",
    "print(f\"LSTM Network:\")\n",
    "print(lstm)\n",
    "print(f\"\\nSequence: {sequence.shape} ‚Üí Output: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gru_intro",
   "metadata": {},
   "source": [
    "## 3. GRU - Gated Recurrent Unit\n",
    "\n",
    "GRU simplifies LSTM with fewer gates:\n",
    "\n",
    "- **Reset gate**: How much past to forget\n",
    "- **Update gate**: How much to update\n",
    "\n",
    "### GRU Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gru_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRUCell: Efficient alternative to LSTM\n",
    "bst.random.seed(42)\n",
    "gru_cell = bst.nn.GRUCell(\n",
    "    input_size=10,\n",
    "    hidden_size=20\n",
    ")\n",
    "\n",
    "print(\"GRUCell:\")\n",
    "print(gru_cell)\n",
    "\n",
    "# GRU only has hidden state (no separate cell state)\n",
    "hidden = jnp.zeros(20)\n",
    "x_t = bst.random.randn(10)\n",
    "hidden_new = gru_cell(x_t, hidden)\n",
    "\n",
    "print(f\"\\nInput: {x_t.shape}\")\n",
    "print(f\"Hidden state: {hidden_new.shape}\")\n",
    "print(\"\\n‚úÖ Simpler than LSTM (no cell state)\")\n",
    "print(\"‚úÖ Faster training, fewer parameters\")\n",
    "print(\"‚úÖ Often performs similarly to LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "### Comparing RNN, LSTM, and GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all three types\n",
    "bst.random.seed(0)\n",
    "input_size, hidden_size = 5, 10\n",
    "\n",
    "rnn_cell = bst.nn.RNNCell(input_size, hidden_size)\n",
    "lstm_cell = bst.nn.LSTMCell(input_size, hidden_size)\n",
    "gru_cell = bst.nn.GRUCell(input_size, hidden_size)\n",
    "\n",
    "# Test on same sequence\n",
    "sequence = bst.random.randn(20, input_size)\n",
    "\n",
    "# Process with RNN\n",
    "h_rnn = jnp.zeros(hidden_size)\n",
    "rnn_states = []\n",
    "for x_t in sequence:\n",
    "    h_rnn = rnn_cell(x_t, h_rnn)\n",
    "    rnn_states.append(h_rnn)\n",
    "\n",
    "# Process with LSTM\n",
    "h_lstm = jnp.zeros(hidden_size)\n",
    "c_lstm = jnp.zeros(hidden_size)\n",
    "lstm_states = []\n",
    "for x_t in sequence:\n",
    "    h_lstm, c_lstm = lstm_cell(x_t, (h_lstm, c_lstm))\n",
    "    lstm_states.append(h_lstm)\n",
    "\n",
    "# Process with GRU\n",
    "h_gru = jnp.zeros(hidden_size)\n",
    "gru_states = []\n",
    "for x_t in sequence:\n",
    "    h_gru = gru_cell(x_t, h_gru)\n",
    "    gru_states.append(h_gru)\n",
    "\n",
    "# Visualize hidden states\n",
    "rnn_states = jnp.stack(rnn_states)\n",
    "lstm_states = jnp.stack(lstm_states)\n",
    "gru_states = jnp.stack(gru_states)\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(np.array(rnn_states.T), aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('RNN Hidden States', fontweight='bold')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Hidden Unit')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(np.array(lstm_states.T), aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('LSTM Hidden States', fontweight='bold')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Hidden Unit')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(np.array(gru_states.T), aspect='auto', cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title('GRU Hidden States', fontweight='bold')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Hidden Unit')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Different activation patterns across time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical_example",
   "metadata": {},
   "source": [
    "## 4. Practical Example: Sequence Classification\n",
    "\n",
    "Let's build a complete sequence classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sequence_classifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassifier(bst.graph.Node):\n",
    "    \"\"\"Classify sequences using LSTM.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = bst.nn.LSTMCell(input_size, hidden_size)\n",
    "        \n",
    "        # Classifier\n",
    "        self.fc = bst.nn.Linear(hidden_size, num_classes)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def __call__(self, sequence):\n",
    "        \"\"\"\n",
    "        Classify a sequence.\n",
    "        \n",
    "        Args:\n",
    "            sequence: (seq_length, input_size)\n",
    "            \n",
    "        Returns:\n",
    "            logits: (num_classes,)\n",
    "        \"\"\"\n",
    "        # Initialize states\n",
    "        hidden = jnp.zeros(self.hidden_size)\n",
    "        cell = jnp.zeros(self.hidden_size)\n",
    "        \n",
    "        # Process sequence\n",
    "        for t in range(sequence.shape[0]):\n",
    "            hidden, cell = self.lstm(sequence[t], (hidden, cell))\n",
    "        \n",
    "        # Use final hidden state for classification\n",
    "        logits = self.fc(hidden)\n",
    "        return logits\n",
    "\n",
    "# Create classifier\n",
    "bst.random.seed(42)\n",
    "classifier = SequenceClassifier(\n",
    "    input_size=8,\n",
    "    hidden_size=32,\n",
    "    num_classes=3\n",
    ")\n",
    "\n",
    "print(\"Sequence Classifier:\")\n",
    "print(classifier)\n",
    "\n",
    "# Test with batch of sequences\n",
    "sequences = [\n",
    "    bst.random.randn(10, 8),  # Short sequence\n",
    "    bst.random.randn(15, 8),  # Medium sequence\n",
    "    bst.random.randn(20, 8),  # Long sequence\n",
    "]\n",
    "\n",
    "print(\"\\nClassifying sequences of different lengths:\")\n",
    "for i, seq in enumerate(sequences):\n",
    "    logits = classifier(seq)\n",
    "    pred = jnp.argmax(logits)\n",
    "    print(f\"  Sequence {i+1} (length={seq.shape[0]:2d}): logits={logits}, predicted class={pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "time_series",
   "metadata": {},
   "source": [
    "## 5. Time Series Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "time_series_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic time series\n",
    "def generate_time_series(n_steps=100):\n",
    "    t = jnp.linspace(0, 10, n_steps)\n",
    "    # Combination of sine waves\n",
    "    series = jnp.sin(t) + 0.5 * jnp.sin(3 * t) + 0.1 * bst.random.randn(n_steps)\n",
    "    return series\n",
    "\n",
    "# Create sequences for prediction\n",
    "def create_sequences(data, seq_length=10):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return jnp.array(X), jnp.array(y)\n",
    "\n",
    "# Generate data\n",
    "bst.random.seed(0)\n",
    "time_series = generate_time_series(200)\n",
    "X, y = create_sequences(time_series, seq_length=15)\n",
    "\n",
    "# Add feature dimension\n",
    "X = X[:, :, None]\n",
    "\n",
    "print(f\"Time series data: {time_series.shape}\")\n",
    "print(f\"Sequences (X): {X.shape}\")\n",
    "print(f\"Targets (y): {y.shape}\")\n",
    "\n",
    "# Create predictor\n",
    "class TimeSeriesPredictor(bst.graph.Node):\n",
    "    def __init__(self, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.gru = bst.nn.GRUCell(input_size=1, hidden_size=hidden_size)\n",
    "        self.fc = bst.nn.Linear(hidden_size, 1)\n",
    "        self.hidden_size = hidden_size\n",
    "    \n",
    "    def __call__(self, sequence):\n",
    "        hidden = jnp.zeros(self.hidden_size)\n",
    "        for t in range(sequence.shape[0]):\n",
    "            hidden = self.gru(sequence[t], hidden)\n",
    "        prediction = self.fc(hidden)\n",
    "        return prediction[0]\n",
    "\n",
    "# Create and test predictor\n",
    "bst.random.seed(42)\n",
    "predictor = TimeSeriesPredictor(hidden_size=64)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = []\n",
    "for i in range(min(50, len(X))):\n",
    "    pred = predictor(X[i])\n",
    "    predictions.append(pred)\n",
    "\n",
    "predictions = jnp.array(predictions)\n",
    "targets = y[:len(predictions)]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(targets, label='True Values', linewidth=2, alpha=0.7)\n",
    "plt.plot(predictions, label='Predictions (Untrained)', linewidth=2, alpha=0.7)\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Time Series Prediction with GRU', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "mse = jnp.mean((predictions - targets) ** 2)\n",
    "print(f\"\\nMSE (untrained): {mse:.4f}\")\n",
    "print(\"üí° With training, GRU can learn to predict future values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "‚úÖ **RNN Basics**\n",
    "  - Recurrence and hidden states\n",
    "  - Processing sequences step-by-step\n",
    "  - Building simple RNN networks\n",
    "\n",
    "‚úÖ **LSTM**\n",
    "  - Gating mechanisms (forget, input, output)\n",
    "  - Cell state for long-term memory\n",
    "  - Handling long-term dependencies\n",
    "\n",
    "‚úÖ **GRU**\n",
    "  - Simplified gating (reset, update)\n",
    "  - Fewer parameters than LSTM\n",
    "  - Efficient alternative\n",
    "\n",
    "‚úÖ **Practical Applications**\n",
    "  - Sequence classification\n",
    "  - Time series prediction\n",
    "  - Variable-length sequences\n",
    "\n",
    "### Quick Comparison\n",
    "\n",
    "| Model | States | Gates | Best For |\n",
    "|-------|--------|-------|----------|\n",
    "| **RNN** | 1 (h) | 0 | Short sequences, simple patterns |\n",
    "| **LSTM** | 2 (h, c) | 3 | Long sequences, complex dependencies |\n",
    "| **GRU** | 1 (h) | 2 | Balance of complexity and performance |\n",
    "\n",
    "### When to Use Each\n",
    "\n",
    "- üéØ **Start with GRU** - Good default choice\n",
    "- üìö **Use LSTM** - When you need maximum capacity for long-term memory\n",
    "- ‚ö° **Use RNN** - For simple patterns or as baseline\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. üîÑ **Initialize hidden states to zero**\n",
    "2. üìä **Normalize input sequences**\n",
    "3. üéØ **Use gradient clipping** to prevent exploding gradients\n",
    "4. üíæ **Save hidden states** for inference on long sequences\n",
    "5. üîç **Try bidirectional RNNs** for offline sequence processing\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue with:\n",
    "- **Dynamics Systems** - Brain-inspired temporal models\n",
    "- **Attention Mechanisms** - Beyond RNNs (Transformers)\n",
    "- **Training** - Optimize RNNs effectively"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
